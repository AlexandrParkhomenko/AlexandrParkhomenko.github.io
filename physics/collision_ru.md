---
layout: default
title: "Робототехника"
description: "Физика столкновений на примере свободного физического движка реального времени Эрвина Куманса Bullet"
date: 
---

# Робототехника. 
## Александр Пархоменко. Физика столкновений на примере свободного физического движка реального времени Эрвина Куманса Bullet.

В версии markdown не отрисовываются формулы, смотрите [html версию](https://alexandrparkhomenko.github.io/physics/collision_ru.html)

1. # Введение
    1. Обзор содержания
        1. Глава 2: Проблемы проектирования обнаружения столкновений
        2. Глава 3: Учебник по математике, геометрии и физике
        3. Глава 4: Ограничивающие объёмы
        4. Глава 5: Базовые тесты примитивов
        5. Глава 6: Иерархии ограничивающих объемов
        6. Глава 7: Пространственное разбиение
        7. Глава 8: Иерархии деревьев BSP
        8. Глава 9: Основанные на выпуклости методы
        9. Глава 10: Обнаружение столкновений с помощью GPU
        10. Глава 11: Числовая устойчивость
        11. Глава 12: Геометрическая устойчивость
        12. Глава 13: Оптимизация
    2. О коде
2. # Вопросы проектирования обнаружения столкновений
    1. Факторы проектирования алгоритма коллизий
    2. Представление области приложения
        1. Представления объектов
        2. Столкновение против геометрии рендеринга
        3. Специализация алгоритмов столкновений
    3. Типы запросов
    4. Параметры моделирования окружающей среды
        1. Количество объектов
        2. Последовательное или одновременное движение
        3. Дискретное и непрерывное движение
    5. Производительность
        1. Обзор оптимизации
    6. Надежность
    7. Простота реализации и использования
        1. Отладка системы обнаружения столкновений
    8. Резюме
3. # Учебник по математике, геометрии и физике
    1. Матрицы
        1. Матричная арифметика
        2. Алгебраические тождества с матрицами
        3. Детерминанты
        4. Решение малых систем линейных уравнений с помощью правила Крамера 
        5. Обращение матриц для матриц 2 × 2 и 3 × 3
        6. Детерминантные предикаты
            1. ORIENT2D(A, B, C )
            2. ORIENT3D(A, B, C, D)
            3. INCIRCLE2D(A, B, C, D)
            4. INSPHERE(A, B, C, D, E )
    2. Системы координат и точки
    3. Векторы
        1. Векторная арифметика
        2. Алгебраические тождества с векторами
        3. Скалярное произведение
        4. Алгебраические тождества скалярных произведений
        5. Векторное произведение
        6. Алгебраические тождества векторых произведений
        7. Тройное скалярное произведение
        8. Алгебраические тождества тройных скалярных произведений
    4. Барицентрические координаты
    5. Линии, лучи и сегменты
    6. Плоскости и полупространства
    7. Многоугольники
        1. Проверка многоугольной выпуклости
    8. Многогранники
        1. Проверка многогранной выпуклости
    9. Вычисление выпуклой оболочки
        1. Алгоритм Эндрю
        2. Алгоритм Quickhull
    10. Регионы Вороного
    11. Сумма Минковского и разность
    12. Физические основы механики
        1. Модели в кинематике
            1. Система отсчета. 
            2. Траектория, длина пути, вектор перемещения
            3. Скорость
            4. Ускорение и его составляющие
                1. Угловая скорость и угловое ускорение
        2. Динамика материальной точки и поступательного движения твердого тела
            1. Первый закон Ньютона. Масса. Сила
            2. Второй закон Ньютона
            3. Третий закон Ньютона
            4. Силы трения
        3. Законы сохранения
            1. Закон сохранения импульса. Центр масс
            2. Энергия, работа, мощность
               1. Кинетическая энергия
               2. Потенциальная энергия
            3. Закон сохранения энергии
            4. Графическое представление энергии
            5. Удар абсолютно упругих и неупругих тел
        4. Механика твердого тела
            1. Момент инерции
            2. Кинетическая энергия вращения
            3. Момент силы. Уравнение динамики вращательного движения твердого тела
            4. Момент импульса и закон его сохранения
    13. Резюме
4. # Ограничивающие объёмы 
    1. Желательные характеристики BV
    2. Выровненные по оси ограничительные параллелипипеды (Axis-aligned Bounding Boxes, AABBs)
        1. AABB-AABB пересечение
        2. Вычисления и обновления AABBs
        3. AABB из ограничивающей объект сферы
        4. AABB реконструирован из исходного набора точек
        5. AABB из восхождения к вершине представления объекта
        6. AABB пересчитан из повернутого AABB
    3. Сферы
        1. Сфера-сфера пересечения
        2. Вычисление ограничивающей сферы
        3. Ограничивающая сфера из направления максимального распространения
        4. Ограничивающая сфера посредством итеративного уточнения
        5. Минимальная ограничивающая сфера
    4. Ориентированные ограничивающие параллелипипеды (Oriented Bounding Boxes, OBBs)
        1. OBB-OBB пересечение
        2. Повышение надежности теста разделительной оси
        3. Вычисление жесткого OBB
        4. Оптимизация OBB на основе PCA
        5. Установка OBB методом перебора
    5. Ометаемые сферой объёмы
        1. Пересечение ометаемых сферой объемов
        2. Вычисление ометаемых сферой ограничивающих объемов
    6. Объемы пересечения полупространства
        1. Kay–Kajiya объемы на основе плит (Slab)
        2. Дискретно-ориентированные многогранники (Discrete-orientation Polytopes, k-DOPs)
        3. Тест на пересечение k-DOP – k-DOP
        4. Вычисление и настройка k-DOP
        5. Приблизительные тесты на пересечение выпуклой оболочки
    7. Другие ограничивающие объемы
    8. Резюме
5. # Базовые тесты примитивов
    1. Вычисления ближайших точек
        1. Ближайшая точка на плоскости к точке
        2. Ближайшая точка на отрезке линии к точке
            1. Расстояние от точки до сегмента
        3. Ближайшая точка на AABB к точке
            1. Расстояние от точки до AABB
        4. Ближайшая точка OBB к точке
            1. Расстояние от точки до OBB
            2. Ближайшая точка на 3D-прямоугольнике к точке
        5. Ближайшая точка на Треугольнике к Точке
        6. Ближайшая точка на Тетраэдре к Точке
        7. Ближайшая точка Выпуклого многогранника к Точке
        8. Ближайшие точки двух Линий
        9. Ближайшие точки двух линейных участков
            1. 2D Пересечение Сегментов
        10. Ближайшие точки Отрезка линии и Треугольника
        11. Ближайшие точки двух Треугольников
    2. Тестирование пересечения примитивов
        1. Тест разделяющей оси
            1. Устойчивость теста разделяющей оси
        2. Тестирование пересечения Сферы и Плоскости
        3. Тестирование пересечения Параллелипипеда и Плоскости
        4. Тестирование пересечения Конуса и Плоскости
        5. Тестирование пересечения Сферы и AABB
        6. Тестирование пересечения Сферы и OBB
        7. Тестирование пересечения Сферы и Треугольника
        8. Тестирование пересечения Сферы и Многоугольника
        9. Тестирование пересечения AABB и Треугольника
        10. Тестирование пересечения Треугольника и Треугольника
    3. Пересекающиеся линии, лучи и (направленные) сегменты
        1. Пересекающиеся Сегмент и Плоскость
        2. Пересекающиеся Луч или Сегмент и Сфера
        3. Пересекающиеся Луч или Сегмент и Параллелипипед
        4. Пересекающиеся Линия и Треугольник
        5. Пересекающиеся Линия и Четырехугольник
        6. Пересекающиеся Луч или Сегмент и Треугольник
        7. Пересекающиеся Луч или Сегмент и Цилиндр
        8. Пересекающиеся Луч или Сегмент и Выпуклый многогранник
    4. Дополнительные тесты
        1. Тестирование Точки в многоугольнике
        2. Тестирование Точки в Треугольнике
        3. Тестирование Точки в Многограннике
        4. Пересечение двух Плоскостей
        5. Пересечение трех Плоскостей
    5. Тест динамических пересечений
        1. Уменьшение вдвое интервала пересечения движущихся объектов
        2. Тест разделяющей оси для движущихся выпуклых объектов
        3. Пересечение движущейся Сферы относительно Плоскости
        4. Пересечение движущихся AABB относительно Плоскости
        5. Пересечение движущейся Сферы относительно Сферы
        6. Пересечение движущейся сферы относительно треугольника (и многоугольника)
        7. Пересечение движущейся сферы относительно AABB
        8. Пересечение движущегося AABB относительно AABB
    6. Резюме
6. # Иерархии ограничивающих объемов
    1. Вопросы проектирования иерархии
        1. Желаемые характеристики BVH
        2. Функции стоимости
        3. Степень дерева
    2. Стратегии построения иерархии конструкций
        1. Построение сверху вниз
            1. Стратегии разбиения
            2. Выбор оси разделения
            3. Выбор точки разделения
        2. Построение снизу вверх
            1. Улучшенная конструкция снизу вверх
            2. Другие стратегии строительства снизу вверх
            3. Снизу вверх n-арные деревья кластеризации
        3. Инкрементальная (вставная) конструкция
            1. Метод инкрементной конструкции Goldsmith–Salmon
    3. Обход иерархии
        1. Правила спуска
        2. Общий информированный обход в глубину
        3. Одновременный обход в глубину
        4. Оптимизированный переход по листу в глубину
    4. Пример иерархии ограничивающих объемов
        1. OBB Деревья
        2. Деревья AABB и BoxTrees
        3. Дерево Сферы через разбиение на Октодерево
        4. Дерево Сферы с покрытых сферой поверхностей
        5. Покрытие сферы генерации и сокращения
        6. k-dop Деревья
    5. Объединение ограничивающих объемов
        1. Слияние двух AABB
        2. Слияние двух сфер
        3. Слияние двух OBB
        4. Слияние двух k-DOP
    6. Эффективное представление дерева и обход
        1. Представление массива
        2. Порядок обхода предзаказа
        3. Смещения вместо указателей
        4. Структуры, удобные для кеширования (Недвоичные деревья)
        5. Узел дерева и порядок примитивов
        6. О рекурсии
        7. Группировка запросов
    7. Улучшенные запросы через кеширование
        1. Кэширование поверхности: кеширование пересекающихся примитивов
        2. Переднее отслеживание
    8. Резюме
7. # Пространственное разбиение
    1. Равномерная сетка
        1. Проблемы с размером ячейки
        2. Сетки как массивы связанных списков
        3. Хешированное хранилище и бесконечные сети
        4. Хранение статических данных
        5. Неявные сетки
        6. Объектно-объектный тест Равномерной сетки
            1. Один тест за раз
            2. Все тесты одновременно
        7. Дополнительные соображения по сетке
    2. Иерархические сетки
        1. Базовая реализация Hgrid
        2. Альтернативные иерархические сеточные представления
        3. Другие иерархические сетки
    3. Деревья
        1. Октодеревья (и Квадродеревья)
        2. Назначение объекта Октодерева
        3. Коды местоположения и поиск октанта для точки
        4. Линейные октодеревья (на основе хэша)
        5. Вычисление ключа Мортона
        6. Свободные октодеревья
        7. k-d Деревья
        8. Гибридные схемы
    4. Обход лучей и отрезков направленных линий
        1. k-d Тест на пересечение деревьев
        2. Тест на пересечение Равномерной сетки
    5. Методы сортировки и поиска
        1. Реализация отсортированного связного списка
        2. Сортировка по массивам
    6. Ячейки и порталы
    7. Избегание повторного тестирования
        1. Битовые флаги
        2. Штамп времени
        3. Амортизированная очистка штампов времени
    8. Резюме
8. # Иерархии деревьев BSP
    1. BSP Деревья
    2. Типы BSP-деревьев
        1. BSP-деревья с хранением узлов
        2. Деревья BSP с хранением Листов
        3. Деревья BSP с твердыми листьями
    3. Построение BSP-дерева
        1. Выбор разделяющих плоскостей
        2. Оценка разделяющих плоскостей
        3. Классификация полигонов по плоскости
        4. Разбиение полигонов на плоскости
        5. Подробнее об устойчивости к разбиению полигонов
        6. Настройка производительности дерева BSP
    4. Использование BSP Дерева
        1. Проверка точки на BSP-дереве с твердыми листьями
        2. Пересечение луча с твердолистным деревом BSP
        3. Многогранники на деревьях BSP с твердыми листьями
    5. Резюме
9. # Основанные на выпуклости методы
    1. Обнаружение столкновений на основе границ
    2. Алгоритмы с Ближайшими особенностями
        1. Алгоритм V-Clip
    3. Иерархические представления многогранников
        1. Иерархия Добкина–Киркпатрика
    4. Линейное и квадратичное программирование
        1. Линейное программирование
            1. Устранение Фурье–Моцкина
            2. Алгоритм Зейделя
        2. Квадратичное программирование
    5. Алгоритм Гилберта–Джонсона–Кирти
        1. Алгоритм Гилберта–Джонсона–Кирти
        2. Нахождение точки минимальной нормы в симплексе
        3. GJK, Ближайшие точки и контактные многообразия
        4. Восхождение на холм для экстремальных вершин
        5. Использование когерентности с помощью кэширования вершин
        6. Оптимизация вращающихся объектов
        7. GJK для движущихся объектов
    6. Алгоритм разделяющих векторов Чанга–Ванга
    7. Резюме
10. # Обнаружение столкновений с помощью GPU
    1. Взаимодействие с графическим процессором
        1. Считывание буфера
        2. Запросы окклюзии
    2. Тестирование выпуклых объектов
    3. Тестирование вогнутых объектов
    4. Фильтрация столкновений на основе графического процессора
    5. Резюме
11. # Числовая устойчивость
    1. Типы проблем устойчивости
    2. Представление действительных чисел
        1. Форматы с плавающей запятой IEEE-754
        2. Бесконечная арифметика
        3. Источники ошибок с плавающей точкой
    3. Надежное использование чисел с плавающей запятой
        1. Сравнение допусков для значений с плавающей запятой
        2. Надежность за счет толстых плоскостей
        3. Надежность за счет совместного использования расчетов
        4. Надежность толстых предметов
    4. Интервальная арифметика
        1. Примеры интервальной арифметики
        2. Интервальная арифметика при обнаружении столкновений
    5. Точные и полуточные вычисления
        1. Точная арифметика с использованием целых чисел
        2. Целочисленное деление
        3. Пересечение сегментов с использованием целочисленной арифметики
    6. Дальнейшие предложения по повышению надежности
    7. Резюме
12. # Геометрическая устойчивость
    1. Вершинная сварка
    2. Вычисление информации о смежности
        1. Вычисление таблицы Vertex-to-Face
        2. Вычисление таблицы Edge-to-Face
        3. Проверка связности
    3. Дыры, Трещины, Зазоры и Т-образные переходы 
    4. Объединение копланарных граней
        1. Проверка копланарности двух многоугольников
        2. Проверка плоскостности многоугольника
    5. Триангуляция и выпуклое разбиение
        1. Триангуляция путем разрезания ушей [1](https://ru.wikipedia.org/wiki/Задача_о_триангуляции_многоугольника#Отрезание_ушей)
            1. Триангуляция многоугольников с отверстиями
        2. Выпуклая декомпозиция многоугольников
        3. Выпуклое разложение многогранников
        4. Работа с «неразложимой» вогнутой геометрией
    6. Проверка непротиворечивости с использованием формулы Эйлера
    7. Резюме
13. # Оптимизация
    1. Кеши процессора
    2. Оптимизация кэша инструкций
    3. Оптимизация кэша данных
        1. Оптимизация структуры
        2. Квантованные и сжатые данные вершин
        3. Предварительная загрузка
    4. Структуры данных и алгоритмы с учетом кеширования
        1. Компактное статическое k-d дерево
        2. Компактное дерево AABB
        3. Кеширование забывчивости
    5. Программное кеширование
        1. Пример кэшированной линеаризации
        2. Амортизированное кэширование с предсказательной линеаризацией
    6. Сглаживание
        1. Анализ псевдонимов на основе типов
        2. Ограниченные указатели
        3. Избегание сглаживаний
    7. Ветвление
    8. Резюме
14. Рекомендации
15. Индекс
16. О коде


# Введение

Это произведение посвящено теме обнаружения столкновений, широкой теме, связанной с, казалось бы, простой проблемой: обнаружение пересечения двух (или более) объектов. Обнаружение столкновений касается проблем определения того, **есть ли* соприкосновение, *когда* и *где* двух объектов. *“Есть ли”* включает установление логического результата, ответ на вопрос, пересекаются ли объекты. *“Когда”* дополнительно необходимо определить, в какое время во время движения произошло столкновение. *“Где”* устанавливает, как предметы входят в контакт. Грубо говоря, на эти три типа запросов становится все сложнее отвечать в указанном порядке. Сбор информации о том, когда и где (в дополнение к логическому результату обнаружения столкновения) иногда обозначается как *«обнаружение столкновения»*. Термины *«обнаружение пересечения»* и *«обнаружение помех»* иногда используются как синонимы «обнаружение столкновения».

Обнаружение столкновений является фундаментальным для многих разнообразных приложений, включая компьютерные игры, физическое моделирование (например, компьютерную анимацию), робототехнику, виртуальное прототипирование и инженерное моделирование (и это лишь некоторые из них). В компьютерных играх обнаружение столкновений гарантирует сохранение иллюзии твердого мира. Он не дает персонажам игроков проходить сквозь стены или проваливаться через пол; он обеспечивает запросы о прямой видимости, сообщая противникам, видят ли они игрока и, следовательно, могут ли они атаковать; и он удерживает скейтбордиста прикрепленным к невидимой направляющей поверхности, гарантируя, что игрок безопасно вернется в хафпайп после того, как поднялся в воздух.

В компьютерной анимации обнаружение столкновений используется, например, для ограничения физической симуляции ткани, чтобы одежда выглядела реалистично и не соскальзывала с персонажа при его движении. Обнаружение столкновений используется для планирования пути в робототехнике, помогая роботам избегать препятствий. В виртуальном прототипировании обнаружение столкновений помогает вычислить зазоры и в целом позволяет дорабатывать прототипы без создания физических моделей. Обнаружение столкновений используется в краш-тестах и другом инженерном моделировании.

Некоторые приложения, такие как планирование пути и рендеринг анимации, не требуют работы их систем столкновения в реальном времени. Другие приложения, в частности компьютерные игры, предъявляют особые требования к эффективности систем обнаружения столкновений в реальном времени. Экшн-игры для компьютеров и консолей включают моделирование, требующее выполнения большого количества запросов с частотой кадров от 30 до 60 кадров в секунду (fps). С такими жесткими временными ограничениями и с обнаружением столкновений, являющимся неотъемлемой частью игровых и физических движков, обнаружение столкновений может составлять большую часть времени, необходимого для создания игрового кадра. В компьютерных играх плохо спроектированная система столкновений может легко стать ключевым узким местом.

Это произведение не только об обнаружении коллизий в целом, но и конкретно об эффективной реализации структур данных и алгоритмов для решения проблем обнаружения коллизий в приложениях реального времени. В то время как область игр часто используется в качестве примеров, некоторые неигровые приложения имеют требования к производительности, аналогичные (или даже превышающие) требования к играм, включая системы тактильной (силовой обратной связи), симуляции частиц, хирургические симуляторы и другие симуляции виртуальной реальности. Описанные здесь методы одинаково хорошо применимы к этим приложениям.

Многие из обсуждаемых здесь методов применимы к областям, отличным от обнаружения столкновений. Например, методы, обсуждаемые в главах с 6 по 8, могут использоваться для ускорения трассировки лучей и их преобразования (например, для вычисления освещения сцены), а также в отношении географических информационных систем (ГИС) для ответа на запросы в больших географических базах данных. Некоторые проблемы из области компьютерной графики могут быть решены как проблемы обнаружения столкновений. Например, отсечение усеченного вида можно решить, используя методы, описанные в главах 6 и 7.

## 1.1 Обзор содержания

В следующих разделах дается краткое описание глав.

### 1.1.1 Глава 2: Проблемы проектирования обнаружения столкновений

В этой главе рассказывается о проблемах, которые необходимо учитывать при построении системы обнаружения столкновений, и о факторах, влияющих на проектирование. К таким факторам относятся то, как представлены объекты, их количество, как они перемещаются и какие типы запросов о столкновениях пользователь хочет задать. Глава 2 также знакомит с терминологией, которая используется в остальной части произведения.

### 1.1.2 Глава 3: Учебник по математике, геометрии и физике

Любая нетривиальная система обнаружения столкновений требует много математических расчетов, основанных на геометрии, чтобы определить, есть ли, когда и где для запросов столкновения. Глава 3 знакомит с математическими и геометрическими понятиями, необходимыми для понимания материала, изучаемого в остальных главах.

### 1.1.3 Глава 4: Граничные объемы

Чтобы ускорить выполнение запросов на столкновение, сначала используются простые геометрические объекты, такие как сферы и прямоугольники, для представления объектов более сложной природы. Только в случае столкновения «простых» ограничивающих объемов (которые достаточно велики для инкапсуляции сложных объектов) выполняются тесты на сложной геометрии. Глава 4 описывает несколько типов ограничивающих объемов, как выполнять для них тесты на пересечение и как подогнать ограничивающий объем к сложному объекту.

### 1.1.4 Глава 5: Базовые тесты примитивов

В предыдущей главе мы начали рассматривать тесты на пересечение. В главе 5 подробно описывается большое количество тестов для определения статуса пересечения и расстояния между парами объектов разного типа, включая линии, лучи, сегменты, плоскости, треугольники, многоугольники, сферы, параллелипипеды, цилиндры и многогранники. В этих тестах рассматриваются как статические, так и движущиеся объекты.

### 1.1.5 Глава 6: Иерархии ограничивающих объемов

Для больших объектов и для коллекций объектов повышение производительности может быть достигнуто за счет построения иерархий ограничивающих объемов над объектом (объектами). Такие иерархии обеспечивают быструю идентификацию объектов или частей объекта, которые не могут участвовать в столкновении, позволяя запросам ограничивать тестирование небольшим количеством объектов или частей объекта. В главе 6 рассказывается о желаемых характеристиках иерархий ограничивающих объёмов и способах построения и выполнения запросов к ним. В главе также исследуются эффективные способы представления этих иерархий.

### 1.1.6 Глава 7: Пространственное разбиение

Когда рассматривается большое количество объектов для столкновения, объекты должны быть разделены на небольшие непересекающиеся подгруппы для облегчения быстрых тестов (с целью избежать наихудшего квадратичного поведения тестирования всех объектов относительно всех других объектов). Иерархии ограничивающих объемов, обсуждаемые в главе 6, представляют собой один из способов выполнения такого разделения. Глава 7 исследует другие подходы к разделению, основанные на сетках, деревьях и сортировке объектов.

### 1.1.7 Глава 8: Иерархии деревьев BSP

Одной из наиболее универсальных древовидных структур для представления данных обнаружения столкновений является дерево разделения двоичного пространства (binary space partitioning, BSP). Деревья BSP можно использовать для разделения пространства независимо от объектов в пространстве. Их также можно использовать для отделения границы объекта от пространства, в котором он находится, тем самым эффективно формируя объемное представление объекта. Глава 8 рассказывает о надежном построении BSP-деревьев и о том, как выполнять тесты на полученных деревьях.

### 1.1.8 Глава 9: Основанные на выпуклости методы

Глава 9 рассматривает ряд более продвинутых методов выполнения запросов на столкновение с выпуклыми объектами, используя особые свойства выпуклых объектов. Представлены иерархические представления, алгоритм ближайших особенностей V-Clip, математические методы оптимизации линейного и квадратичного программирования, эффективный алгоритм Гилберта–Джонсона–Кирти и алгоритм разделяющих векторов Чанга и Ванга.

### 1.1.9 Глава 10: Обнаружение столкновений с помощью GPU

Обычные графические карты для ПК достигли такой степени, что обладают большей вычислительной мощностью, чем основной процессор ПК. Это изменение вызвало интерес к переложению вычислений на видеокарты. В главе 10 кратко рассказывается, как выполнять тесты обнаружения столкновений с использованием графического оборудования.

### 1.1.10 Глава 11: Числовая устойчивость

Даже самые маленькие ошибки в системе обнаружения столкновений могут привести к катастрофическим сбоям. Например: объекты не могут столкнуться со статическим пейзажем геометрии мира и, таким образом, выпадают из мира. В этой главе обсуждаются вопросы устойчивости, связанные с работой с арифметикой с плавающей запятой, и предлагаются подходы к решению этих проблем.

### 1.1.11 Глава 12: Геометрическая устойчивость

В то время как Глава 11 рассматривает, как надежно выполнять вычисления, Глава 12 рассматривает проблему взятия произвольного набора многоугольников и превращения его в хорошо сформированную геометрию, пригодную для ввода в систему обнаружения столкновений. Представлены методы сварки вершин, удаления зазоров и трещин, сращивания копланарных граней и разложения объектов на выпуклые (или треугольные) части.

### 1.1.12 Глава 13: Оптимизация

В последней главе рассказывается о том, как сделать еще более эффективными рассмотренные структуры данных и алгоритмы, нацелив и настроив их для конкретной аппаратной платформы. Значительный прирост производительности может быть достигнут за счет оптимизации кода для использования преимуществ иерархии памяти (кешей) и параллелизма кода и данных. В главе 13 представлено подробное описание того, как проводить такую оптимизацию.

## 1.2 О коде

Представленные идеи дополняются примерами кода. В то время как многие работы полагаются исключительно на высокоуровневый псевдокод для передачи общих идей алгоритма, здесь большая часть кода дается на C++. Есть две причины для представления кода в этом виде. Во-первых, он предоставляет детали, которые часто жизненно важны для понимания (и реализации) алгоритма. Во-вторых, понимание теперь можно дополнительно получить, запустив код и изучив значения переменных во время выполнения. Последнее особенно важно для читателя, который не может полностью разбираться в математике, необходимой для реализации конкретного алгоритма. Лишь в 7.1.6.1 данный код выражен псевдокодом. @TODO

C++ используется только как средство для представления подробных исполняемых алгоритмов описанных концепций. Этой цели мог бы служить любой компьютерный язык, но C++ был выбран по нескольким причинам, включая его популярность и его способность кратко абстрагироваться от низкоуровневых манипуляций с геометрическими объектами, такими как точки и векторы, с использованием классов и (перегруженных) инфиксных операторов. Чтобы сделать представленный код доступным как можно большему количеству программистов (например, тех, кто знаком только с C или Java), по возможности намеренно избегали определенных функций C++, таких как шаблоны и STL (Стандартная библиотека шаблонов). Любители C++ могут захотеть сделать несколько глубоких вдохов в начале каждой главы!

Исходя из теоремы о бесплатных завтраках, невозможно написать программу на все случаи жизни. Поэтому иллюстрируются основные идеи, и для их представления, код должен быть кратким и по существу. Были сделаны уступки, чтобы не загромождать текст подробным синтаксисом C++. Например, определения классов намеренно минималистичны (или отсутствуют), глобальные переменные иногда заменяют правильные переменные-члены, указатели не объявляются как константы (или ограничивают), а массивы часто объявляются фиксированного размера вместо того, чтобы динамически выделяться соответствующего размера. Имена переменных также были ограничены по длине, чтобы строки кода лучше вписывались на страницу набора.

Чтобы превратить представленный код в реальный производственный код, могут потребоваться некоторые дополнения. Например, тесты на деление на ноль не всегда выполняются, чтобы не вдаваться в детали, которые могут затруднить понимание общего подхода. Точно так же некоторые тесты кода могут потребовать добавления значений допуска для полной устойчивости. Цель состоит в том, чтобы обсудить надежность в главе 11, чтобы прояснить, какие изменения (если таковые имеются) необходимы для превращения представленного кода в надежный производственный код. Чтобы прояснить, какие аргументы функции являются входами, а какие - выходами, входные переменные часто передаются по значению, а выходные переменные - по ссылке. В некоторых случаях было бы более эффективно передавать входные переменные по ссылке. Это оставлено в качестве упражнения для читателя.

Комментарии набираются курсивом, а код - жирным шрифтом. Имена функций, классов, структур и определяемых пользователем типов начинаются с заглавной буквы, а переменные - с строчной буквы. Где возможно, имена переменных были выбраны в соответствии с обозначениями, используемыми в сопроводительном тексте. В некоторых случаях эти правила противоречат друг другу. Например, точки в тексте обозначаются заглавными буквами, а в коде - строчными.

Представленный в книге код реализован в большей степени в проекте Эрвина Куманса [«Bullet»](https://github.com/bulletphysics/bullet3).

# Глава 2
# Вопросы проектирования обнаружения столкновений

Проектирование эффективной системы обнаружения столкновений немного похоже на сборку головоломки: необходимо соединить множество частей, прежде чем появится общая картина. Подобным образом большая часть этого произведения посвящена изучению отдельных частей, в которых используются различные подходы к обнаружению столкновений. Общая картина станет ясной по ходу изучения. В этой главе дается краткий обзор ряда вопросов, которые необходимо учитывать при выборе подходов, и того, как соотносятся компоненты этих подходов. В этой главе также вводится ряд терминов, определения и пояснения которых будут даны в следующих главах. Более подробно затронутые здесь вопросы представлены ниже.

## 2.1 Факторы проектирования алгоритма коллизий

Есть несколько факторов, влияющих на выбор, сделанный при разработке системы обнаружения столкновений. Эти факторы будут разбиты на следующие категории:

1. *Представление области приложения*. Геометрические представления, используемые для сцены и ее объектов, имеют прямое отношение к используемым алгоритмам. С меньшими ограничениями, накладываемыми на эти представления, необходимо использовать более общие решения по обнаружению столкновений с возможными последствиями для производительности.
2. *Различные типы запросов*. Как правило, чем более подробны типы запросов и результаты, тем больше вычислительных усилий требуется для их получения. Для поддержки определенных запросов могут потребоваться дополнительные структуры данных. Не все представления объектов поддерживают все типы запросов.
3. *Параметры моделирования окружающей среды*. Само моделирование содержит несколько параметров, оказывающих непосредственное влияние на систему обнаружения столкновений. Сюда входит количество объектов, их относительные размеры и положение, перемещаются ли они и как, разрешено ли им проникать друг в друга, и являются ли они жесткими или гибкими.
4. *Производительность*. Системы обнаружения столкновений в реальном времени работают с жесткими ограничениями по времени и размеру. Поскольку время и пространство всегда являются компромиссом, несколько функций обычно сбалансированы для удовлетворения заявленных требований к производительности.
5. *Надежность*. Не все приложения требуют одинакового уровня физического моделирования. Например, укладка кирпичей друг на друга требует гораздо большей сложности от системы обнаружения столкновений, чем наличие баскетбольного мяча, подпрыгивающего на баскетбольной площадке. Мяч, отскочивший слишком рано или под несколько большим углом, останется незамеченным, но даже малейшие ошибки в вычислении точек соприкосновения сложенных кирпичей могут привести к тому, что они медленно начнут проникать друг в друга или соскальзывать друг с друга.
6. *Простота реализации и использования*. Большинство проектов выполняются в установленные сроки. Планирование функций системы обнаружения столкновений ничего не значит, если система не может быть завершена и введена в эксплуатацию вовремя. Поэтому решения относительно простоты реализации играют большую роль в выборе подхода.

Эти вопросы более подробно рассматриваются в оставшейся части главы.

## 2.2 Представление области приложения

Чтобы выбрать подходящие алгоритмы обнаружения столкновений, важно учитывать типы геометрических представлений, которые будут использоваться для сцены и ее объектов. В этом разделе вкратце рассказывается о различных представлениях объектов, о том, как упрощенную геометрию можно использовать вместо геометрии моделирования, и как знание конкретных приложений может позволить использовать специализированные решения вместо более общих решений.

### 2.2.1 Представления объектов

В большинстве современных аппаратных средств в качестве основного примитива рендеринга используются треугольники. Следовательно, *многоугольное представление* является естественным выбором для сцен и объектов сцены, а также для их соответствующей геометрии столкновения. Самым общим полигональным представлением является *буфер из полигонов*: неупорядоченный набор полигонов без информации о связности, указывающей, как один полигон связан с другим. Без каких-либо ограничений, буфер из многоугольников является привлекательным представлением для художников и дизайнеров уровней. Алгоритмы, работающие с буферами полигонов, применимы к любому набору полигонов, но, как правило, менее эффективны и менее надежны, чем те, которые полагаются на дополнительную информацию. Например, многоугольный буфер не содержит информации о «внутренней части» объекта, поэтому нет простого способа узнать, оказался ли объект каким-то образом ошибочно внутри другого объекта. Упомянутая дополнительная информация может включать в себя, какие ребра соединяются с какими вершинами и какие грани соединяются с данной гранью, образует ли объект замкнутое твердое тело и является ли объект выпуклым или вогнутым.


**Рисунок 2.1** Геометрические модели, подобные изображенной на картинке, обычно строятся из набора полигональных сеток.

Многоугольники могут быть соединены друг с другом на своих рёбрах, чтобы сформировать большую многоугольную поверхность, называемую *многоугольной сеткой*. Построение объектов из набора полигональных сеток - один из наиболее распространенных методов создания геометрических моделей (рис. 2.1).

Многоугольные объекты определяются в терминах их вершин, ребер и граней. Говорят, что при таком построении объекты имеют *явное* представление. *Неявные* объекты относятся к сферам, конусам, цилиндрам, эллипсоидам, торам и другим геометрическим примитивам, которые не определены явно таким образом, но неявно через математическое выражение. Неявные объекты часто описываются как отображение функций из трехмерного пространства в действительные числа, $f:ℝ^3→ℝ$, где точки заданы $f(x,y,z)<0$
и принадлежат объекту, $f(x,y,z)=0$ граница, и $f(x,y,z)>0$ находятся вне объекта (рисунок 2.2). Граница объекта, определяемая неявной функцией, называется неявной поверхностью. Неявные объекты могут использоваться как грубые аппроксимации объектов сцены для быстрой отбраковки. Неявная форма может позволить проводить быстрые тесты на пересечение, особенно с линиями и лучами - факт, используемый в приложениях для трассировки лучей. Несколько примеров неявных тестов приведены в главе 5.

**Рисунок 2.2** Неявно определенная сфера (где сфера определяется как граница плюс внутренняя часть).

**Рисунок 2.3** (а) Куб с цилиндрическим отверстием в нем. (b) Дерево построения CSG для левого объекта, где цилиндр вычитается из куба.

Выпуклые многоугольные объекты также можно описать как пересечение ряда полупространств. Например, куб может быть выражен как пересечение шести полупространств, каждое полупространство «обрезает» часть пространства, лежащую за пределами грани куба. Полупространства и объемы пересечений полупространств более подробно описаны в главе 3.

Геометрические примитивы, такие как сферы, параллелипипеды и цилиндры, также являются строительными блоками объектов, созданных с помощью структуры конструктивной твердотельной геометрии (constructive solid geometry, CSG). Объекты CSG рекурсивно формируются путем применения теоретико-множественных операций (таких как объединение, пересечение или различие) с основными геометрическими фигурами или другими объектами CSG, что позволяет создавать объекты произвольной сложности. Таким образом, объект CSG представлен в виде (бинарного) дерева с теоретико-множественными операциями, заданными во внутренних узлах, и геометрическими примитивами в листьях (рис. 2.3). Объекты CSG подразумевают, что вершины, ребра и грани не доступны напрямую.

Сильной стороной CSG-моделирования является то, что результирующие объекты всегда действительны - без трещин и других проблем, мешающих полигональным представлениям. CSG также является представлением объёма, что позволяет легко определить, например, находится ли точка запроса внутри объекта CSG. CSG на многогранных объектах может быть реализован с помощью процессов, описанных, например, в [Laidlaw86] и [Thibault87]. Однако может быть трудно добиться надежных реализаций из-за неточности численных расчетов.

### 2.2.2 Столкновение против геометрии рендеринга

Хотя можно передать геометрию визуализации непосредственно в систему столкновений, есть несколько причин, по которым лучше иметь отдельную геометрию, с которой выполняется обнаружение столкновений.

1. Графические платформы продвинулись до такой степени, что визуализация геометрии становится слишком сложной, чтобы ее можно было использовать для обнаружения столкновений или физики. Кроме того, обычно существует ограничение на то, насколько точными должны быть столкновения. Таким образом, вместо использования той же геометрии, которая использовалась для рендеринга, для обнаружения столкновений вместо нее можно использовать упрощенную прокси-геометрию. В играх, например, принято полагаться на простые геометрические фигуры, такие как сферы и параллелипипеды, для представления игрового объекта, независимо от сложности объекта. Если прокси-объекты сталкиваются, предполагается, что сталкиваются и фактические объекты. Эти простые геометрические формы или *ограничивающие объемы* часто используются для ускорения запросов на столкновение независимо от того, какое геометрическое представление используется. Ограничивающие объемы обычно делаются так, чтобы полностью заключить геометрию. Граничные объемы подробно обсуждаются в Главе 4.

2. Для современного оборудования геометрия, как правило, задается в очень специфических форматах (таких как полосы треугольников и индексированные буферы вершин), которые позволяют быстро рендерить, но не обнаруживают столкновения. Вместо того, чтобы декодировать эти структуры на лету (даже если декодированные данные можно кэшировать для повторного использования), обычно более эффективно предоставить специальную геометрию столкновения. Кроме того, графическое оборудование часто поддерживает форматы только для треугольников. Для геометрии столкновения эффективность иногда может быть достигнута за счет поддержки других, нетреугольных примитивов.

3. Необходимые данные и организация данных для геометрии рендеринга и геометрии столкновений, вероятно, сильно различаются. В то время как данные статического рендеринга могут быть отсортированы по материалам, данные о столкновениях обычно организованы пространственно. Для визуализации геометрии требуются встроенные данные, такие как информация о материале, цвета вершин и координаты текстуры, тогда как геометрия столкновений требует связанных свойств поверхности. Разделение этих двух и хранение всей информации, относящейся к столкновениям, уменьшает данные о столкновении. Меньшие данные, в свою очередь, приводят к повышению эффективности за счет большей согласованности кэша данных.

4. Иногда геометрия столкновения отличается от визуализированной геометрии конструктивно. Например, снег по колено для игры сноуборд можно смоделировать с помощью поверхности столкновения на полметра ниже визуализированного представления поверхности снега. Аналогичным образом можно поступить с ходьбой по колышущейся траве по щиколотку или по мутной воде по пояс. Даже если геометрия визуализации используется в качестве геометрии столкновения, должны быть предусмотрены условия для исключения некоторой геометрии визуализации из (и для включения дополнительной геометрии без визуализации в) набор данных геометрии столкновения.

5. В целях моделирования данные о столкновениях должны храниться, даже если данные визуализации могут быть выброшены как невидимые. Поскольку геометрия столкновения меньше, чем соответствующая геометрия рендеринга, таким образом уменьшается объем постоянной памяти.

6. Исходная геометрия может быть представлена в виде полигонального буфера или сетки, тогда как для моделирования требуется представление твердотельного объекта. В этом случае гораздо проще вычислить твердую прокси-геометрию, чем пытаться каким-то образом укрепить исходное геометрическое представление.

Однако у использования раздельной геометрии столкновений есть некоторые потенциальные недостатки.

1. Дублирование данных (в основном вершин) приводит к использованию дополнительной памяти. Эту проблему можно облегчить, создав часть или всю геометрию столкновения из геометрии рендеринга на лету с помощью кэширования линеаризации (как описано в Разделе 13.5 и далее).

2. Для изготовления и поддержания двух наборов одинаковой геометрии может потребоваться дополнительная работа. Построение прокси-геометрии вручную ухудшит график ее создания. Если он построен с помощью инструмента, этот инструмент должен быть написан до того, как система столкновений станет пригодной для использования. Кроме того, если есть необходимость вручную изменить выходные данные инструмента, изменения необходимо каким-то образом передать обратно в инструмент и исходный набор данных.

3. Если они построены и поддерживаются отдельно, геометрия рендеринга и коллизий может не совпадать в разных местах. Когда геометрия столкновения не заполняет тот же объем, что и геометрия визуализации, объекты могут частично исчезать или парить над поверхностью других объектов.

4. Версии и другие проблемы логистики могут проявиться для двух геометрий. Была ли геометрия столкновения действительно перестроена при изменении геометрии рендеринга? Если создается вручную, что будет первым: геометрия столкновения или геометрия визуализации? И как вы обновляете одно, когда другое меняется?

Для игр достаточно хорошо работает использование прокси-геометрии, которая близка (но может не совсем соответствовать) реальным визуальным эффектам. С точки зрения восприятия люди не очень хорошо определяют, происходят ли точные столкновения. Чем больше задействовано объектов и чем быстрее они движутся, тем меньше вероятность того, что игрок заметит какие-либо несоответствия. Люди также плохо умеют предсказывать, каким должен быть исход столкновения, что позволяет проявлять вольность и при реагировании на столкновение. В играх обнаружением столкновений и реагированием на них можно эффективно управлять по принципу «если все выглядит правильно, значит, правильно». Другие приложения предъявляют более строгие требования к точности.

### 2.2.3 Специализация алгоритмов столкновений

Вместо того, чтобы иметь одну всеобъемлющую систему обнаружения столкновений, часто бывает целесообразно предоставить специализированные системы столкновений для конкретных сценариев. Примером того, где важна специализация, являются столкновения частиц. Вместо того, чтобы отправлять частицы одну за другой через обычную систему столкновений, они лучше обрабатываются и отправляются на столкновение как группы частиц, где группы могут формироваться и преобразовываться в зависимости от контекста. Частицы могут быть даже исключены из столкновения, в тех случаях, когда отсутствие столкновения не заметно.

Другой пример - использование отдельных алгоритмов для обнаружения столкновения между объектом и другими объектами, а также между объектом и сценой. Столкновения объект-объект могут быть даже дополнительно специализированы, чтобы персонаж игрока и быстро движущиеся снаряды обрабатывались иначе, чем другие объекты. Например, случай, когда все объекты всегда сталкиваются с персонажем игрока, лучше рассматривать как жестко запрограммированный тест, а не вставлять персонажа игрока в общую систему столкновений.

Рассмотрим также моделирование больших миров. Для маленьких миров данные о столкновениях могут всегда храниться в памяти. Однако в большом бесшовном мире данные о столкновениях должны загружаться и выгружаться по мере прохождения мира. В последнем случае наличие объектов, отделенных от мировой структуры, снова является привлекательным выбором, поэтому на объекты не влияют изменения мировой структуры. Возможный недостаток наличия отдельных структур для хранения, скажем, объектов и мира, заключается в том, что теперь выполнение запросов влечет за собой обход двух структур данных, а не только одной.

## 2.3 Типы запросов

Самый простой запрос на столкновение - это проблема *обнаружения пересечения* или *проверки пересечения*: ответ на логический вопрос о том, перекрываются ли два (статических) объекта, A и B, в их заданных положениях и ориентациях. Логические запросы пересечения быстро и легко реализовать, поэтому они широко используются. Однако иногда логического результата недостаточно и необходимо найти пересекающиеся части. Проблема *поиска пересечений* является более сложной, поскольку включает поиск одной или нескольких точек соприкосновения.

Для некоторых приложений достаточно найти какую-либо общую точку между объектами. В других случаях, например, при моделировании твердого тела, может потребоваться определение набора точек соприкосновения, то есть *контактного коллектора*. Надежное вычисление контактного многообразия - сложная задача. В целом, с *приблизительными запросами*, ответы на которые требуются только с точностью до заданного допуска, гораздо проще иметь дело, чем с *точными запросами*. Примерные запросы - обычное дело в играх. Кроме того, в играх запросы о столкновении обычно требуются для сообщения определенных свойств столкновения, назначенных объектам и их границам. Например, такие свойства могут включать скользкость дорожного покрытия или способность преодолевать подъем по поверхности стены.

Если объекты проникают, некоторые приложения требуют определения *глубины проникновения*. Глубина проникновения обычно определяется как *минимальное поступательное расстояние*: длина самого короткого вектора движения, который разделял бы объекты. В общем, вычисление этого вектора движения - сложная задача. *Расстояние разделения* между двумя непересекающимися объектами A и B определяется как минимум расстояний между точками в A и точками в B. Когда расстояние равно нулю, объекты пересекаются. Измерение расстояния между двумя объектами полезно, так как позволяет прогнозировать следующее столкновение. Более общая проблема заключается в нахождении *ближайших точек* к A и B: точки в A и точки в B, определяющих расстояние между объектами. Обратите внимание, что ближайшие точки не обязательно уникальны; может быть бесконечное количество ближайших точек. Для динамических объектов вычисление следующего времени столкновения известно как расчет *предполагаемого времени прибытия* (estimated time of arrival, ETA) или *времени столкновения* (time of impact, TOI). Значение ETA можно использовать, например, для управления временным шагом при моделировании твердого тела. Тип движения - один из параметров моделирования, обсуждаемых далее в следующем разделе.

## 2.4 Параметры моделирования окружающей среды

Как упоминалось ранее в этой главе, несколько параметров моделирования напрямую влияют на то, что является подходящим выбором для системы обнаружения столкновений. Чтобы проиллюстрировать некоторые из проблем, которые они могут вызвать, в следующих разделах конкретно рассматривается, как количество объектов и их перемещение связаны с обработкой столкновений.

### 2.4.1 Количество объектов

Поскольку любой объект потенциально может столкнуться с любым другим объектом, требуется симуляция с n объектами (n−1)+(n−2)+...+1=n(n−1)/2=O(n<sup>2</sup>) попарных тестов,
худший случай. Из-за квадратичной временной сложности наивное тестирование каждой пары объектов на столкновение быстро становится слишком дорогостоящим даже при умеренных значениях n. Снижение затрат, связанных с парным тестом, только линейно повлияет на время выполнения. Чтобы действительно ускорить процесс, необходимо уменьшить количество тестируемых пар. Это сокращение выполняется путем разделения обработки столкновений нескольких объектов на две фазы: *широкую фазу (broad phase)* и *узкую фазу (narrow phase)*.

На широкой фазе определяются более мелкие группы объектов, которые *могут* сталкиваться, и быстро исключаются те, которые определенно *не сталкиваются*. Узкая фаза представляет собой попарные тесты внутри подгрупп. Он отвечает за определение точных столкновений, если таковые имеются. Широкую и узкую фазы иногда называют обработкой n тел и парной обработкой соответственно.

На рисунке 2.4 показано, как широкофазная обработка снижает рабочую нагрузку за счет стратегии «разделяй и властвуй» (divide-and-conquer). Для 11 объектов (показаны прямоугольниками) для теста всех пар потребуется 55 тестов отдельных пар. После того, как обработка в широкой фазе дала 5 непересекающихся подгрупп (обозначенных заштрихованными областями), в узкой фазе нужно будет выполнить только 10 индивидуальных парных тестов. Методы обработки с широкой фазой обсуждаются в главах с 6 по 8. Обработка с узкой фазой рассматривается в главах 4, 5 и 9.

**Рисунок 2.4** На широкой фазе определяются непересекающиеся группы возможно пересекающихся объектов.

Помимо количества объектов, относительный размер объектов также влияет на количество тестов, которые необходимо выполнить. Когда в сцене присутствуют как маленькие, так и большие объекты, широкофазная система обычно должна работать усерднее (или быть более сложной) для идентификации групп, чем для набора однородных по размеру объектов. Как размер объекта влияет на широкофазовые методы, обсуждается далее в главе 7.

### 2.4.2 Последовательное или одновременное движение

В реальной жизни объекты движутся *одновременно* в течение заданного временного шага движения, и любые возможные столкновения разрешаются за этот временной шаг. Для точного компьютерного моделирования реального события необходимо каким-то образом определить самое раннее время контакта между любыми двумя движущимися объектами. Затем симуляцию можно продвинуть до этого момента времени, переместив все объекты в положение, в котором они были бы, когда произойдет первое столкновение. Затем столкновение разрешается, и процесс продолжает определять следующее столкновение, повторяя его до тех пор, пока не будет использован весь временной шаг движения.

Выполнение моделирования путем многократного перехода к следующему наиболее раннему моменту контакта становится довольно дорогостоящим. Например, когда один или несколько объектов упираются в поверхность, следующее столкновение происходит почти сразу после текущего времени столкновения. Таким образом, симуляция продвигается лишь на небольшую часть, и для определения полного временного шага перемещения может потребоваться практически «вечность». Одно из решений этой проблемы - использовать широкую фазу для идентификации групп объектов, которые могут взаимодействовать внутри группы, но не с объектами других групп в течение временного шага. Таким образом, моделирование каждой группы может выполняться с разной скоростью, помогая облегчить проблему в целом.

**Рисунок 2.5** (a) Вверху: Если оба объекта движутся одновременно, столкновения нет. Внизу: если круговой объект перемещается раньше треугольником, объекты сталкиваются. В (b) снова нет столкновения для одновременного движения, но для последовательного движения объекты сталкиваются. (c) объекты сталкиваются при одновременном движении, но не при последовательном движении.

Альтернативный вариант - перемещать объекты одновременно, но с фиксированным (маленьким) шагом по времени для перемещения. Одновременное движение может привести к взаимопроникновению объектов, с чем обычно нужно как-то бороться, например, путем резервного копирования моделирования в более раннее состояние. В обоих случаях одновременные обновления остаются дорогостоящими и поэтому часто используются для точного моделирования твердого тела. Однако многие игры, как и другие приложения, не являются симуляциями твердого тела, и было бы излишним и потраченным впустую попытки имитировать движение с высокой точностью. Для них альтернативным вариантом является *последовательное* разрешение движения. То есть объекты перемещаются по одному объекту за раз, и любые столкновения обнаруживаются и разрешаются до того, как процесс продолжится со следующим объектом.

Ясно, что последовательное движение не является физически точной моделью движения. Некоторые объекты могут столкнуться с объектами, которые еще не двигались в этом кадре, но которые бы сдвинулись с места, если бы два объекта двигались одновременно (рис. 2.5a). Другие объекты могут столкнуться с объектами, которые двигались раньше, а теперь находятся на их пути (рис. 2.5b). В некоторых случаях, когда два одновременно движущихся объекта столкнулись бы на полпути своего движения, столкновения теперь будут пропускаться, поскольку один объект перемещается мимо другого (рис. 2.5c). В играх, например, проблемы, связанные с моделью последовательного движения, часто можно игнорировать. Высокая частота кадров в играх часто делает шаг движения настолько маленьким, что перекрытие также невелико и не очень заметно.

Одним из преимуществ модели последовательного движения является то, что инвариант непроникания объекта очень легко поддерживать. Если во время движения объекта происходит столкновение, движение можно просто отменить (например). Только необходимость отменить движение одного объекта следует противопоставить модели одновременного движения с фиксированным временным шагом, в которой движение всех одновременно перемещаемых объектов должно быть отменено.

### 2.4.3 Дискретное и непрерывное движение

То, что может сильно повлиять как на вычислительные усилия, необходимые для определения результата столкновения, так и на точность самого результата, заключается в том, что два объекта, участвующие в парном тесте, движутся во время тестирования. *Обнаружение статического столкновения* включает обнаружение пересечения между объектами в дискретные моменты времени во время их движения. В каждый такой момент времени объекты обрабатываются так, как если бы они были неподвижны в своих текущих положениях с нулевой скоростью. Напротив, *динамическое обнаружение столкновений* учитывает полное непрерывное движение объектов в течение заданного интервала времени. Динамические тесты столкновения обычно могут сообщать точное время столкновения и точку (точки) первого контакта. Статические тесты (намного) дешевле, чем динамические, но интервалы времени между тестами должны быть короткими, чтобы движение объектов было меньше пространственной протяженности объектов. В противном случае объекты могут просто переходить друг друга от одного временного шага к следующему без обнаружения столкновения. Это явление называется *туннелированием*.

Объем, покрываемый объектом, непрерывно движущимся за заданный промежуток времени, называется *охватываемым объемом (swept volume)*. Если эти объемы двух движущихся объектов не пересекаются, значит, между объектами нет пересечения. Даже если охватываемые объемы пересекаются, объекты могут не пересекаться во время движения. Таким образом, пересечение охватываемых объемов является достаточным, но не необходимым условием столкновения объектов. Для сложных движений охватываемый объем сложно вычислить и с ним работать. К счастью, идеальная точность требуется редко. Динамическое испытание на столкновение сложных опрокидывающихся движений обычно можно упростить, допустив кусочно-линейное движение; то есть линейное перемещение по диапазону движения с мгновенным вращением в конце (или начале) движения. Где-то между этими двумя альтернативами находится замена неограниченного движения винтовым движением (то есть фиксированным вращательным и поступательным движением).

При работе с движущимися объектами практически всегда предпочтительно учитывать относительное движение объектов, вычитая движение одного объекта из другого объекта, таким образом фактически оставляя один объект статичным. Предполагая линейное поступательное движение для объектов, эта операция представляет собой простое вычитание вектора. Ключевым преимуществом рассмотрения только относительного движения является то, что для тестирования одного движущегося объекта относительно неподвижного объекта тест с охватываемым объемом теперь является тестом на точное пересечение. В играх весь охватываемый объем иногда просто заменяется *скоростным коробкой*: продолговатым прямоугольником, закрывающим весь диапазон движения объекта (или каким-либо аналогичным простым прокси-объектом, не обязательно прямоугольником).

## 2.5 Производительность

Если взять в качестве примера игровые приставки, для получения наилучших визуальных эффектов игры должны работать со скоростью 60 кадров в секунду (в странах с форматом NTSC TV; 50 кадров в секунду на территории PAL). Эта частота кадров оставляет 16,7 мс для подготовки каждого игрового кадра. В зависимости от типа игры обнаружение столкновений может составлять, скажем, от 10 до 30% кадра, в свою очередь оставляя от 2 до 5 мс для обнаружения столкновений. Для платформенной игры, в которой могут быть десятки объектов, зависящих от столкновений, активных в данный момент времени, для обработки столкновения для каждого объекта может быть доступно только от 50 до 250 мкс - это немного времени. Ясно, что очень важно уменьшить среднее время выполнения запросов на столкновение. Однако, поскольку в играх очень заметны большие внезапные падения частоты кадров, также важно убедиться, что худший случай для выбранных алгоритмов не занимает больше времени, чем в среднем.

Можно сделать несколько вещей, чтобы ускорить обработку столкновений, чему в значительной степени и посвящена это произведение. Некоторые общие идеи относительно того, какие оптимизации важны для обнаружения столкновений, обсуждаются в следующем разделе.

### 2.5.1 Обзор оптимизации

Первый принцип оптимизации заключается в том, что нет ничего быстрее, чем вообще не выполнять задачу. Таким образом, некоторые из наиболее успешных оптимизаций скорости вращаются вокруг как можно более быстрого сокращения объема работы до минимально возможного. Таким образом, одной из наиболее важных оптимизаций для системы обнаружения столкновений является широкая фаза обработки, упомянутая в разделе 2.4.1, то есть использование пространственной локализации объектов. Поскольку объекты могут поражать только те предметы, которые находятся рядом с ними, испытаний с удаленными объектами можно избежать, разбив их по пространству. Затем тесты производятся только в отношении областей, расположенных непосредственно рядом с объектом, игнорируя те, которые находятся слишком далеко, чтобы пересекать объект. Есть сильное сходство между этим пространственным разделением и тем, что сделано для отсечения вида, чтобы ограничить количество нарисованных графических объектов.

Пространственное разделение может быть выполнено с использованием плоской структуры, например, путем разделения пространства на сетку ячеек одинакового размера. Это также может быть реализовано в терминах иерархии, где пространство рекурсивно делится пополам, пока не будет достигнута некоторая цель завершения. Затем объекты вставляются в сетку или иерархию. Сетки и иерархическое разбиение также полезны для парных тестов узкой фазы, особенно когда объекты имеют высокую сложность. Вместо того, чтобы тестировать один объект против другого, они позволяют ограничить тесты столкновений частями двух ближайших друг к другу объектов. Объектное и пространственное разбиение обсуждается в главах 6 и 7.

Проведение недорогих тестов ограничивающего объема перед выполнением более дорогих геометрических тестов также является хорошим способом сократить объем работы, необходимой для определения столкновения. Скажем, охватывающие ограничивающие сферы были добавлены ко всем объектам, тогда простой тест на пересечение сфер со сферами теперь покажет - когда сферы не перекрываются - что дальнейшее тестирование сложной содержащейся геометрии не требуется. Граничные объемы рассматриваются в главе 4.

Понимание того, что объекты имеют тенденцию делать небольшие локальные шаги от кадра к кадру - если они вообще перемещаются - приводит к третьей важной оптимизации: использовать эту *временную (или от кадра к кадру) когерентность*. Например, нужно тестировать только объекты, которые переместились с момента последнего кадра; статус столкновения остается таким же для других объектов. Временная когерентность также может позволить кэшировать данные и вычисления и повторно использовать их в одном или нескольких будущих кадрах, что ускоряет тесты. Предположения, основанные на согласованности движений, очевидно, становятся недействительными, если объектам разрешено «телепортироваться» в произвольные места. Согласованность более подробно обсуждается в главе 9.

Наконец, очень важны оптимизации для конкретной архитектуры. Многие платформы поддерживают некоторый тип кода или параллелизм данных, которые при полном использовании могут обеспечить значительное ускорение. Из-за больших различий между скоростью, с которой работают ЦП, и скоростью, с которой основная память может предоставлять данные для работы (с преимуществом скорости для ЦП), то, как геометрия столкновений и другие данные хранятся в памяти, также может иметь огромное влияние скорости на систему столкновения. Эти вопросы подробно рассматриваются в главе 13.

## 2.6 Надежность

Обнаружение столкновений - одно из множества геометрических приложений, для которых очень важна надежность. Здесь надежность используется просто для обозначения способности программы работать с численными вычислениями и геометрическими конфигурациями, с которыми в некотором роде трудно справиться. Столкнувшись с такими проблемными входными данными, надежная программа дает ожидаемые результаты. Ненадежная программа может в тех же ситуациях аварийно завершиться или зайти в бесконечный цикл. Проблемы устойчивости можно в общих чертах разделить на два класса: проблемы, связанные с отсутствием *числовой устойчивости*, и проблемы, связанные с отсутствием *геометрической устойчивости*.

Проблемы числовой устойчивости возникают из-за использования переменных конечной точности во время вычислений. Например, когда промежуточные вычисления становятся больше, чем может быть представлено переменной с плавающей точкой или целым числом, промежуточный результат будет недействительным. Если такие проблемы не обнаружены, окончательный результат вычисления также может быть неверным. Надежные реализации должны гарантировать невозможность возникновения таких проблем, или если они это сделают, вместо них будут возвращены скорректированные действительные результаты.

Геометрическая устойчивость влечет за собой обеспечение топологической правильности и общей геометрической согласованности. Проблемы часто связаны с невозможной или вырожденной геометрией, что может быть результатом неправильного численного расчета. Большинство алгоритмов на том или ином уровне ожидают правильно сформированных входных данных. Если задана неправильная входная геометрия, например, треугольники, вырождающиеся в точку, или многоугольники, не все вершины которых лежат в плоскости, может произойти что угодно, если эти случаи не будут обнаружены и рассмотрены.

Иногда трудно провести различие между числовой и геометрической надежностью, поскольку одно может порождать другое. Чтобы избежать неясных и трудно исправляемых ошибок времени выполнения, надежность должна рассматриваться как при проектировании, так и при разработке системы обнаружения столкновений. В главах 11 и 12 устойчивость обсуждается более подробно.

## 2.7 Простота реализации и использования

В случае внедрения системы обнаружения столкновений с нуля вопрос ожидаемого времени разработки может быть столь же важным, как и желаемый набор функций. Например, игры часто имеют ограниченный бюджет и временные рамки, и задержка любого критического компонента может дорого обойтись. При оценке простоты реализации интересно посмотреть не только на общую сложность алгоритма, но и на то, сколько и какого типа особые случаи задействованы, сколько задействованных переменных настройки (таких как числовые допуски) и другие ограничения, которые могут повлиять на время разработки.

Несколько дополнительных вопросов связаны с использованием системы обнаружения столкновений. Например, насколько общая система? Может ли она работать с объектами самых разных размеров? Может ли она также отвечать на различные запросы? Сколько времени требуется в процессе сборки для создания структур данных, связанных с конфликтами? Что касается последнего вопроса, хотя время, затрачиваемое на предварительную обработку, не имеет значения для производительности во время выполнения, оно все ещё важно на этапе проектирования и производства. В процессе разработки модели часто меняются, а длительное время предварительной обработки снижает производительность и затрудняет экспериментирование. Некоторые из этих вопросов можно решить, допустив более быстрое и менее оптимизированное построение структуры данных во время разработки, а также более медленное, но более оптимальное построение для неотладочных сборок.

### 2.7.1 Отладка системы обнаружения столкновений

Как и весь код, системы обнаружения столкновений подвержены ошибкам. Поиск этих ошибок иногда может быть трудным и требовать много времени. Во время разработки можно предпринять шаги, чтобы сделать этот процесс отладки менее болезненным. Вот несколько хороших идей:

- Храните циклический буфер аргументов для n последних запросов о конфликте, соответствующих данным за несколько секунд (или больше). Затем, когда что-то пойдет не так, программа может быть приостановлена, а данные могут быть выведены для дальнейшего анализа, например, для пошагового выполнения вызовов с сохраненными аргументами. Регистрируемые данные также могут предоставить полезную информацию при срабатывании утверждения.
- Предоставьте средства для визуализации геометрии столкновения. Например, вы можете визуализировать проверенные поверхности, их атрибуты столкновения, а также любые иерархии и группировки поверхностей. Кроме того, визуализируйте сами запросы на столкновение, предпочтительно с историей, предоставленной циклическим буфером, упомянутым ранее. Эта визуализация обеспечивает контекст, который позволяет легко выявлять неверные запросы на столкновение.
- Реализуйте простой *эталонный алгоритм* (например, алгоритм перебора, который проверяет все объекты или все полигоны относительно друг друга) и запускайте эталонный алгоритм параллельно с более сложным алгоритмом. Если результаты различаются, есть проблема (по всей видимости, с более продвинутым алгоритмом).
- Поддерживайте набор тестов и запускайте код столкновения с набором тестов при изменении кода. Код геометрической природы, как правило, имеет множество особых случаев, и наличие набора всеобъемлющих тестов помогает в раннем обнаружении проблем. Каждый раз, когда обнаруживается ошибка, добавляйте тестовые примеры, чтобы определить, появляется ли она когда-либо повторно.

Конечно, также применимы все общие стратегии отладки, такие как использование вызовов **assert()**. Хорошее обсуждение таких стратегий можно найти в [McConnell93,
Глава 26].

## 2.8 Резюме

В этой главе описаны многие факторы, которые необходимо учитывать при разработке и внедрении системы обнаружения столкновений. В нем говорилось о возможных представлениях геометрии столкновений и о том, следует ли использовать геометрию рендеринга или специальную геометрию для выполнения тестов столкновений. Обработка коллизий была определена как происходящая в два этапа: узкую и широкую. Широкая фаза связана с грубым определением небольших подгрупп потенциально сталкивающихся объектов, тогда как узкая фаза выполняет подробные тесты парных столкновений между объектами. Узкофазное тестирование является основной темой глав 4 и 5, где обсуждается множество различных типов запросов для самых разных геометрических представлений объектов. Узкофазное тестирование также обсуждается в главе 9. Широкофазовые методы обсуждаются в главах с 6 по 8. Была подчеркнута важность устойчивости. В этом произведении две полные главы посвящены теме устойчивости, главы 11 и 12. Поскольку изучается обнаружение столкновений для приложений реального времени, производительность также была подчеркнута как важное системное соображение. В некотором смысле большая часть посвящена производительности, поскольку на протяжении всего ее обсуждения обсуждаются эффективные алгоритмы и структуры данных. В главе 13 обсуждаются оптимизации.


# Глава 3
# Учебник по математике, геометрии и физике

## 3.1 Матрицы
### 3.1.1 Матричная арифметика
### 3.1.2 Алгебраические тождества с матрицами
### 3.1.3 Детерминанты
### 3.1.4 Решение малых систем линейных уравнений с помощью правила Крамера 
### 3.1.5 Обращение матриц для матриц 2 × 2 и 3 × 3
### 3.1.6 Детерминантные предикаты
#### 3.1.6.1 ORIENT2D(A, B, C )
#### 3.1.6.2 ORIENT3D(A, B, C, D)
#### 3.1.6.3 INCIRCLE2D(A, B, C, D)
#### 3.1.6.4 INSPHERE(A, B, C, D, E )
## 3.2 Системы координат и точки

В современной математике *точка* обычно относится к элементу некоторого множества, называемому пространством. Единственная её характеристика - расположение, которое описано в терминах *системы координат*, задается опорной точкой, называемой *началом координат* (origin), а также рядом *осей координат*. Каждая точка в n-мерной системе координат задается набором (tuple) $n$ действительных чисел $(x_1, x_2, ..., x_n )$. Набор из $n$ чисел называется *координатой точки*. Точка, описываемая кортежем из $n$, - это точка, которую можно достичь, начиная с начала координат и совершая *перемещения* на $x_1$ единиц по первой координатной оси, $x_2$ единицы по второй координатной оси и так далее для всех заданных чисел. Начало координат - это точка со всеми нулевыми компонентами $(0, 0, ..., 0)$. Система координат может быть задана относительно родительской системы координат, и в этом случае начало подчиненной системы координат может соответствовать любой точке в родительской системе координат.

Наибольший интерес представляет *декартова (или прямоугольная) система координат*, в которой оси координат перпендикулярны друг другу. Для двухмерного пространства две оси координат условно обозначаются как ось $x$ и ось $y$. В трехмерном пространстве третья координатная ось называется осью $z$.

*Координатное пространство* - это набор точек, которые может указывать система координат. Говорят, что система координат охватывает это пространство. Данный набор координатных осей, охватывающий пространство, называется *системой отсчета* или *базисом* для пространства. Существует бесконечно много систем отсчета для данного координатного пространства.

Здесь точки обозначаются прописными буквами курсивом (например, P, Q и R). Как обсуждается в следующем разделе, точки тесно связаны с векторами.

## 3.3 Векторы
### 3.3.1 Векторная арифметика
### 3.3.2 Алгебраические тождества с векторами
### 3.3.3 Скалярное произведение
### 3.3.4 Алгебраические тождества скалярных произведений
### 3.3.5 Векторное произведение
### 3.3.6 Алгебраические тождества векторых произведений
### 3.3.7 Тройное скалярное произведение
### 3.3.8 Алгебраические тождества тройных скалярных произведений
## 3.4 Барицентрические координаты
## 3.5 Линии, лучи и сегменты
## 3.6 Плоскости и полупространства
## 3.7 Многоугольники
### 3.7.1 Проверка многоугольной выпуклости
## 3.8 Многогранники
### 3.8.1 Проверка многогранной выпуклости
## 3.9 Вычисление выпуклой оболочки
### 3.9.1 Алгоритм Эндрю
### 3.9.2 Алгоритм Quickhull
## 3.10 Регионы Вороного
## 3.11 Сумма Минковского и разность

## 3.12 Физические основы механики

**Механика** — раздел физики, изучающий закономерности механического движения, причины, вызывающие или изменяющие это движение.

**Механическое движение** — это изменение с течением времени взаимного расположения тел или их частей.

В классической механике рассматривают пространство и время как объективные формы существования материи, но в отрыве друг от друга и от движения материальных тел.

Механика делится на три раздела:

- **Кинематика** изучает движение тел, не рассматривая причины, которые это движение обусловливают.
- **Динамика** изучает законы и причины, которые вызывают или изменяют движения тел.
- **Статика** изучает законы равновесия системы тел. Если известны законы движения тел, то из них можно установить и законы равновесия. Поэтому законы статики отдельно от законов динамики физика не рассматривает.

### 3.12.1 Модели в кинематике

В механике для описания движения тел в зависимости от задач используются разные **физические модели**. Самая простая модель это **материальная точка** — тело, обладающее массой, размерами которого в данной задаче можно пренебречь. Например, изучая движение планет по орбитам вокруг Солнца, можно принять их за материальные точки.

Любое тело можно рассматривать как множество малых взаимодействующих между собой частиц, каждая из которых может быть представлена материальной точкой, получается **система материальных точек**.

Абсолютно **твердое тело** (rigid body) - система материальных точек, в которой не изменяется расстояние между любыми двумя точками, то есть характеризуется ограничением расстояния.

Любое движение твердого тела можно представить как комбинацию поступательного и вращательного движений. **Поступательное движение** — это движение, при котором любая прямая, жестко связанная с движущимся телом, остается параллельной своему первоначальному положению. **Вращательное движение** — это движение, при котором все точки тела движутся по окружностям, центры которых лежат на одной и той же прямой, называемой **осью вращения**.

#### 3.12.1.1 Система отсчета.

Движение тел происходит в пространстве и во времени. Поэтому для описания движения модели надо знать, в каких местах пространства она находилась.

Положение материальной точки определяется по отношению к какому-либо другому, произвольно выбранному телу, называемому **телом отсчета**. С ним связывается **система отсчета** — совокупность системы координат и часов. В декартовой системе координат, используемой наиболее часто, положение точки *А* в данный момент времени по отношению к этой системе характеризуется тремя координатами $х$, $у$ и $z$ или радиусом-вектором $\vec r$, проведенным из начала системы координат в данную точку.

![](1.files/image001.jpg)

#### 3.12.1.2 Траектория, длина пути, вектор перемещения

При движении материальной точки ее координаты с течением времени изменяются. В общем случае ее движение определяется скалярными уравнениями

$$\begin{cases}x=x(t),\\y=y(t),\\z=z(t)\end{cases} (1)$$

эквивалентными векторному уравнению $\vec r = \vec r(t)$

$$\vec r = \vec r(t). (2)$$

Уравнения (1) (соответственно (2)) называются **кинематическими уравнениями движения материальной точки**. 

![](1.files/image003.jpg)(: $r_B, r_A$ :)

**Рисунок 3.12.2** Движение материальной точки вдоль произвольной траектории

Число независимых координат, полностью определяющих положение точки в пространстве, называется **числом степеней свободы**: 
- Если материальная точка свободно движется в пространстве, то она обладает тремя степенями свободы (координаты $х$, $у$ и $z$ );
- Если она движется по поверхности, то — двумя степенями свободы;
- Если вдоль некоторой линии, то — одной степенью свободы.

Исключая $t$ в уравнениях (1) и (2), получим уравнение траектории движения материальной точки. **Траектория** движения материальной точки — линия, описываемая этой точкой в пространстве. В зависимости от формы траектории движение может быть **прямолинейным** или **криволинейным**.

Рассмотрим движение материальной точки вдоль произвольной траектории (Рисунок 3.12.2). Отсчет времени начнем с момента, когда точка находилась в положении *А*. Длина участка траектории *АВ*, пройденного материальной точкой с момента начала отсчета времени, называется **длиной пути** $\Delta s$ и является скалярной функцией времени: $\Delta s = \Delta s ( t )$. Вектор $\Delta \vec r = \vec r_B - \vec r_A$ , проведенный из начального положения движущейся точки в положение ее в данный момент времени (приращение радиуса-вектора точки за рассматриваемый промежуток времени), называется **перемещением**. 

При прямолинейном движении вектор перемещения совпадает с соответствующим участком траектории и модуль перемещения $\mid \Delta \vec r \mid$ равен пройденному пути $\Delta s$ .

#### 3.12.1.3 Скорость

Для характеристики движения материальной точки вводится векторная величина — скорость, которой определяется как *быстрота* движения, так и его *направление* в данный момент времени.

Пусть материальная точка движется по какой-либо криволинейной траектории так, что в момент времени $t$ ей соответствует радиус-вектор $r_A$ (рис. 3). В течение малого промежутка времени $\Delta t$ точка пройдет путь $\Delta s$ и получит элементарное (бесконечно малое) перемещение $\Delta r$ .

**Вектором средней скорости** $\langle v \rangle$ называется отношение приращения $\Delta r$ радиуса-вектора точки к промежутку времени $\Delta t$ :
$$\langle \vec{v} \rangle = \frac { \Delta \vec r }{\Delta t}. (1)$$ 

Направление вектора средней скорости совпадает с направлением $\Delta \vec r$ . При неограниченном уменьшении $\Delta t$ средняя скорость стремится к предельному значению, которое называется **мгновенной скоростью v** :

$$\vec v = \lim_{\Delta t \to 0}\frac{\Delta \vec r}{\Delta t} = \frac{d \vec r}{dt} .$$

Мгновенная скорость $\vec v$ , таким образом, есть векторная величина, равная первой производной радиуса-вектора движущейся точки по времени. Так как секущая в пределе совпадает с касательной, то вектор скорости $\vec v$ направлен по касательной к траектории в сторону движения (рисунок 3). По мере уменьшения $\Delta t$ путь $\Delta s$ все больше будет приближаться к $\mid\Delta \vec r \mid$, поэтому модуль мгновенной скорости

$$v=\mid\vec v\mid=\mid\lim_{\Delta t \to 0}\frac{\Delta \vec r}{\Delta t}\mid=\lim_{\Delta t \to 0}\frac{\mid\Delta \vec r\mid}{\Delta t}=\lim_{\Delta t \to 0}\frac{\Delta s}{\Delta t} = \frac{ds}{dt}$$

![](1.files/image007.jpg)

**Рисунок 3**  Движение материальной точки по криволинейной траектории

Таким образом, модуль мгновенной скорости равен первой производной пути по времени: 

$$v = \frac{ds}{dt} (2)$$ 

**При неравномерном движении** модуль мгновенной скорости с течением времени изменяется. В данном случае пользуются скалярной величиной $\langle v \rangle$ — **средней скоростью** неравномерного движения:

$$\langle v \rangle = \frac{ds}{dt}$$

Если выражение $ds = v*dt$ (из формулы (2)) проинтегрировать по времени в пределах от $t$ до $t + \Delta t$ , то найдем длину пути, пройденного точкой за время $\Delta t$ :

$$s = \int_t^{t + \Delta t} v*dt. (3)$$ 

В случае **равномерного движения** числовое значение мгновенной скорости постоянно; тогда выражение (3) примет вид

$$s=v\int_t^{t+\Delta t}dt=v \Delta t.$$

Длина пути, пройденного точкой за промежуток времени от $t_1$ до $t_2$ , дается интегралом

$$s=\int_{t1}^{t2}v(t)dt.$$

#### 3.12.1.4 Ускорение и его составляющие

В случае неравномерного движения важно знать, как быстро изменяется скорость с течением времени. Физической величиной, характеризующей быстроту изменения скорости по модулю и направлению, является **ускорение**.

Рассмотрим **плоское движение**, т. е. такое, при котором все участки траектории точки лежат в одной плоскости. Пусть вектор $v$ задает скорость материальной точки в точке A в момент времени $0$. 

За время $\Delta t$ движущаяся точка перешла в положение В и приобрела скорость, отличную от $\vec v$ как по модулю, так и направлению и равную $\vec v_B=\vec v+ \Delta \vec v$ . Перенесем вектор $v_B$ в точку А и найдем $\Delta \vec v$ (рис.4).

**Средним ускорением** неравномерного движения в интервале от $t$ до $t+\Delta t$ называется векторная величина, равная отношению изменения скорости $\Delta \vec v$ к интервалу времени $\Delta t$ :

$$\langle\vec a \rangle =\frac{\Delta \vec v}{\Delta t}$$

**Мгновенным ускорением а** (ускорением) материальной точки в момент времени $t$ будет предел среднего ускорения:

$$\vec a = \lim_{\Delta t \to 0} \langle \vec a \rangle = \lim_{\Delta t \to 0}\frac{\Delta \vec v}{\Delta t} = \frac{dv}{dt}.$$

Таким образом, ускорение $а$ есть векторная величина, равная первой производной скорости по времени.

![](1.files/image013.jpg)

**Рисунок 4** Вывод формулы ускорения.

Разложим $\Delta \vec v$ на две составляющие. Для этого из точки *А* (рис. 4) по направлению скорости $\vec v$ отложим вектор *AD*, по модулю равный $v_B$ . Очевидно, что вектор *CD*, равный $\Delta \vec v_\tau$ , определяет изменение скорости за время $\Delta t$ *по модулю* : $\Delta \vec v_\tau = \vec v_B - \vec v$ . Вторая же составляющая $\Delta v_n$ вектора $\Delta v$ характеризует изменение скорости за время $\Delta t$ *по направлению*. 

**Тангенциальная составляющая ускорения** :

$$a_\tau = \lim_{\Delta t \to 0}\frac{\Delta v_\tau}{\Delta t} = \lim_{\Delta t \to 0}\frac{\Delta v}{\Delta t} = \frac{dv}{dt},$$

т.е. равна первой производной по времени от модуля скорости, определяя тем самым быстроту изменения скорости по модулю. Найдем вторую составляющую ускорения. Допустим, что точка *В* достаточно близка к точке *А*, поэтому $\Delta s$ можно считать дугой окружности некоторого радиуса $r$ , мало отличающейся от хорды *АВ*. Тогда из подобия треугольников *АОВ* и *EAD* следует $\frac{\Delta v_n}{AB} = v_B /r$ , но так как $AB = v \Delta t$ , то

$$\frac{\Delta v_n}{\Delta t}=\frac{v v_B}{r}.$$

В пределе при $\Delta t \to 0$ получим $v_B \to v.$

Поскольку $\vec v_B \to \vec v$, угол *EAD* стремится к нулю, а так как треугольник *EAD* равнобедренный, то угол *ADE* между $\vec v$ и $\Delta \vec v_n$ стремится к прямому. Следовательно, при $\Delta t \to 0$ векторы $\Delta v_n$ и $v$ оказываются взаимно перпендикулярными. Так как вектор скорости направлен по касательной к траектории, то вектор $\Delta v_n$ , перпендикулярный вектору скорости, направлен к центру ее кривизны. 

Вторая составляющая ускорения называется **нормальной составляющей ускорения** и направлена по нормали к траектории к центру ее кривизны (поэтому ее называют также **центростремительным ускорением)**. Она равна:

$$a_n = \lim_{\Delta t \to 0}\frac{\Delta v_n}{\Delta t} = v^2/r,$$

**Полное ускорение** тела есть геометрическая сумма тангенциальной и нормальной составляющих (рисунок 5):

$$\vec a=\frac{d \vec v}{dt} = \vec a_\tau + \vec a_n.$$

Итак, *тангенциальная* составляющая ускорения характеризует *быстроту изменения скорости по модулю* (направлена по касательной к траектории), а *нормальная* составляющая ускорения — быстроту изменения скорости по направлению (направлена к центру кривизны траектории).
Составляющие $\vec a_n$ и $\vec a_\tau$ перпендикулярны друг другу.

![](1.files/image020.jpg)

**Рисунок 5** Составляющие ускорения.

В зависимости от тангенциальной и нормальной составляющих ускорения движение можно классифицировать следующим образом:

1. $а_\tau = 0, а_n = 0$ — прямолинейное равномерное движение;
2. $a_\tau = a = \text{const}, a_n =0$ — прямолинейное равнопеременное движение. При таком виде движения
$$a_\tau = a = \frac{\Delta v}{\Delta t} = \frac{v_2 - v_1}{t_2 - t_1}.$$
Если в начальный момент времени $t_1 = t_0$, а начальная скорость $v_1 = v_0$ , то, обозначив $t_2 = t$ и $v_2 = v$, получим $a = (v - v_0 )/t$, откуда $v =v_0 + at.$ Проинтегрировав эту формулу в пределах от нуля до произвольного момента времени $t$ , найдем, что длина пути, пройденного точкой, в случае равнопеременного движения
$$s = \int_0^t vdt = \int_0^t (v_0 + at)dt = v_0t + \frac{at^2}{2};$$
3. $a_\tau = f(t) , а_n = 0$ — прямолинейное движение с переменным ускорением;
4. $a_\tau = 0, а_n = \text{const}$ . При $a_\tau = 0$ скорость по модулю не изменяется, а изменяется по направлению. Из формулы $а_n = v^2/r$ следует, что радиус кривизны должен быть постоянным. Следовательно, движение по окружности является равномерным;
5. $a_\tau = 0, а_n != 0$ — равномерное криволинейное движение;
6. $a_\tau = \text{const}, a_n != 0$ — криволинейное равнопеременное движение;
7. $a_\tau = f(t), a_n != 0$ — криволинейное движение с переменным ускорением.

##### 3.12.1.4.1 Угловая скорость и угловое ускорение

![](1.files/image024.jpg)
**Рисунок 6** Линейная скорость  точки
**Рисунок 7** Линейное ускорение точки

Рассмотрим твердое тело, которое вращается вокруг неподвижной оси. Тогда отдельные точки этого тела будут описывать окружности разных радиусов, центры которых лежат на оси вращения. Пусть некоторая точка движется по окружности радиуса $R$. Ее положение через промежуток времени $\Delta t$ зададим углом $\Delta \varphi$ . Элементарные (бесконечно малые) углы поворота рассматривают как векторы. Модуль вектора $d\varphi$ равен углу поворота, а его направление совпадает с направлением поступательного движения острия винта, головка которого вращается в направлении движения точки по окружности, т. е. подчиняется **правилу правого, винта** (рис.6). Векторы, направления которых связываются с направлением вращения, называются **псевдовекторами** или **аксиальными векторами**. Эти векторы не имеют определенных точек приложения: они могут откладываться из любой точки оси вращения.

**Угловой скоростью** называется векторная величина, равная первой производной угла поворота тела по времени:

$$\vec \omega = \lim_{\Delta t \to 0}\frac{\Delta \vec \varphi}{\Delta t} = \frac{d \vec \varphi}{dt}.$$

Вектор $\omega$ направлен вдоль оси вращения по правилу правого винта, т. е. так же, как и вектор $d\varphi$ (рисунок 7). Размерность угловой скорости $dim \omega = T^{-1}$ , a ее единица — радиан в секунду (рад/с).

Линейная скорость точки:
$$v = \lim_{\Delta t \to 0}\frac{\Delta s}{\Delta t} = \lim_{\Delta t \to 0}\frac{R \Delta \varphi}{\Delta t} = R \lim_{\Delta t \to 0}\frac{\Delta \varphi}{\Delta t} = R\omega,$$ 
т. е. 
$$v = \omega R$$

В векторном виде формулу для линейной скорости можно написать как векторное произведение:

$$\vec v = [\vec \omega \vec R]$$

При этом модуль векторного произведения, по определению, равен $\omega R \sin(\hat {\vec \omega \vec R})$,

а направление совпадает *с* направлением поступательного движения правого винта при его вращении от $\omega$ к $R.$

Если $\omega = \text{const}$, то вращение равномерное и его можно характеризовать **периодом вращения Т** — временем, за которое точка совершает один полный оборот, т. е. поворачивается на угол $2\pi$ . Так как промежутку времени $\Delta t = T$ соответствует $\Delta \varphi =2\pi$ , то $\omega = \frac{2\pi}{Т}$, откуда

$$T=\frac{2\pi}{\omega}.$$

Число полных оборотов, совершаемых телом при равномерном его движении по окружности, в единицу времени называется **частотой вращения:** 

откуда

$$n = \frac{1}{T} = \frac{\omega}{2\pi}, \omega = 2\pi n$$

**Угловым ускорением** называется векторная величина, равная первой производной угловой скорости по времени:

$$\vec \epsilon = \frac{d \vec \omega}{dt}.$$

При вращении тела вокруг неподвижной оси вектор углового ускорения направлен вдоль оси вращения в сторону вектора элементарного приращения угловой скорости. При ускоренном движении вектор

![](1.files/image031.jpg)

$\epsilon$ сонаправлен вектору $\omega$ (рисунок 8), при замедленном.— противонаправлен ему (рисунок 9).

Тангенциальная составляющая ускорения

$a_\tau = \frac{dv}{dt}$, $v = \omega R$ и 
$$a_\tau = \frac{d(\omega R)}{dt} = R \frac{d \omega}{dt} = R \epsilon.$$

Нормальная составляющая ускорения

$$a_n = \frac{v^2}{R} = \frac{\omega^2 R^2}{R} = \omega^2R.$$

Таким образом, связь между линейными (длина пути s , пройденного точкой по дуге окружности радиуса *R* , линейная скорость $v$ , тангенциальное ускорение $a_\tau$ , нормальное ускорение $а_n$ ) и угловыми величинами (угол поворота $\varphi$ , угловая скорость $\omega$, угловое ускорение $\epsilon$ ) выражается следующими формулами:

$$s = R \varphi, v = R \omega, a_tau = R \epsilon, a_n = \omega^2 R$$

В случае равнопеременного движения точки по окружности ( $\epsilon = \text{const}$ )

$$\omega = \omega_0 \pm \epsilon t, \varphi = \omega_0 t \pm \epsilon t^2 / 2,$$

где $\omega_0$ — начальная угловая скорость.

### 3.12.2 Динамика материальной точки и поступательного движения твердого тела

В основе динамики лежат три закона Ньютона, сформулированные им в 1687 г. Их рассматривают как *систему взаимосвязанных законов* и опытной проверке подвергают не каждый отдельный закон, а всю систему в целом.

#### 3.12.2.1 Первый закон Ньютона. Масса. Сила

**Первый закон Ньютона**:  всякая материальная точка (тело) сохраняет состояние покоя или равномерного прямолинейного движения до тех пор, пока *воздействие* со стороны других тел не заставит ее изменить это состояние.

Стремление тела сохранять состояние покоя или равномерного прямолинейного движения называется **инертностью**. Поэтому первый закон Ньютона называют также **законом инерции**. 

Механическое движение относительно, и его характер зависит от системы отсчета. Первый закон Ньютона выполняется не во всякой системе отсчета, а те системы, по отношению к которым он выполняется, называются **инерциальными системами отсчета**. Инерциальной системой отсчета является такая система, которая либо покоится, либо движется равномерно и прямолинейно относительно какой-то другой инерциальной системы. *Первый закон Ньютона утверждает существование инерциальных систем отсчета*. 

Опытным путем установлено, что инерциальной можно считать гелиоцентрическую (звездную) систему отсчета (начало координат находится в центре Солнца, а оси проведены в направлении определенных звезд). Система отсчета, связанная с Землей, строго говоря, неинерциальна, однако эффекты, обусловленные ее неинерциальностью (Земля вращается вокруг собственной оси и вокруг Солнца), при решении многих задач пренебрежимо малы, и в этих случаях ее можно считать инерциальной.

Из опыта известно, что при одинаковых воздействиях различные тела неодинаково изменяют скорость своего движения, т. е., иными словами, приобретают различные ускорения. Ускорение зависит не только от величины воздействия, но и от свойств самого тела (от его массы).

**Масса**  тела — физическая величина, характеристика материи, определяющая ее инерционные **(инертная масса)** и гравитационные **(гравитационная масса)** свойства. В настоящее время можно считать доказанным, что инертная и гравитационная массы равны друг другу (с точностью, не меньшей $10^{-12}$ их значения).

Чтобы описывать воздействия, упоминаемые в первом законе Ньютона, вводят понятие силы. Под действием сил тела либо изменяют скорость движения, т. е. приобретают ускорения (динамическое проявление сил), либо деформируются, т. е. изменяют свою форму и размеры (статическое проявление сил). В каждый момент времени сила характеризуется числовым значением, направлением в пространстве и точкой приложения. Итак, **сила** — это векторная величина, являющаяся мерой механического воздействия на тело со стороны других тел или полей, в результате которого тело приобретает ускорение или изменяет свою форму и размеры.

#### 3.12.2.2 Второй закон Ньютона

Второй закон Ньютона — основной закон динамики поступательного движения — отвечает на вопрос, как изменяется механическое движение материальной точки (тела) под действием приложенных к ней сил.

Если рассмотреть действие различных сил на одно и то же тело, то оказывается, что ускорение, приобретаемое телом, всегда прямо пропорционально равнодействующей приложенных сил:

a ~ F (m=const). (1)

При действии одной и той же силы на тела с разными массами их ускорения оказываются различными, а именно:

 а ~ 1/m (F=const). (2)

Используя выражения (1) и (2) и учитывая, что сила и ускорение — величины векторные, можем записать

$$\vec a = k  \frac{\vec F}{m} . (3)$$

Соотношение (3) выражает **второй закон Ньютона**: ускорение, приобретаемое материальной точкой (телом), пропорционально вызывающей его силе, совпадает с нею по направлению и обратно пропорционально массе материальной точки (тела).

В СИ коэффициент пропорциональности *k* =  1. Тогда

$$\vec a = \frac{\vec F}{m} ,$$

или

$$\vec F = m \vec a = m \frac{d \vec v}{dt}. (4)$$

Учитывая, что масса материальной точки (тела) в классической механике есть величина постоянная, в выражении (4) ее можно внести под знак производной:

$$\vec F =\frac{d}{dt}(m \vec v ) . (5)$$

Векторная величина

$$\vec p = m \vec v , (6)$$

численно равная произведению массы материальной точки на ее скорость и имеющая направление скорости, называется **импульсом (количеством движения)** этой материальной точки.

Подставляя (6) в (5), получим

$$\vec F = \frac{d \vec p}{dt} . (7)$$

Это выражение — **более общая формулировка второго закона Ньютона**: скорость изменения импульса материальной точки равна действующей на нее силе. Выражение (7) называется **уравнением движения материальной точки**. 

Единица силы в СИ — **ньютон** (Н): 1 Н — сила, которая массе в 1 кг сообщает ускорение $1 м/с^2$ в направлении действия силы:

$1Н = 1 кг * м/с^2$ .

Второй закон Ньютона справедлив только в инерциальных системах отсчета. Первый закон Ньютона можно получить из второго. Действительно, в случае равенства нулю равнодействующей сил (при отсутствии воздействия на тело со стороны других тел) ускорение (см. (3)) также равно нулю. Однако *первый закон Ньютона* рассматривается как *самостоятельный закон* (а не как следствие второго закона), так как именно он утверждает существование инерциальных систем отсчета, в которых только и выполняется уравнение (7).

Если на материальную точку одновременно действуют несколько сил $F_1, F_2 ,..., F_n$ , то ее ускорение:

$$\vec a = \frac{1}{m} \sum_{i=1}^n\vec F_i = \sum_{i=1}^n\vec a_i$$

![](2.files/image001.jpg)

В механике большое значение имеет **принцип независимости действия сил**: если на материальную точку действует одновременно несколько сил, то каждая из этих сил сообщает материальной точке ускорение согласно второму закону Ньютона, как будто других сил не было. 

Согласно этому принципу, силы и ускорения можно разлагать на составляющие, использование которых приводит к существенному упрощению решения задач.

Например, на рис. 10 действующая сила $\vec F = m \vec a$ разложена на два компонента: тангенциальную силу $\vec F_\tau$ (направлена по касательной к траектории) и нормальную силу $\vec F_n$(направлена по нормали к центру кривизны). Используя выражения $v = R \omega, a_tau = R \epsilon, a_n = \omega^2 R$,  можно записать:

$$F_\tau = m a_tau = m\frac{dv}{dt}; F_n = m a_n = (m v^2)/R = m \omega^2 R$$

Если на материальную точку действует одновременно несколько сил, то, согласно принципу независимости действия сил, под $\vec F$ во втором законе Ньютона понимают результирующую силу.

#### 3.12.2.3 Третий закон Ньютона

Взаимодействие между материальными точками (телами) определяется **третьим законом Ньютона**: всякое действие материальных точек (тел) друг на друга носит характер взаимодействия; силы, с которыми действуют друг на друга материальные точки, всегда равны по модулю, противоположно направлены и действуют вдоль прямой, соединяющей эти точки:

$\vec F_{12} = - \vec F_{21}$ , (1)

где $\vec F_{12}$ — сила, действующая на первую материальную точку со стороны второй; $\vec F_{21}$ — сила, действующая на вторую материальную точку со стороны первой. Эти силы приложены к *разным* материальным точкам (телам), всегда действуют *парами* и являются силами *одной природы*. 

При использовании законов динамики иногда допускают следующую ошибку: так как действующая сила всегда вызывает равную по модулю и противоположную по направлению силу противодействия, то, следовательно, их равнодействующая должна быть равна нулю и тела вообще не могут приобрести ускорения. Однако надо помнить, что во втором законе Ньютона речь идет об ускорении, приобретаемом телом под действием приложенных к нему сил. Равенство нулю ускорения означает равенство нулю равнодействующей сил, приложенных к одному и тому же телу. Третий же закон Ньютона говорит о равенстве сил, приложенных к *различным* телам. На каждое из двух взаимодействующих тел действует только одна сила, которая и сообщает данному телу ускорение.

Третий закон Ньютона позволяет осуществить переход от динамики *отдельной* материальной точки к динамике *системы* материальных точек. Это следует из того, что и для системы материальных точек взаимодействие сводится к силам парного взаимодействия между материальными точками.

Законы Ньютона в таких формулировках справедливы только в инерциальных системах отсчета при скоростях много меньше скорости света.

#### 3.12.2.4 Силы трения

Из опыта известно, что всякое тело, движущееся по горизонтальной поверхности другого тела, при отсутствии действия на него других сил с течением времени замедляет свое движение и в конце концов останавливается. Это можно объяснить существованием **силы трения,** которая препятствует скольжению соприкасающихся тел друг относительно друга. Силы трения зависят от относительных скоростей тел. Силы трения могут быть разной природы, но в результате их действия механическая энергия всегда превращается во внутреннюю энергию соприкасающихся тел, то есть в энергию теплового движения частиц.

Различают внешнее (сухое) и внутреннее (жидкое или вязкое) трение. **Внешним трением** называется трение, возникающее в плоскости касания двух соприкасающихся тел при их относительном перемещении. Если соприкасающиеся тела неподвижны друг относительно друга, говорят о **трении покоя,** если же происходит относительное перемещение этих тел, то в зависимости от характера их относительного движения говорят о **трении скольжения, качения** или **верчения**. 

**Внутренним трением** называется трение между частями одного и того же тела, например между различными слоями жидкости или газа, скорости которых меняются от слоя к слою. В отличие от внешнего трения здесь отсутствует трение покоя. Если тела скользят относительно друг друга и разделены прослойкой вязкой жидкости (смазки), то трение происходит в слое смазки. В таком случае говорят о **гидродинамическом трении** (слой смазки достаточно толстый) и **граничном трении** (толщина смазочной прослойки около 0,1 мкм и меньше).

Обсудим некоторые закономерности внешнего трения. Это трение обусловлено шероховатостью соприкасающихся поверхностей; в случае же очень гладких поверхностей трение обусловлено силами межмолекулярного притяжения.

Рассмотрим лежащее на плоскости тело (рис. 11), к которому приложена горизонтальная сила F.

![](2.files/image003.jpg)

![](2.files/image004.jpg)

Тело придет в движение лишь тогда, когда приложенная сила $\vec F$ будет больше силы трения $\vec F_\text{тр}$ . 
Французские физики Г. Амонтон (1663—1705) и Ш. Кулон (1736—1806) опытным путем установили следующий **закон**: сила трения скольжения $\vec F_\text{тр}$ пропорциональна силе $\vec N$ нормального давления, с которой одно тело действует на
другое: 

$F_\text{тр} = f N$ ,
где $f$ — коэффициент трения скольжения, зависящий от свойств соприкасающихся поверхностей.

Найдем значение коэффициента трения. Если тело находится на наклонной плоскости с углом наклона а (рис. 12), то оно приходит в движение только когда тангенциальная составляющая $\vec F$ силы тяжести $\vec Р$ больше силы трения $\vec F_\text{тр}$ . Следовательно, в предельном случае (начало скольжения тела) $F = F_\text{тр}$ или

$P\sin\alpha_0 = fN = fP \cos\alpha_0$ откуда $f = \tg\alpha_0$

Таким образом, коэффициент трения равен тангенсу угла $\alpha_0$ , при котором начинается скольжение тела по наклонной плоскости.

Для гладких поверхностей определенную роль начинает играть межмолекулярное притяжение. Поэтому Б. В. Дерягиным (р. 1902) предложен **закон трения скольжения** 

$$F_\text{тр} = f_\text{ист} (N + S p_0),$$ 

где $p_0$ — добавочное давление, обусловленное силами межмолекулярного притяжения, которые быстро уменьшаются с увеличением расстояния между частицами; $S$ — площадь контакта между телами; $f_\text{ист}$ — истинный коэффициент трения скольжения.

Трение используется в технике. Например, из-за наличия трения между колесами и дорогой движется транспорт.

В некоторых случаях силы трения оказывают вредное действие, и поэтому их надо уменьшать. Для этого на трущиеся поверхности наносят смазку (сила трения уменьшается примерно в 10 раз), которая заполняет неровности между этими поверхностями и располагается тонким слоем между ними так, что поверхности как бы перестают касаться друг друга, а скользят друг относительно друга отдельные слои жидкости. Таким образом, внешнее трение твердых тел заменяется значительно меньшим внутренним трением жидкости.

Радикальным способом уменьшения силы трения является замена трения скольжения трением качения (шариковые и роликовые подшипники и т.д.). **Сила трения качения** определяется по закону Кулона:

 $$F_\text{тр} = \frac{f_k N}{r} , (1)$$

где $r$ — радиус катящегося тела; $f_k$ — коэффициент трения качения, имеющий размерность $dim f_k = L$ . Из (1) следует, что сила трения качения обратно пропорциональна радиусу катящегося тела.

### 3.12.3 Законы сохранения



#### 3.12.3.1 Закон сохранения импульса. Центр масс


Для вывода закона сохранения импульса рассмотрим некоторые понятия. Совокупность материальных точек (тел), рассматриваемых как единое целое, называется **механической системой**. Силы взаимодействия между материальными точками механической системы называются **внутренними**. Силы, с которыми на материальные точки системы действуют внешние тела, называются **внешними**.

Механическая система тел, на которую не действуют внешние силы, называется **замкнутой** (или **изолированной**). Если мы имеем механическую систему, состоящую из многих тел, то, согласно третьему закону Ньютона, силы, действующие между этими телами, будут равны и противоположно направлены, т. е. геометрическая сумма внутренних сил равна нулю.

Рассмотрим механическую систему, состоящую из $n$ тел, масса и скорость которых соответственно равны $m_1, m_2, \ldots, m_n$ и $v_1, v_2, \ldots, v_n$ . Пусть $F'_1, F'_2 , \ldots, F'_n$ — равнодействующие внутренних сил, действующих на каждое из этих тел, a $F_1, F_2, \ldots, F_n$ — равнодействующие внешних сил. Запишем второй закон Ньютона для каждого из $n$ тел механической системы:
$$\begin{cases}\frac{d}{dt}(m_1 \vec v_1 )= \vec F'_1 + \vec F_1, \\ \frac{d}{dt}(m_2 \vec v_2 )= \vec F'_2 + \vec F_2,\\\cdots\cdots\cdots\cdots\cdots\cdots,\\\frac{d}{dt}(m_n \vec v_n )= \vec F'_n + \vec F_n\end{cases} .$$

Складывая почленно эти уравнения, получим

$$\frac{d}{dt} (m_1 \vec v_1 + m_2 \vec v_2 + \ldots + m_n \vec v_n ) = \vec F '_1 + \vec F '_2 + \ldots + \vec F '_n + \vec F_1 + \vec F_2 + \ldots+ \vec F_n .$$

Но так как геометрическая сумма внутренних сил механической системы по третьему закону Ньютона равна нулю, то

$$\frac{d}{dt} (m_1 \vec v_1 + m_2 \vec v_2 + \ldots + m_n \vec v_n ) = \vec F_1 + \vec F_2 + \ldots+ \vec F_n,$$

или

$$\frac{d \vec p}{dt} = \vec F_1 + \vec F_2 + \ldots+ \vec F_n , (1)$$

где 
$$\vec p = \sum_{i=1}^n m_i \vec v_i$$

импульс системы. Таким образом, производная по времени от импульса механической системы равна геометрической сумме внешних сил, действующих на систему.

В случае отсутствия внешних сил (рассматриваем замкнутую систему)

$$\frac{d \vec p}{dt} = \sum_{i=1}^n \frac{d}{dt} m_i \vec v_i = 0$$
т. е.
$$\vec p = \sum_{i=1}^n m_i \vec v_i = \text{const}$$

Это выражение и является **законом сохранения импульса**: импульс замкнутой системы сохраняется, т. е. не изменяется с течением времени.

Закон сохранения импульса справедлив не только в классической физике, хотя он и получен как следствие законов Ньютона. Эксперименты доказывают, что он выполняется и для замкнутых систем микрочастиц (они подчиняются законам квантовой механики). Этот закон носит универсальный характер, т. е. закон сохранения импульса — *фундаментальный закон природы*. 

Закон сохранения импульса является следствием определенного свойства симметрии пространства — его однородности. **Однородность пространства** заключается в том, что при параллельном переносе в пространстве замкнутой системы тел как целого ее физические свойства и законы движения не изменяются, иными словами, не зависят от выбора положения начала координат инерциальной системы отсчета.

Отметим, что согласно (1), импульс сохраняется и для незамкнутой системы, если геометрическая сумма всех внешних сил равна нулю.

В механике Галилея — Ньютона из-за независимости массы от скорости импульс системы может быть выражен через скорость ее центра масс. **Центром масс** (или **центром инерции)** системы материальных точек называется воображаемая точка С, положение которой характеризует распределение массы этой системы. Ее радиус-вектор равен

$$\vec r_C = \frac{\sum_{i=1}^n m_i \vec r_i}{m}$$

где $m_i$ и $r_i$ — соответственно масса и радиус-вектор $i$-й материальной точки; $n$ — число материальных точек в системе;

$m = \sum_{i=1}^n m_i$ — масса системы.

Скорость центра масс

$$\vec v_C = \frac{d \vec r_C}{dt} = \frac{\sum_{i=1}^n m_i  \frac{\vec dr_i}{dt}}{m} = \frac{\sum_{i=1}^n m_i \vec v_i}{m}$$

Учитывая, что $\vec p_i = m_i \vec v_i$ , а $\sum_{i=1}^n \vec p_i$ есть импульс $\vec р$ системы, можно написать

$$\vec p = m \vec v_c , (2)$$

т. е. импульс системы равен произведению массы системы на скорость ее центра масс.

Подставив выражение (2) в уравнение (1), получим

$$m \frac{d \vec v_c}{dt} = \vec F_1 + \vec F_2 + \ldots + \vec F_n, (3)$$ 

т. е. центр масс системы движется как материальная точка, в которой сосредоточена масса всей системы и на которую действует сила, равная геометрической сумме всех внешних сил, действующих на систему. Выражение (3) представляет собой **закон движения центра масс**. 

В соответствии с (2) из закона сохранения импульса вытекает, что *центр масс замкнутой системы либо движется прямолинейно и равномерно, либо остается неподвижным*.


#### 3.12.3.2 Энергия, работа, мощность

Энергия — универсальная мера различных форм движения и взаимодействия. С различными формами движения материи связывают различные формы энергии: механическую, тепловую, электромагнитную, ядерную и др. В одних явлениях форма движения материи не изменяется (например, горячее тело нагревает холодное), в других — переходит в иную форму (например, в результате трения механическое движение превращается в тепловое). Однако существенно, что во всех случаях энергия, отданная (в той или иной форме) одним телом другому телу, равна энергии, полученной последним телом.

Изменение механического движения тела вызывается силами, действующими на него со стороны других тел. Чтобы

количественно характеризовать процесс обмена энергией между взаимодействующими телами, в механике вводится понятие **работы силы**. 

Если тело движется *прямолинейно* и на него действует постоянная сила $F$ , которая составляет некоторый угол $\alpha$ с направлением перемещения, то работа этой силы равна произведению проекции силы $F_s$ на направление перемещения $F_s = F \cos\alpha$ , умноженной на перемещение точки приложения силы:

 $$A = F_s \cdot s = \mid F \mid \mid s \mid \cos \alpha . (1)$$

В общем случае сила может изменяться как по модулю, так и по направлению, поэтому формулой (1) пользоваться нельзя. Если, однако, рассмотреть элементарное перемещение $dr$, то силу $F$ можно считать постоянной, а движение точки её

![](3.files/image001.jpg)

приложения — прямолинейным. **Элементарной работой** силы $F$ на перемещении $dr$ называется *скалярная* величина

$$dА = \vec F d \vec r = F \cdot \cos\alpha \cdot ds = F_s ds,$$

где $\alpha$ — угол между векторами $F$ и $dr$ ; $ds = |d \vec r |$ — элементарный путь; $F_s$ — проекция вектора $F$ на вектор $dr$ (рис. 13).

Работа силы на участке траектории от точки *1* до точки *2* равна алгебраической сумме элементарных работ на отдельных бесконечно малых участках пути. Эта сумма приводится к интегралу

$$A=\int_1^2 F ds \cos\alpha = \int_1^2 F_s ds. $$ 

Для вычисления этого интеграла надо знать зависимость силы  $F_s$ от пути $s$ вдоль траектории *1*  — *2*. Пусть эта зависимость представлена графически (рис. 14), тогда искомая работа $А$ определяется на графике площадью закрашенной фигуры. Если, например, тело движется прямолинейно, сила $F = \text{const}$ и $a = \text{const}$, то получим

$$A=\int_1^2 F ds \cos\alpha = F \cos\alpha \int_1^2 ds = F s \cos\alpha$$

где $s$ — пройденный телом путь (см. также формулу (1)).

Из формулы (1) следует, что при $\alpha < \pi/2$ работа силы положительна, в этом случае составляющая $F_s$ совпадает

![](3.files/image004.jpg)

по направлению с вектором скорости движения `v` (см. рис. 13). Если $\alpha > \pi/2$, то работа силы отрицательна. При $\alpha = \pi/2$ (сила направлена перпендикулярно перемещению) работа силы равна нулю.

Единица работы — **джоуль** (Дж): 1 Дж — работа, совершаемая силой в 1 Н на пути в 1 м (1 Дж = 1 Н * м).

Чтобы охарактеризовать скорость совершения работы, вводят понятие **мощности**: 

$$N = \frac{dA}{dt} . (3)$$

За время $dt$ сила $\vec F$ совершает работу $\vec F d \vec r$ , и мощность, развиваемая этой силой, в данный момент времени

$$N = \frac{\vec F d \vec r}{dt}= \vec F \vec v$$

т. е. равна скалярному произведению вектора силы на вектор скорости, с которой движется точка приложения этой силы; $N$ — величина *скалярная*. 

Единица мощности — **ватт** (Вт): 1 Вт — мощность, при которой за время 1 с совершается работа в 1 Дж (1 Вт = 1 Дж/с).

#### 3.12.3.2.1 Кинетическая энергия

**Кинетическая энергия**  механической системы — это энергия механического движения этой системы.

Сила $\vec F$ , действуя на покоящееся тело и вызывая его движение, совершает работу, а энергия движущегося тела возрастает на величину затраченной работы. Таким образом, работа $dA$ силы $\vec F$ на пути, который тело прошло за время возрастания скорости от 0 до $\vec v$, идет на увеличение кинетической энергии $dT$ тела, т. е.

$$dA = dT.$$

Используя второй закон Ньютона $\vec F =m\frac{d\vec v}{dt}$ и умножая обе части равенства на перемещение $d\vec r$ , получим

$$\vec F d\vec r = m\frac{d\vec v}{dt}dr = dA$$

Так как $\vec v = \frac{d \vec r}{dt}$, то $dA = m \vec v * d \vec v = m v * dv = dT$, откуда $T = \int_0^v mv * dv = m v^2/2$

Таким образом, тело массой $m$, движущееся со скоростью $v$, обладает кинетической энергией

$$Т = \frac{mv^2}{2}. (1)$$

Из формулы (1) видно, что кинетическая энергия зависит только от массы и скорости тела, т. е. кинетическая энергия системы есть функция состояния ее движения.

При выводе формулы (1) предполагалось, что движение рассматривается в инерциальной системе отсчета, так как иначе нельзя было бы использовать законы Ньютона. В разных инерциальных системах отсчета, движущихся друг относительно друга, скорость тела, а следовательно, и его кинетическая энергия будут неодинаковы. Таким образом, кинетическая энергия зависит от выбора системы отсчета.
Кинетическая энергия механической системы равна сумме кинетических энергий тел, входящих в систему. Так кинетическая энергия системы из $n$ материальных точек равна

$$T = \sum_{i=1}^n \frac{m_i v_i^2}{2},$$

где $v_i$ — скорость $i$-й материальной точки массой $m_i.$


#### 3.12.3.2.2 Потенциальная энергия

**Потенциальная энергия** — механическая энергия системы тел, определяемая их взаимным расположением и характером сил взаимодействия между ними.

Пусть взаимодействие тел осуществляется посредством силовых полей (например, поля упругих сил, поля гравитационных сил), характеризующихся тем, что работа, совершаемая действующими силами при перемещении тела из одного положения в другое, не зависит от того, по какой траектории это перемещение произошло, а зависит только от начального и конечного положений. Такие поля называются **потенциальными,** а силы, действующие в них,— **консервативными**. Если же работа, совершаемая силой, зависит от траектории перемещения тела из одной точки в другую, то такая сила называется **диссипативной**; ее примером является сила трения.

Тело, находясь в потенциальном поле сил, обладает потенциальной энергией $\Pi$. Работа консервативных сил при элементарном (бесконечно малом) изменении конфигурации системы равна приращению потенциальной энергии, взятому со знаком минус, так как работа совершается за счет убыли потенциальной энергии:

$dA = -d\Pi$. (2)

Работа $dА$ выражается как скалярное произведение силы $\vec F$ на перемещение $d \vec r$ и выражение (2) можно записать в виде

$\vec F d\vec r = -d\Pi$. (3)

Следовательно, если известна функция $П(\vec r )$, то из формулы (3) можно найти силу $\vec F$ по модулю и направлению.

Потенциальная энергия может быть определена исходя из (3) как

$\Pi = -\int\vec F d \vec r + C$

где $С$ — постоянная интегрирования, т. е. потенциальная энергия определяется с точностью до некоторой произвольной постоянной. Это, однако, не отражается на физических законах, так как в них входит или разность потенциальных энергий в двух положениях тела, или производная $\Pi$ по координатам. Поэтому потенциальную энергию тела в каком-то определенном положении считают равной нулю (выбирают нулевой уровень отсчета), а энергию тела в других положениях отсчитывают относительно нулевого уровня. Для консервативных сил

$F_x = - \frac{\partial\Pi}{\partial x}$, $F_y = - \frac{\partial\Pi}{\partial y}$, $F_z = - \frac{\partial\Pi}{\partial z}$

или в векторном виде

$\vec F = -\nabla П$ , (4) где

$\nabla\Pi = \frac{\partial\Pi}{\partial x} \vec i + \frac{\partial\Pi}{\partial y} \vec j + \frac{\partial\Pi}{\partial z} \vec k$ (5)

( $i$, $j$, $k$ — единичные векторы координатных осей). Вектор, определяемый выражением (5), называется **градиентом скаляра П**. 

Для него наряду с обозначением $\text{grad }\Pi$ применяется также обозначение $\nabla\Pi$. $\nabla$ («набла») означает символический вектор, называемый **оператором Гамильтона**  или **набла-оператором:** 

$$\nabla = \frac{\partial}{\partial x} \vec i + \frac{\partial}{\partial y} \vec j + \frac{\partial}{\partial z} \vec k (6)$$

Конкретный вид функции $\Pi$ зависит от характера силового поля. Например, потенциальная энергия тела массой $m$, поднятого на высоту $h$ над поверхностью Земли, равна

$\Pi = mgh$, (7)

где высота $h$ отсчитывается от нулевого уровня, для которого $\Pi_0 = 0$. Выражение (7) вытекает непосредственно из того, что потенциальная энергия равна работе силы тяжести при падении тела с высоты $h$ на поверхность Земли.

Так как начало отсчета выбирается произвольно, то потенциальная энергия может иметь отрицательное значение *(кинетическая энергия всегда положительна!}*. Если принять за нуль потенциальную энергию тела, лежащего на поверхности Земли, то потенциальная энергия тела, находящегося на дне шахты (глубина $h$ ), $\Pi = - mgh.$

Найдем потенциальную энергию упруго деформированного тела (пружины). Сила упругости пропорциональна
деформации: $F_\text{х упр} = -kx$, где $F_\text{х упр}$ — проекция силы упругости на ось $х$; $k$ — **коэффициент упругости** (для пружины — **жесткость**), а знак минус указывает, что $F_\text{х упр}$ направлена в сторону, противоположную деформации $х$. 
По третьему закону Ньютона, деформирующая сила равна по модулю силе упругости и противоположно ей направлена, т. е.

$F_x = -F_\text{х упр} = kx$ 
Элементарная работа $dA$, совершаемая силой $F_x$ при бесконечно малой деформации $dx$, равна
$dA = F_x dx = k x*dx$, а полная работа

$A=\int_0^x kx*dx=kx^2/2$

идет на увеличение потенциальной энергии пружины. Таким образом, потенциальная энергия упругодеформированного тела

$\Pi = (k x^2)/2$ .

Потенциальная энергия системы, подобно кинетической энергии, является функцией состояния системы. Она зависит только от конфигурации системы и ее положения по отношению к внешним телам.

**Полная механическая энергия системы**  — энергия механического движения и взаимодействия:

$Е = T + П$ ,

т. е. равна сумме кинетической и потенциальной энергий.

#### 3.12.3.3 Закон сохранения энергии

Закон сохранения энергии — результат обобщения многих экспериментальных данных. Идея этого закона принадлежит М. В. Ломоносову (1711 —1765), изложившему закон сохранения материи и движения, а количественная формулировка закона сохранения энергии дана немецким врачом Ю. Майером (1814—1878) и немецким естествоиспытателем Г. Гельмгольцем (1821 — 1894).

Рассмотрим систему материальных точек массами $m_1, m_2, \ldots, m_n$ , движущихся со скоростями $v_1, v_2 , \ldots, v_n$ . Пусть $F'_1 , F'_2 , \ldots, F'_n$ — равнодействующие внутренних консервативных сил, действующих на каждую из этих точек, a $F_1, F_2, \ldots, F_n$ — равнодействующие внешних сил, которые также будем считать консервативными. Кроме того, будем считать, что на материальные точки действуют еще и внешние неконсервативные силы; равнодействующие этих сил, действующих на каждую из материальных точек, обозначим $f_1, f_2, \ldots, f_n$ . При $v < < с$ массы материальных точек

постоянны и уравнения второго закона Ньютона для этих точек следующие:

$$\begin{cases}\frac{m_1 d \vec v_1}{dt} =\vec F'_1 + \vec F_1 + \vec f_1),\\\frac{m_2 d \vec v_2}{dt} =\vec F'_2 + \vec F_2 + \vec f_2),\\\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots,\\\frac{m_n d \vec v_n}{dt} =\vec F'_n + \vec F_n + \vec f_n)\end{cases}$$

Двигаясь под действием сил, точки системы за интервал времени $dt$ совершают перемещения, соответственно равные $d\vec r_1 , d\vec r_2 , \ldots, d\vec r_n$ . Умножим каждое из уравнений скалярно на соответствующее перемещение и, учитывая, что $d\vec r_i = \vec v_i dt$, получим:

$$\begin{cases}m_1 (\vec v_1 d \vec v_1) - (\vec F'_1 + \vec F_1) d \vec r_1 = \vec f_1 d \vec r_1,\\ m_2 (\vec v_2 d \vec v_2) - (\vec F'_2 + \vec F_2) d \vec r_2 = \vec f_2 d \vec r_2,\\ \cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots,\\ m_n(\vec v_n d \vec v_n) - (\vec F'_n + \vec F_n) d \vec r_n = \vec f_n d \vec r_n\end{cases}$$

Сложив эти уравнения, получим

$$\sum_{i=1}^n m_i (\vec v_i d \vec v_i) - \sum_{i=1}^n (\vec F'_i + \vec F_i) d \vec r_i = \sum_{i=1}^n \vec f_i d \vec r_i. (1)$$

Первый член левой части равенства (1)

$$\sum_{i=1}^n m_i (\vec v_i d \vec v_i) = \sum_{i=1}^n d(m_i \vec v_i^2/2) = dT$$

где $dT$ есть приращение кинетической энергии системы. Второй член

$$\sum_{i=1}^n (\vec F'_i + \vec F_i)d \vec r_i$$

равен элементарной работе внутренних и внешних консервативных сил, взятой со знаком минус, т. е. равен элементарному приращению потенциальной энергии $d\Pi$ системы (см. предыдущий параграф (2)).

Правая часть равенства (1) задает работу внешних неконсервативных сил,

действующих на систему. Таким образом, имеем

 $d(T + П) = dA$ . (2)

При переходе системы из состояния *1*  в какое-либо состояние *2* 

$\int_1^2 d(T+\Pi)=A_12$

т. е. изменение полной механической энергии системы при переходе из одного состояния в другое равно работе, совершенной при этом внешними неконсервативными силами. Если внешние неконсервативные силы отсутствуют, то из (2) следует, что

$d(Т + П) = 0$,

откуда

$Т + П = E = \text{const}$, (3)

т. е. полная механическая энергия системы сохраняется постоянной. Выражение (3) представляет собой **закон сохранения механической энергии:** в системе тел, между которыми действуют только консервативные силы, полная механическая энергия сохраняется, т. е. не изменяется со временем.

Механические системы, на тела которых действуют только консервативные силы (внутренние и внешние), называются **консервативными системами**. Закон сохранения механической энергии можно сформулировать так: в консервативных системах полная механическая энергия сохраняется.

Закон сохранения механической энергии связан с *однородностью времени*, т. е. инвариантностью физических законов относительно выбора начала отсчета времени. Например, при свободном падении тела в поле сил тяжести его скорость и пройденный путь зависят лишь от начальной скорости и продолжительности свободного падения тела и не зависят от того, когда тело начало падать.

Существует еще один вид систем — **диссипативные системы,** в которых механическая энергия постепенно уменьшается за счет преобразования в другие (немеханические) формы энергии. Этот процесс получил название **диссипации** (или **рассеяния энергии**). Строго говоря, все системы в природе являются диссипативными.

В консервативных системах полная механическая энергия остается постоянной. Могут происходить лишь превращения кинетической энергии в потенциальную и обратно в эквивалентных количествах, так что полная энергия остается неизменной. Поэтому, как указывает Ф. Энгельс, этот закон не есть просто закон *количественного* сохранения энергии, а закон сохранения и превращения энергии, выражающий и *качественную* сторону взаимного превращения различных форм движения друг в друга. Закон сохранения и превращения энергии — *фундаментальный закон природы*, он справедлив как для систем макроскопических тел, так и для систем микротел.

В системе, в которой действуют также неконсервативные силы, например силы трения, полная механическая энергия системы не сохраняется. Следовательно, в этих случаях закон сохранения механической энергии несправедлив. Однако при «исчезновении» механической энергии всегда возникает эквивалентное количество энергии другого вида. Таким образом, *энергия никогда не исчезает и не появляется вновь, она лишь превращается из одного вида в другой*. В этом и заключается *физическая сущность* закона сохранения и превращения энергии — сущность неуничтожимости материи и ее движения.

#### 3.12.3.4 Графическое представление энергии

Во многих задачах рассматривается одномерное движение тела, потенциальная энергия которого является функцией лишь одной переменной (например, координаты $х$), т. е. $\Pi=\Pi(x)$. График зависимости потенциальной энергии от некоторого аргумента называется **потенциальной кривой**. Анализ потенциальных кривых позволяет определить характер движения тела.

Будем рассматривать только консервативные системы, т. е. системы, в которых взаимные превращения механической энергии в другие виды отсутствуют.

![](3.files/image017.jpg)

Тогда справедлив закон сохранения энергии в форме (3). Рассмотрим графическое представление потенциальной энергии для тела в однородном поле тяжести и для упругодеформированного тела.

Потенциальная энергия тела массой $m$, поднятого на высоту $h$ над поверхностью Земли, согласно параграфу о потенциальной энергии (7), $\Pi(h) = mgh$. График данной зависимости $\Pi = \Pi(h)$ — прямая линия, проходящая через начало координат (рис. 15), угол наклона которой к оси $h$ тем больше, чем больше масса тела (так как $\tg\alpha = mg$).

Пусть полная энергия тела равна $Е$ (ее график— прямая, параллельная оси $h$). На высоте $h$ тело обладает потенциальной энергией $\Pi$, которая определяется отрезком вертикали, заключенным между точкой $h$ на оси абсцисс и графиком $\Pi(h)$. Естественно, что кинетическая энергия $Т$ задается ординатой между графиком $\Pi(h)$ и горизонтальной прямой $ЕЕ$. Из рис. 15 следует, что если $h = h_\text{max}$ , то $Т = 0$ и $П = E = mgh_\text{max}$ , т. е. потенциальная энергия становится максимальной и равной полной энергии.

Из приведенного графика можно найти скорость тела на высоте $h$: 

$T=E-П$ ,

т. е.

$\frac{mv^2}{2} = m g h_\text{max} - m g h$, откуда

$$v = \sqrt{2g(h_\text{max} -h)}.$$ 

Зависимость потенциальной энергии упругой деформации $П = (k x^2)/2$ от деформации $х$ имеет вид параболы (рис. 16), где график заданной полной энергии тела $Е$ — прямая, параллельная оси

![](3.files/image018.jpg)

абсцисс $х$, а значения $Т$ и $П$ определяются так же, как на рис. 15. Из рис. 16 следует, что с возрастанием деформации $х$ потенциальная энергия тела возрастает, а кинетическая — уменьшается. Абсцисса $x_\text{max}$ определяет максимально возможную деформацию растяжения тела, а $-x_\text{max}$ —максимально возможную деформацию сжатия, тела. Если $х= ± x_\text{max}$ , то $T = 0$ и $П = E = (kx_\text{max}^2)/2$, т. е. потенциальная энергия становится максимальной и равной полной энергии.

Из анализа графика на рис. 16 вытекает, что при полной энергии тела, равной $Е$, тело не может сместиться правее $x_\text{max}$ и левее $-x_\text{max}$ , так как кинетическая энергия не может быть отрицательной величиной и, следовательно, потенциальная энергия не может быть больше полной. В таком случае говорят, что тело находится в **потенциальной яме** с координатами

$-x_\text{max} <= x <= x_\text{max}$ .

В общем случае потенциальная кривая может иметь довольно сложный вид, например с несколькими чередующимися максимумами и минимумами (рис.17). Проанализируем эту потенциальную кривую.

![](3.files/image019.jpg)

Если $Е$ — заданная полная энергия частицы, то частица может находиться только там, где $П(х) <= E$ , т.е. в областях I и III. Переходить из области I в III и обратно частица не может, так как ей препятствует **потенциальный барьер** *CDG*,  ширина которого равна интервалу значений $х$, при которых $E<П$, а его высота определяется разностью $П_\text{max} - E$ . Для того чтобы частица смогла преодолеть потенциальный барьер, ей необходимо сообщить дополнительную энергию, равную высоте барьера или превышающую ее. В области 1 частица с полной энергией $Е$ оказывается «запертой» в потенциальной яме ABC и совершает колебания между точками с координатами $x_A$ и $х_C$ . 

В точке $В$ с координатой $x_0$ (рис. 17) потенциальная энергия частицы минимальна. Так как действующая на частицу сила (см. §12) $F_х =-\frac{\partial П}{\partial х}$ $П$ — функция только одной координаты), а условие минимума потенциальной энергии $\frac{\partial П}{\partial х}=0$, то в точке $В$ $F_x = 0$. При смещении частицы из положения $x_0$ (и влево, и вправо) она испытывает действие возвращающей силы, поэтому положение $x_0$ является положением **устойчивого равновесия**. Указанные условия выполняются и для точки $х'_0$ (для $П_\text{max}$ ). Однако эта точка соответствует положению **неустойчивого равновесия,** так как при смещении частицы из положения $х'_0$ появляется сила, стремящаяся удалить ее от этого положения.

#### 3.12.3.5 Удар абсолютно упругих и неупругих тел

Примером применения законов сохранения импульса и энергии при решении реальной физической задачи является столкновение абсолютно упругих и неупругих тел.

Удар (или **соударение**) — это столкновение двух или более тел, при котором взаимодействие длится короткое время. Исходя из данного определения, кроме явлений, которые можно отнести к ударам в прямом смысле этого слова (столкновения атомов или биллиардных шаров), сюда можно отнести и такие, как удар человека о землю при прыжке с лесницы и т. д. При ударе в телах возникают столь значительные внутренние силы, что внешними силами, действующими на них, можно пренебречь. Это позволяет рассматривать соударяющиеся тела как замкнутую систему и применять к ней законы сохранения.

Тела во время удара претерпевают деформацию. Сущность удара заключается в том, что кинетическая энергия относительного движения соударяющихся тел на короткое время преобразуется в энергию упругой деформации. Во время удара имеет место перераспределение энергии между соударяющимися телами. Наблюдения показывают, что относительная скорость тел после удара не достигает своего прежнего значения. Это объясняется тем, что нет идеально упругих тел и идеально гладких поверхностей. Отношение нормальных составляющих относительной скорости тел после и до удара называется **коэффициентом восстановления** $\epsilon$ :

$$\epsilon = \frac{v'_n}{v_n} .$$

Если для сталкивающихся тел $\epsilon = 0$, то такие тела называются *абсолютно неупругими*, если $\epsilon = 1$ — *абсолютно упругими*. 

На практике для всех тел $0< \epsilon <1$ (например, для стальных шаров $\epsilon \approx 0,56$, для шаров из слоновой кости $\epsilon \approx 0,89$, для свинца $\epsilon \approx 0$). Однако в некоторых случаях тела можно с большой точностью рассматривать либо как абсолютно упругие, либо как абсолютно неупругие.

Прямая, проходящая через точку соприкосновения тел и нормальная к поверхности их соприкосновения, называется **линией удара**. Удар называется **центральным**, если тела до удара движутся вдоль прямой, проходящей через их центры масс. Мы будем рассматривать только центральные абсолютно упругие и абсолютно неупругие удары.

**Абсолютно упругий удар** —  столкновение двух тел, в результате которого в обоих взаимодействующих телах не остается никаких деформаций и вся кинетическая энергия, которой обладали тела до удара, после удара снова превращается в кинетическую энергию.

![](3.files/image020.jpg)

Для абсолютно упругого удара выполняются закон сохранения импульса и закон сохранения кинетической энергии.

Обозначим скорости шаров массами $m_1$ и $m_2$ до удара через $\vec v_1$ и $\vec v_2$ , после удара — через $\vec v'_1$ и $\vec v'_2$ (рис. 18). При прямом центральном ударе векторы скоростей шаров до и после удара лежат на прямой линии, соединяющей их центры. Проекции векторов скорости на эту линию равны модулям скоростей. Их направления учтем знаками: положительное значение припишем движению вправо, отрицательное — движению влево.

При указанных допущениях законы сохранения имеют вид

$$m_1\vec v_1+m_2\vec v_2=m_1\vec v'_1+m_2\vec v'_2 (1)$$

$$\frac{m_1\vec v_1^2}{2}+\frac{m_2\vec v_2^2}{2}=\frac{m_1\vec v`_1^2}{2}+\frac{m_2\vec v`_2^2}{2} (2)$$

Произведя соответствующие преобразования в выражениях (1) и (2), получим

$$m_1(\vec v_1-\vec v`_1)=m_2(\vec v`_2-\vec v_2) (3)$$

$$m_1(\vec v_1^2-\vec v`_1^2)=m_2(\vec v`_2^2-\vec v_2^2) (4)$$

 откуда

$$\vec v_1+\vec v`_1 = \vec v_2+\vec v`_2 (5)$$

Решая уравнения (3) и (5), находим

$$\vec v'_1=\frac{(m_1-m_2)\vec v_1+2m_2\vec v_2}{m_1+m_2} (6)$$

$$\vec v'_2=\frac{(m_2-m_1)\vec v_2+2m_1\vec v_1}{m_1+m_2}$$

Разберем несколько примеров.

1) При $\vec v_2=0$
$$\vec v'_1=\frac{m_1-m_2}{m_1+m_2} \vec v_1 (8)$$
$$\vec v'_2=\frac{2m_1}{m_1+m_2} \vec v_1 (9)$$

Проанализируем выражения (8) и (9) для двух шаров различных масс:

а) $m_1 = m_2$ . Если второй шар до удара висел неподвижно $\vec v_2 = 0$ (рис. 19), то после удара остановится первый шар $\vec v'_1 =0$, а второй будет двигаться с той же скоростью и в том же направлении, в котором двигался первый шар до удара $\vec v'_2 = \vec v_1$ ; 

б) $m_1 > m_2$ .

![](3.files/image025.jpg)

Первый шар продолжает двигаться в том же направлении, как и до удара, но с меньшей скоростью $\vec v'_1 < \vec v_1$. Скорость второго шара после удара больше, чем скорость первого после удара $\vec v'_2 > \vec v'_1$ (рис.20);

![](3.files/image026.jpg)

в) $m_1< m_2$. Направление движения первого шара при ударе изменяется — шар отскакивает обратно. Второй шар движется в ту же сторону, в которую двигался первый шар до удара, но с меньшей скоростью, т.е.  $\vec v'_2 < \vec v_1$(рис. 21);

г) $m_2 > > m_1$ (например, столкновение шара со стеной). Из уравнений (8) и (9) следует, что $\vec v'_1 = - \vec v_1$ , $\vec v'_2 \approx \frac{2 m_1\vec v_1}{m_2} \approx 0.$

![](3.files/image027.jpg)

2) При $m_1= m_2$ выражения (6) и (7) будут иметь вид

 $\vec v'_1 = \vec v_2 , \vec v'_2 = \vec v_1$ , 

т. е. шары равной массы «обмениваются» скоростями.

**Абсолютно неупругий удар** —  столкновение двух тел, в результате которого тела объединяются, двигаясь дальше как единое целое.

![](3.files/image028.jpg)

Продемонстрировать абсолютно неупругий удар можно с помощью шаров из пластилина (глины), движущихся навстречу друг другу (рис. 22).

Если массы шаров $m_1$ и $m_2$, их скорости до удара $\vec v_1$ и $\vec v_2$, то, используя закон сохранения импульса, можно записать

$$m_1\vec v_1+m_2\vec v_2=(m_1+m_2)\vec v,$$
 откуда 
$$\vec v=\frac{m_1\vec v_1+m_2\vec v_2}{m_1+m_2} (10)$$

Если шары движутся навстречу друг другу, то они вместе будут продолжать двигаться в ту сторону, в которую двигался шар, обладающий большим импульсом. В частном случае если массы шаров равны $m_1 = m_2$ , то

$\vec v = (\vec v_1 + \vec v_2)/2.$

Выясним, как изменяется кинетическая энергия шаров при центральном абсолютно неупругом ударе. Так как в процессе соударения шаров между ними действуют силы, зависящие не от самих деформаций, а от их скоростей, то мы имеем дело с силами, подобными силам трения, поэтому закон сохранения механической энергии не должен соблюдаться. Вследствие деформации происходит «потеря» кинетической энергии, перешедшей в тепловую или другие формы энергии. Эту «потерю» можно определить по разности кинетической энергии тел до и после удара:

$$\Delta T=\frac{m_1\vec v_1^2}{2}+\frac{m_2\vec v_2^2}{2}-\frac{(m_1+m_2)\vec v^2}{2}.$$ 
Используя (10), получим 
$$\Delta T=\frac{m_1m_2}{2(m_1+m_2)}(\vec v_1-\vec v_2)^2.$$

Если ударяемое тело было первоначально неподвижно $\vec v_2 =  0$ , то 

$\vec v=\frac{m_1\vec v_1}{m_1+m_2}$, $\Delta T=\frac{m_2}{(m_1+m_2)}\frac{m_1\vec v_1^2}{2}.$

Когда $m_2 >> m_1$ (масса неподвижного тела очень большая), то $\vec v << \vec v_1$ и почти вся кинетическая энергия тела при ударе переходит в другие формы энергии. Поэтому, например, для получения значительной деформации наковальня должна быть массивнее молотка. Наоборот, при забивании гвоздей в стену масса молотка должна быть гораздо большей $m_1 > > m_2$ , тогда $\vec v \approx \vec v_1$ и практически вся энергия затрачивается на возможно большее перемещение гвоздя, а не на остаточную деформацию стены.

Абсолютно неупругий удар — пример того, как происходит «потеря» механической энергии под действием диссипативных сил.


### 3.12.4 Механика твердого тела



#### 3.12.4.1 Момент инерции

При изучении вращения твердого тела пользуются понятием момента инерции. **Моментом инерции** системы (тела) относительно оси вращения называется физическая величина, равная сумме произведений масс $n$ материальных точек системы на квадраты их расстояний до рассматриваемой оси:

$$J=\sum_{i=1}^n m_i r_i^2$$

В случае непрерывного распределения масс эта сумма сводится к интегралу

$$J=\int r^2 dm,$$

где интегрирование производится по всему объему тела. Величина $r$ в этом случае есть функция положения точки с координатами $х$, $у$, $z$ . 

В качестве примера найдем момент инерции однородного сплошного цилиндра высотой $h$ и радиусом $R$ относительно его геометрической оси (рис.23). 

![](4.files/image003.jpg)

Разобьем цилиндр на отдельные полые концентрические цилиндры бесконечно малой толщины $dr$ с внутренним радиусом $r$ и внешним — $r+dr$ . Момент инерции каждого полого цилиндра $dJ = r ^2 dm$ (так как $dr << r$, то считаем, что расстояние всех точек цилиндра от оси равно $r$ ), где $dm$ — масса всего элементарного цилиндра; его объем $2 \pi r h * dr$. Если $\rho$ — плотность материала, то $2 \pi r h \rho * dr$ и $dJ = 2 \pi h \rho r^3 dr$. Тогда момент инерции сплошного цилиндра

$$J = \int dJ = 2\pi h \rho \int_0^R r^3 dr = \frac{1}{2}\pi h R^4\rho,$$

но так как $\pi R^2 h$ — объем  цилиндра, то его масса $\pi R^2 h * \rho$ , а момент инерции

$$J = \frac{1}{2} m R^2 .$$

Если известен момент инерции тела относительно оси, проходящей через его центр масс, то момент инерции относительно любой другой параллельной оси определяется **теоремой Штейнера**: момент инерции тела $J$ относительно любой оси вращения равен моменту его инерции $J_c$ относительно параллельной оси, проходящей через центр масс $С$ тела, сложенному с произведением массы $m$ тела на квадрат расстояния $d$ между осями: $J = J_c+ m d^2$ . (1)

Таблица 1

![](4.files/image005.jpg)

В заключение приведем значения моментов инерции (табл. 1) для некоторых тел (тела считаются однородными, $m$ — масса тела).

#### 3.12.4.2 Кинетическая энергия вращения

Рассмотрим абсолютно твердое тело (см. § 1), вращающееся около неподвижной оси $z$, проходящей через него (рис. 24). Мысленно разобьем это тело на маленькие объемы с элементарными массами $m_1, m_2 , \ldots, m_n$, находящиеся на расстоянии $r_1, r_2 , \ldots, r_n$ от оси вращения. При вращении твердого тела относительно неподвижной оси отдельные его элементарные объемы массами $m_i$, опишут окружности различных радиусов $r_i$ и имеют различные линейные скорости $v_i$. Но так как мы рассматриваем абсолютно твердое тело, то угловая скорость вращения этих объемов одинакова:

$$\omega = \frac{v_1}{r_1} = \frac{v_2}{r_2} = \ldots = \frac{v_n}{r_n} .  (1)$$

Кинетическую энергию вращающегося тела найдем как сумму кинетических энергий его элементарных объемов:

$$T_{\text{вр}} = \frac{m_1 v_1^2}{2} + \frac{m_2 v_2^2}{2} + \ldots + \frac{m_n v_n^2}{2},$$

![](4.files/image007.jpg)

или
приложения силы, на силу
$$T_{\text{вр}} = \sum_{i=1}^n\frac{m_i v_i^2}{2}.$$

Используя выражение (1), получим

$$T_{\text{вр}}=\sum_{i=1}^n\frac{m_i \omega^2}{2} r_i^2 = \frac{\omega^2}{2} \sum_{i=1}^nm_i r_i^2 = \frac{J_z\omega^2}{2},$$

где $J_z$ — момент инерции тела относительно оси 2. Таким образом, кинетическая энергия вращающегося тела

$$T_\text{вр}= \frac{J_z\omega^ 2}{2} . (2)$$

Из сравнения формулы (2) с выражением из параграфа о кинетической энергии тела (1), движущегося поступательно $T = (m v^2)/2$, следует, что момент инерции вращательного движения — *мера инертности тела*. Формула (2) справедлива для тела, вращающегося вокруг неподвижной оси.

В случае плоского движения тела, например цилиндра, скатывающегося с наклонной плоскости без скольжения, энергия движения складывается из энергии поступательного движения и энергии вращения:

$$T=\frac{m v_C^2}{2}+\frac{J_C \omega^2}{2},$$

где $m$ — масса катящегося тела; $v_c$ — скорость центра масс тела; $J_с$ — момент инерции тела относительно оси, проходящей через его центр масс; $\omega$ — угловая скорость тела.

#### 3.12.4.3 Момент силы. Уравнение динамики вращательного движения твердого тела

**Моментом силы F относительно неподвижной точки**  $О$ называется физическая величина, определяемая векторным произведением радиуса-вектора $\vec r$, проведенного из точки $О$ в точку $А$ приложения силы, на силу $\vec F$ (рис. 25):

$$\vec M = [ \vec r \vec F ]_z .$$

![](4.files/image011.jpg)

Здесь $М$ — псевдовектор, его направление совпадает с направлением поступательного движения правого винта при его вращении от $\vec r$ к $\vec F$ .

Модуль момента силы

$$M = F r \sin\alpha = Fl , (1)$$

где $a$ — угол между $\vec r$ и $\vec F$ ; $r \sin\alpha = l$ — кратчайшее расстояние между линией действия силы и точкой О — **плечо силы**. 

**Моментом силы относительно неподвижной оси $z$** называется *скалярная* величина $М_z$, равная проекции на эту ось вектора $М$ момента силы, определенного относительно произвольной точки $О$ данной оси $z$ (рис.26). Значение момента $М_z$ не зависит от выбора положения точки $О$ на оси $z$. 



![](4.files/image012.jpg)

![](4.files/image013.jpg)

Если ось $z$ совпадает с направлением вектора $М$ , то момент силы представляется в виде вектора, совпадающего с осью:

$$\vec М_z= [ \vec r \vec F ]_z .$$

Найдем выражение для работы при вращении тела (рис.27). Пусть сила $F$ приложена в точке $В$, находящейся от оси вращения на расстоянии $r$ , $\alpha$ — угол между направлением силы и радиусом-вектором $r$ . Так как тело абсолютно твердое, то работа этой силы равна работе, затраченной на поворот всего тела. При повороте тела на бесконечно малый угол $d\varphi$ точка приложения $В$ проходит путь $ds = r d\varphi$ , и работа равна произведению проекции силы на направление смещения на величину смещения:

 $$dA = F \cdot \sin\alpha \cdot r \cdot d\varphi . (2) $$
 Учитывая (1), можем записать 
 $$d A = M_z d\varphi ,$$

где $F r \sin\alpha = F l = M_z$ — момент силы относительно оси $z$. Таким образом, работа при вращении тела равна произведению момента действующей силы на угол поворота.

Работа при вращении тела идет на увеличение его кинетической энергии:

$dA = dT$ , но

$dT=d(\frac{J_z \omega^2}{2}) = J_z\omega * d\omega$, поэтому $M_z d\varphi = J_z\omega d\omega$ , или $M_z \frac{d\varphi}{dt} = J_z\omega \frac{d\omega}{dt}$

Учитывая, что $\omega = \frac{d\varphi}{dt}$ , получим

$$M_z = J_z\frac{d\omega}{dt} = J_z\epsilon, (3)$$

Уравнение (3) представляет собой **уравнение динамики вращательного движения твердого тела** относительно неподвижной оси.

Можно показать, что если ось вращения совпадает с главной осью инерции (см. §20), проходящей через центр масс, то имеет место векторное равенство

$$\vec M = J\vec\epsilon,  (4)$$

где $J$ — главный момент инерции тела (момент инерции относительно главной оси).

#### 3.12.4.4 Момент импульса и закон его сохранения

При сравнении законов вращательного и поступательного движений просматривается аналогия между ними, только во вращательном движении вместо силы «выступает» ее момент, роль массы играет момент инерции. Какая же величина будет аналогом импульса тела? Ею является момент импульса тела относительно оси.

**Моментом импульса (количества движения)**  материальной точки *А* **относительно неподвижной точки** О называется физическая величина, определяемая векторным произведением:

$$\vec L = [ \vec r, \vec p ] = [ \vec r, m\vec v ] ,$$

![](4.files/image017.jpg)

где $r$ — радиус-вектор, проведенный из точки $О$ в точку $A$; $p = m v$ — импульс материальной точки (рис.28); $L$ —псевдовектор, его направление совпадает с направлением поступательного движения правого винта при его вращении от $r$ к $p$ . Модуль вектора момента импульса

 $$L = r p \sin\alpha = mv r \sin\alpha = p l ,$$ 

где $\alpha$ — угол между векторами $r$ и $p$ , $l$ — плечо вектора $р$ относительно точки $О$. 

**Моментом импульса относительно неподвижной оси** $z$ называется скалярная величина $L_z$, равная проекции на эту ось вектора момента импульса, определенного относительно произвольной точки $О$ данной оси. Значение момента импульса $L_z$ не зависит от положения точки $О$ на оси $z.$

При вращении абсолютно твердого тела вокруг неподвижной оси $z$ каждая отдельная точка тела движется по окружности постоянного радиуса $r_i$ с некоторой скоростью $\vec v_i$ . Cкорость $\vec v_i$ ; и импульс $m_i \vec v_i$

перпендикулярны этому радиусу, т. е. радиус является плечом вектора $m_i \vec v_i$. Поэтому можем записать, что момент импульса отдельной частицы

$$L_{iz} = m_i v_i r_i, (1)$$

и направлен по оси в сторону, определяемую правилом правого винта.

**Момент импульса твердого тела**  относительно оси есть сумма моментов импульса отдельных частиц:

$$L_z = \sum_{i=1}^n m_i v_i r_i$$

Используя формулу из параграфа о Кинетической энергии вращения (1) $v_i= \omega r_i$ , получим

$$L_z = \sum_{i=1}^n m_i r_i^2\omega = \omega\sum_{i=1}^n m_i r_i^2 = J_z\omega,$$

т. е.

$$L_z= J_z\omega . (2)$$

Таким образом, момент импульса твердого тела относительно оси равен произведению момента инерции тела относительно той же оси на угловую скорость.

Продифференцируем уравнение (2) по времени:

$\frac{dL_z}{dt} = J_z\frac{d\omega}{dt} = J_z\epsilon = M_z$, т. е.

$$\frac{dL_z}{dt} = M_z$$

Это выражение — еще одна форма **уравнения (закона) динамики вращательного движения твердого тела** относительно неподвижной оси: производная момента импульса твердого тела относительно оси равна моменту сил относительно той же оси.

Можно показать, что имеет место векторное равенство

$$\frac{d\vec L}{dt} = \vec М . (3)$$

В замкнутой системе момент внешних сил $\vec М = 0$ и $\frac{d\vec L}{dt} = 0$, откуда

$$L = \text{const} . (4)$$

Выражение (4) представляет собой **закон сохранения момента импульса**: момент импульса замкнутой системы сохраняется, т. е. не изменяется с течением времени.

Закон сохранения момента импульса — *фундаментальный закон природы*, Он связан со свойством симметрии пространства — его *изотропностью*, т. е. с инвариантностью физических законов относительно выбора направления осей координат системы отсчета (относительно поворота замкнутой системы в пространстве на любой угол).

![](4.files/image021.jpg)

![](4.files/image022.jpg)

Продемонстрировать закон сохранения момента импульса можно с помощью скамьи Жуковского. Пусть человек на скамье, которая без трения вращается вокруг вертикальной оси, и держит на вытянутых руках гантели (рис. 29), приведен во вращение с угловой скоростью $\omega_1$ . Если человек прижмет гантели к себе, то момент инерции системы уменьшится. Поскольку момент внешних сил равен нулю, момент импульса системы сохраняется и угловая скорость вращения $\omega_2$ возрастает. Аналогично, гимнаст во время прыжка через голову поджимает к туловищу руки и ноги, чтобы уменьшить свой момент инерции и увеличить тем самым угловую скорость вращения.

Сопоставим основные величины и уравнения, определяющие вращение тела вокруг неподвижной оси и его поступательное движение в таблице 2:

| Поступательное движение                  | Вращательное движение |
| ---------------------------------------- | --------------------- |
| Масса $m$                                | Момент инерции $J$    |
| Скорость $\vec v = \frac{d \vec r}{dt}$  | Угловая скорость $\vec \omega = \frac{d \vec \phi}{dt}$ |
| Ускорение $\vec a = \frac{d \vec v}{dt}$ | Угловое ускорение $\vec \epsilon = \frac{d \vec \omega}{dt}$ |
| Сила $\vec F$                            | Момент силы $M_z$ или $\vec M$ |
| Импульс $\vec p = m \vec v$              | Момент импульса $L_z = J_z \omega$ |
| Основное уравнение динамики $\vec F =m \vec a$ $\vec F = \frac{\vec p}{dt}$ | Основное уравнение динамики $M_z = J_z \epsilon$ $\vec M = \frac{d \vec L}{dt}$
| Работа $dA = F_s ds$                     | Работа $dA = M_z d\phi$ |
| Кинетическая энергия $\frac{m v^2}{2}$   | Кинетическая энергия $\frac{J_z \omega^2}{2}$ |


## 3.13 Резюме

Работа в области обнаружения столкновений требует твердого знания геометрии и линейной алгебры, не говоря уже о математике в целом. В этой главе были рассмотрены некоторые концепции из этих областей, которые пронизывают всю книгу. В частности, важно полностью понимать свойства скалярных, векторных и скалярных тройных произведений, поскольку они используются, например, при выводе практически всех примитивных тестов на пересечение (см. Главу 5). Читатели, которые не чувствуют себя комфортно с этими математическими понятиями, могут захотеть обратиться к учебникам линейной алгебры, таким как те, которые упомянуты во введении к главе.

В этой главе также был рассмотрен ряд геометрических понятий, включая точки, прямые, лучи, сегменты, плоскости, полупространства, многоугольники и многогранники. Восхитительное введение в эти и другие геометрические концепции дано в [Mortenson99]. Также были рассмотрены соответствующие концепции из вычислительной геометрии и теории выпуклых множеств. Области Вороного важны при вычислении ближайших точек. Существование разделяющих плоскостей и осей для непересекающихся выпуклых объектов позволяет проводить эффективные тесты на разделение этих объектов, как более подробно обсуждается в главах 5 и 9. Операции суммы и разности Минковского позволяют преобразовать некоторые задачи обнаружения столкновений в другую форму. что может быть проще вычислить. В главах 5 и 9 обсуждаются также такие преобразования.

Хорошим введением в область вычислительной геометрии является [O’Rourke98]. Теория выпуклых множеств (в контексте выпуклой оптимизации) обсуждается в [Boyd04].

Более сложное моделирование учитывает физическую природу взаимодействий. Начиная с рассмотрения абсолютно твёрдых тел.

# Глава 4
# Ограничивающие объёмы

Непосредственная проверка геометрии двух объектов на предмет столкновения друг с другом часто бывает очень дорогой, особенно когда объекты состоят из сотен или даже тысяч полигонов. Чтобы минимизировать эту стоимость, ограничивающие объемы объекта обычно проверяются на пересечение перед выполнением проверки пересечения геометрии.

Ограничивающий объем (bounding volume, BV) - это один простой объем, вмещающий один или несколько объектов более сложной природы. Идея состоит в том, чтобы более простые объемы (такие как параллелипипеды и сферы) имели более дешевые тесты на пересечение, чем сложные объекты, которые они связывали. Использование ограничивающих объемов позволяет проводить быстрые тесты на отсутствие перекрытия, потому что нужно проверять сложную геометрию, только когда первоначальный запрос перекрытия для ограничивающих объемов дает положительный результат (рисунок 4.1).

Конечно, когда объекты действительно перекрываются, этот дополнительный тест приводит к увеличению времени вычислений. Однако в большинстве случаев несколько объектов обычно находятся достаточно близко, чтобы их ограничивающие объемы перекрывались. Следовательно, использование ограничивающих объемов обычно приводит к значительному увеличению производительности, а исключение сложных объектов из дальнейших тестов хорошо оправдывает небольшие дополнительные затраты, связанные с тестом ограничивающего объема.

Для некоторых приложений тест пересечения ограничивающего объема сам по себе служит достаточным доказательством столкновения. Если этого не происходит, обычно все же целесообразно обрезать содержащиеся объекты, чтобы ограничить дальнейшие тесты полигонами, содержащимися в перекрытии ограничивающих объемов. Тестирование полигонов объекта A по сравнению с полигонами объекта B обычно имеет сложность $O(n^2)$. Таким образом, если количество тестируемых полигонов можно, скажем, сократить вдвое, рабочая нагрузка снизится на 75%. Глава 6, посвященная иерархиям ограничивающих объемов, дает более подробную информацию о том, как сократить тестирование объектов и полигонов до минимума. В этой главе обсуждение ограничивается тестами пар ограничивающих объемов. Кроме того, представленные здесь тесты в основном однородны в том смысле, что ограничивающие объемы одного и того же типа тестируются друг против друга. Однако нередко можно использовать несколько типов ограничивающих объемов одновременно. Несколько тестов на неоднородное пересечение BV обсуждаются в следующей главе.

**Рисунок 4.1** Ограничивающие объемы A и B не перекрываются, и, следовательно, A и B не могут пересекаться. Нельзя исключать пересечение между C и D, потому что их ограничивающие объемы перекрываются.

В качестве ограничивающих рамок были предложены многие геометрические формы. В этой главе основное внимание уделяется наиболее часто используемым формам; а именно сферы, параллелипипеды и выпуклые корпусные объемы. Несколько менее распространенных ограничивающих объемов приведены в Разделе 4.7.

## 4.1 Желательные характеристики BV

Не все геометрические объекты служат эффективными ограничивающими объемами. Желательные свойства ограничивающих объемов включают:

- Недорогие тесты на пересечение
- Плотное прилегание
- Недорого в вычислении
- Легко вращать и перемещать
- Занимает мало памяти

Ключевая идея, лежащая в основе ограничивающих объемов, заключается в том, чтобы предшествовать дорогим геометрическим тестам менее дорогостоящие тесты, которые позволяют тесту выйти раньше, так называемый «ранний выход». Для поддержки недорогих тестов на пересечение ограничивающий объем должен иметь простую геометрическую форму. В то же время, чтобы сделать испытание на раннем этапе максимально эффективным, ограничивающий объем должен быть как можно более плотным, что приведет к компромиссу между стоимостью испытания на герметичность и пересечением. Тест на пересечение не обязательно охватывает только сравнение с объемами одного и того же типа, но может также тестировать с другими типами ограничивающих объемов. Кроме того, тестирование может включать в себя такие запросы, как включение точек, пересечение луча с объемом и пересечение с плоскостями и многоугольниками.

**Рисунок 4.2** Типы ограничивающих объемов: сфера, выровненный по оси ограничивающий параллелипипед (axis-aligned bounding box, AABB), ориентированный ограничивающий параллелипипед (oriented
bounding box, OBB), дискретный многогранник ориентации по восьми направлениям (eight-direction discrete orientation polytope, 8-DOP) и выпуклая оболочка.

Ограничивающие объемы обычно вычисляются на этапе предварительной обработки, а не во время выполнения. Тем не менее, важно, чтобы их конструкция не влияла отрицательно на время создания ресурсов. Однако некоторые ограничивающие объемы необходимо повторно выровнять во время выполнения при перемещении содержащихся в них объектов. Для них, если вычисление ограничивающего объема является дорогостоящим, повторное выравнивание ограничивающего объема предпочтительнее (дешевле), чем его пересчет с нуля.

Поскольку ограничивающие объемы хранятся в дополнение к геометрии, в идеале они должны добавлять немного дополнительной памяти к геометрии. Более простые геометрические формы требуют меньше памяти. Поскольку многие из желаемых свойств в значительной степени исключают друг друга, отсутствие определенного ограничивающего объема - лучший выбор для всех ситуаций. Вместо этого лучше всего протестировать несколько разных ограничивающих объемов, чтобы определить наиболее подходящий для данного приложения. На рисунке 4.2 показаны некоторые компромиссы между пятью наиболее распространенными типами ограничивающего объема. Данный порядок в отношении лучших границ, лучшего отбора, более быстрых тестов и меньшего объема памяти следует рассматривать как приблизительное, а не абсолютное руководство. Первым из ограничивающих объемов, рассматриваемых в этой главе, является выровненный по оси ограничивающий параллелипипед, описанный в следующем разделе.

## 4.2 Выровненные по оси ограничительные параллелипипеды (Axis-aligned Bounding Boxes, AABBs)

Выровненный по оси ограничивающий прямоугольник (AABB) - один из наиболее распространенных ограничивающих объемов. Это прямоугольный шестигранный блок (в 3D, четырехсторонний в 2D), грани которого ориентированы таким образом, что нормали его граней всегда параллельны осям данной системы координат. Лучшая особенность AABB - это быстрая проверка перекрытия, которая просто включает прямое сравнение отдельных значений координат.

**Рисунок 4.3** Три распространенных представления AABB: (a) min-max, (b) min-widths и (c) center-radius.

Существует три распространенных представления AABB (рис. 4.3). Один - по минимальному и максимальному значениям координат по каждой оси:

```cpp
    // region R = { (x, y, z) | min.x<=x<=max.x, min.y<=y<=max.y, min.z<=z<=max.z }
    struct AABB {
        Point min;
        Point max;
    };
```

Это представление определяет область BV пространства как область между двумя противоположными угловыми точками: min и max. Другое представление - это минимальная угловая точка min и ширина или диаметр dx, dy и dz от этого угла:

```cpp
    // region R = { (x, y, z) | min.x<=x<=min.x+dx, min.y<=y<=min.y+dy, min.z<=z<=min.z+dz}
    struct AABB {
        Point min;
        float d[3]; // диаметр или ширина (dx, dy, dz)
    };
```
Последнее представление определяет AABB как центральную точку C и пределы или радиусы полуширины rx, ry и rz вдоль ее осей:

```cpp
    // region R = { (x, y, z) | |c.x-x|<=rx, |c.y-y|<=ry, |c.z-z|<=rz }
    struct AABB {
        Point c;    // центральная точка AABB
        float r[3]; // радиус или половина ширины (rx, ry, rz)
    };
```

С точки зрения требований к памяти представление центрального радиуса является наиболее эффективным, поскольку значения полуширины часто могут храниться в меньшем количестве бит, чем значения центрального положения. То же самое верно и для значений ширины представления min-width, хотя и в несколько меньшей степени. Наихудшим является представление min-max, в котором все шесть значений должны храниться с одинаковой точностью. Для уменьшения объема памяти требуется представление AABB с использованием целых чисел, а не чисел с плавающей запятой, как здесь используется.

Если объект перемещается только путем переноса, обновление последних двух представлений дешевле, чем представление min-max, потому что необходимо обновить только три из шести параметров. Полезной особенностью представления центрального радиуса является то, что его также можно протестировать как ограничивающую сферу.

### 4.2.1 AABB-AABB пересечение

Тесты на пересечение между AABB просты, независимо от представления. Два AABB перекрываются, только если они перекрываются по всем трем осям, причем их протяженность по каждому измерению рассматривается как интервал на соответствующей оси. Для представления min-max этот тест перекрытия интервалов принимает следующий вид:

```cpp
    int TestAABBAABB(AABB a, AABB b) {
        // Выход без пересечения, если они разделены по оси
        if (a.max[0] < b.min[0] || a.min[0] > b.max[0]) return 0;
        if (a.max[1] < b.min[1] || a.min[1] > b.max[1]) return 0;
        if (a.max[2] < b.min[2] || a.min[2] > b.max[2]) return 0;
        // Перекрытие по всем осям означает, что AABB пересекаются
        return 1;
    }
```

Представление min-ширина наименее привлекательно. Его тест на пересечение, даже если он написан экономно, все равно не сравнится с первым тестом с точки зрения количества выполненных операций:

```cpp
    int TestAABBAABB(AABB a, AABB b) {
        float t;
        if ((t = a.min[0] - b.min[0]) > b.d[0] || -t > a.d[0]) return 0;
        if ((t = a.min[1] - b.min[1]) > b.d[1] || -t > a.d[1]) return 0;
        if ((t = a.min[2] - b.min[2]) > b.d[2] || -t > a.d[2]) return 0;
        return 1;
    }
```

Наконец, представление центр-радиус приводит к следующему тесту на пересечение:

```cpp
    int TestAABBAABB(AABB a, AABB b) {
        if (Abs(a.c[0] - b.c[0]) > (a.r[0] + b.r[0])) return 0;
        if (Abs(a.c[1] - b.c[1]) > (a.r[1] + b.r[1])) return 0;
        if (Abs(a.c[2] - b.c[2]) > (a.r[2] + b.r[2])) return 0;
        return 1;
    }
```

В современных архитектурах вызов **Abs()** обычно преобразуется в одну инструкцию. В противном случае функцию можно эффективно реализовать, просто удалив знаковый бит двоичного представления значения с плавающей запятой. Когда поля AABB объявляются как целые числа, а не как числа с плавающей запятой, альтернативный тест для представления центр-радиус может быть выполнен следующим образом. С целыми числами перекрытие между двумя диапазонами [A, B] и [C, D] может быть определено выражением:

```cpp
overlap = (unsigned int)(B - C) <= (B - A) + (D - C);
```

При принудительном понижении значения без знака в случае, когда C>B, левая часть становится недопустимо большим значением, делая выражение ложным. Принудительное переполнение эффективно заменяет вызов функции абсолютного значения и позволяет записать тест представления центрального радиуса как:

```cpp
    int TestAABBAABB(AABB a, AABB b) {
        int r;
        r = a.r[0] + b.r[0]; if ((unsigned int)(a.c[0] - b.c[0] + r) > r + r) return 0;
        r = a.r[1] + b.r[1]; if ((unsigned int)(a.c[1] - b.c[1] + r) > r + r) return 0;
        r = a.r[2] + b.r[2]; if ((unsigned int)(a.c[2] - b.c[2] + r) > r + r) return 0;
        return 1;
    }
```

Работа с целыми числами позволяет использовать другие приемы реализации, многие из которых зависят от архитектуры. Инструкции SIMD, если они есть, обычно позволяют реализовать тесты AABB в виде всего лишь нескольких инструкций кода (примеры которых можно найти в главе 13). Наконец, в системе обнаружения столкновений, которая должна выполнять огромное количество тестов на пересечение, может быть целесообразно упорядочить тесты в соответствии с вероятностью их проведения. Например, если операции в основном выполняются в почти плоской плоскости xz, проверка координаты y должна выполняться в последнюю очередь, поскольку она вероятнее одинакова.

### 4.2.2 Вычисления и обновления AABB

Ограничивающие объемы обычно задаются в локальном пространстве модели связанных объектов (которое может быть мировым пространством). Чтобы выполнить запрос на пересечение между двумя ограничивающими объемами, объемы должны быть преобразованы в общую систему координат. Выбор стоит между преобразованием двух ограничивающих объемов в мировое пространство и преобразованием одного ограничивающего объема в локальное пространство другого. Одно из преимуществ преобразования в локальное пространство состоит в том, что в результате ему приходится выполнять половину работы по преобразованию в мировое пространство. Это также часто приводит к более жесткому ограничению объема, чем преобразование в мировое пространство. Рисунок 4.4 иллюстрирует эту концепцию. Пересчитанные AABB объектов A и B перекрываются в мировом пространстве (рис. 4.4a). Однако в пространстве объекта B объекты оказываются разделенными (рисунок 4.4c).

**Рисунок 4.4** (a) AABB A и B в мировом пространстве. (b) AABB в локальном пространстве A. (c) AABB в локальном пространстве B.

Точность - еще одна веская причина для преобразования одного ограничивающего объема в локальное пространство другого. Мировое пространственный тест может сдвинуть оба объекта далеко от начала координат. Действие добавления смещения в перенос во время преобразования локальных координат, близких к началу координат ограничивающего объема, может привести к потере многих (или даже всех) бит точности исходных значений. Для локальных пространственных тестов объекты хранятся рядом с исходной точкой и точность расчетов сохраняется. Обратите внимание, однако, что путем корректировки переносов так, чтобы преобразованные объекты были сосредоточены в начале мирового пространства, преобразования также могут быть выполнены для поддержания точности.

Преобразование в мировое пространство становится интересным, когда обновленные ограничивающие объёмы могут кратковременно кэшироваться в течение временного шага. Путем кэширования ограничивающего объема после преобразования любой ограничивающий объем должен быть преобразован только один раз в любое заданное пространство. Поскольку все ограничивающие объемы преобразуются в одно и то же пространство при преобразовании в мировое пространство, это становится преимуществом в ситуациях, когда объекты проверяются на пересечение несколько раз. Напротив, кэширование обновленных ограничивающих объемов вообще не помогает при преобразовании в локальное пространство других ограничивающих объемов, поскольку все преобразования включают либо новые объекты, либо новые целевые системы координат. Кэширование обновленных ограничивающих объемов имеет недостаток, состоящий в почти удвоении необходимого пространства для хранения, так как большинство полей представления ограничивающих объемов изменяются во время обновления.

Некоторые ограничивающие объемы, такие как сферы или выпуклые оболочки, естественным образом преобразуются в любую систему координат, так как они не ограничены определенной ориентацией. Следовательно, они называются невыровненными или (свободно) ориентированными ограничивающими объемами. Напротив, выровненные ограничивающие объемы (такие как AABB) ограничены в том, какую ориентацию они могут принимать. Выровненные ограничивающие объемы необходимо повторно выровнять, поскольку они становятся невыровненными из-за вращения объекта во время движения. Для обновления или реконструкции AABB есть четыре общие стратегии:

- Использование свободного AABB фиксированного размера, который всегда охватывает объект
- Вычисление точной динамической реконструкции из исходного набора точек
- Вычисление плотной динамической реконструкции с использованием восхождения на холм
- Вычисление приблизительной динамической реконструкции из повернутого AABB

В следующих четырех разделах эти подходы рассматриваются более подробно.

### 4.2.3 AABB из ограничивающей объект сферы

Первый метод полностью исключает необходимость изменения формы AABB, делая его достаточно большим, чтобы вмещать объект в любой ориентации. Этот охватывающий AABB фиксированного размера вычисляется как ограничивающий параллелипипед ограничивающей сферы содержащегося объекта A. Ограничивающая сфера, в свою очередь, центрируется в точке поворота P, вокруг которой A вращается. Его радиус r - это расстояние до самой дальней вершины объекта от этого центра (как показано на рисунке 4.5). Убедившись, что точка поворота объекта P находится в центре объекта, радиус сферы минимизируется.

**Рисунок 4.5** AABB ограничивающей сферы, которая полностью содержит объект A при произвольной ориентации.

Преимущество этого представления заключается в том, что во время обновления этот AABB просто необходимо преобразовать (тем же преобразованием, что и ограниченный объект), и любое вращение объекта можно полностью игнорировать. Однако сама ограничивающая сфера (которая имеет лучшие свойства, чем AABB) также будет обладать этим свойством. Таким образом, ограничивающие сферы следует рассматривать как потенциально лучший выбор ограничивающего объема в этом случае.

### 4.2.4 AABB реконструирован из исходного набора точек

Стратегия обновления, описанная в этом разделе (а также две оставшиеся стратегии обновления, которые будут описаны) динамически изменяет размер AABB, поскольку он повторно выравнивается с осями системы координат. Для плотно подогнанного ограничивающего прямоугольника исследуется основная геометрия ограниченного объекта и устанавливаются границы прямоугольника путем нахождения крайних вершин во всех шести направлениях координатных осей. Прямой подход проходит через все вершины, отслеживая вершину, наиболее удаленную от вектора направления. Это расстояние может быть вычислено через проекцию вектора вершины на вектор направления. Для сравнения нет необходимости нормализовать вектор направления. Эта процедура проиллюстрирована в следующем коде, который находит как наименьшие, так и наиболее удаленные точки вдоль вектора направления:

```cpp
    // Возвращает индексы imin и imax в массив pt[] соответственно 
    // наименьшей и наиболее удаленной точки вдоль направления dir
    void ExtremePointsAlongDirection(Vector dir, Point pt[], int n, int *imin, int *imax) {
        float minproj = FLT_MAX, maxproj = -FLT_MAX;
        for (int i = 0; i < n; i++) {
            // Спроецировать вектор от начала до точки на вектор направления
            float proj = Dot(pt[i], dir);
            // Следить за наименее удаленной точкой вдоль вектора направления
            if (proj < minproj) {
                minproj = proj;
                *imin = i;
            }
            // Следить за самой удаленной точкой вдоль вектора направления
            if (proj > maxproj) {
                maxproj = proj;
                *imax = i;
            }
        }
    }
```

Когда n велико, эта процедура $O(n)$ может быть дорогостоящей, если осуществляется во время выполнения. Предварительная обработка данных вершин может ускорить процесс. Один простой подход, который не добавляет никаких дополнительных данных, основан на том факте, что только вершины на выпуклой оболочке объекта могут способствовать определению формы ограничивающего объема (Рисунок 4.6). На этапе предварительной обработки все k вершин выпуклой оболочки объекта будут сохранены таким образом, чтобы они располагались перед всеми оставшимися вершинами. Затем можно построить плотный AABB, исследуя только эти k первых вершин. Для обычных вогнутых объемов это было бы победой, но выпуклый объем, все вершины которого уже находятся на выпуклой оболочке, не улучшится.

Используя дополнительные специализированные предварительно вычисленные структуры поиска, поиск экстремальных вершин может быть выполнен за время $O(\log n)$. Например, для этой цели может использоваться иерархия Добкина–Киркпатрика (описанная в главе 9). Однако из-за дополнительной памяти, необходимой для этих структур, а также из-за накладных расходов при их обходе, в большинстве случаев их следует рассматривать как избыточные. Конечно, если жесткие ограничивающие объемы так важны, следует рассмотреть более жесткие ограничивающие объемы, чем AABB.

### 4.2.5 AABB из восхождения к вершине представления объекта

Другой способ ускорить процесс перестройки AABB - использовать представление объекта, в котором можно быстро найти соседние вершины для вершины. Такое представление позволяет расположить крайние вершины, определяющие новый AABB, путем простого подъема на холм (Рисунок 4.7).

**Рисунок 4.7** (a) Крайняя вершина E в направлении d. (b) После поворота объекта против часовой стрелки новая крайняя вершина E в направлении d может быть получена путем подъема на холм по пути вершины, выделенному серым цветом.

Вместо того, чтобы отслеживать минимальные и максимальные значения экстентов по каждой оси, поддерживаются шесть указателей вершин. Соответствуя тем же значениям, что и раньше, теперь они фактически указывают на (до шести) экстремальных вершин объекта вдоль каждого направления оси. Шаг подъема на холм теперь продолжается путем сравнения указанных вершин с их соседними вершинами, чтобы увидеть, являются ли они по-прежнему экстремальными в том же направлении, что и раньше. Те, которые не были заменены одним из их наиболее крайних соседей, и проверка повторяется до тех пор, пока не будет найдена экстремальная вершина в этом направлении. Чтобы не застрять в локальных минимумах, в процессе подъема на холм предметы должны быть выпуклыми. По этой причине восхождение на холм выполняется на предварительно рассчитанных выпуклых оболочках невыпуклых объектов. В целом, этот пересчет точного AABB является ожидаемой операцией с постоянным временем.

Необходимость преобразовывать вершины только при их фактическом исследовании в процессе восхождения на холм значительно сокращает вычислительные затраты. Однако это можно улучшить, если осознать, что только один из компонентов x, y или z используется для нахождения экстремальной вершины вдоль данной оси. Например, при нахождении экстремальной точки по оси +x необходимо вычислить только x-компоненты преобразованных вершин. Следовательно, трансформационные издержки снижаются на две трети.

Необходимо проявить осторожность, чтобы написать надежную реализацию этого метода восхождения. Рассмотрим экстремальную вершину вдоль любой оси, окруженную только компланарными вершинами. Если теперь объект вращается на 180 градусов вокруг любой из оставшихся двух осей, вершина становится экстремальной в противоположном направлении по той же оси.
Однако, поскольку он окружен компланарными вершинами, шаг подъема на холм не может найти лучшую соседнюю вершину и, таким образом, заканчивается вершиной, которая фактически является наименее экстремальной в искомом направлении! Надежная реализация должна учитывать эту ситуацию. В качестве альтернативы копланарные вершины могут быть удалены на этапе предварительной обработки, как описано в главе 12. Проблема поиска экстремальных вершин вновь рассматривается в разделе 9.5.4.

### 4.2.6 AABB пересчитан из повернутого AABB

Последний из четырех методов перестройки, наиболее распространенный подход - просто обернуть повернутый AABB в новый AABB. Это дает приблизительный, а не точный AABB. Поскольку результирующий AABB больше, чем тот, с которого был начат, важно, чтобы приблизительный AABB вычислялся из поворота исходного AABB локального пространства. В противном случае повторное вычисление из повернутого AABB на предыдущем временном шаге заставит AABB расти бесконечно.

Рассмотрим выровненный по оси ограничивающий параллелипипед A, на который действует матрица вращения **M**, в результате чего ориентированный ограничивающий параллелипипед A' имеет некоторую ориентацию. Три столбца (или строки, в зависимости от используемого матричного соглашения) матрицы вращения **M** задают оси мировых координат A' в его локальной системе координат. (Если векторы являются векторами-столбцами и умножаются справа от матрицы, то столбцы **M** являются осями. Если вместо этого векторы умножаются слева от матрицы как векторы-строки, тогда строки **M** являются осями.)

Скажем, A задается с использованием представления min-max, а **M** - матрица столбцов. Выровненный по осям ограничивающий параллелипипед B, ограничивающий A', задается интервалами экстентов, образованными проекцией восьми повернутых вершин A' на оси мировых координат. Для, скажем, x экстентов B, только x компоненты векторов-столбцов **M** вносят вклад.
Следовательно, поиск экстентов соответствует поиску вершин, которые производят минимальное и максимальное произведения со строками **M**. Каждая вершина B представляет собой комбинацию трех преобразованных минимальных или максимальных значений из A. Минимальное значение экстента - это сумма меньших членов, а максимальное значение - сумма больших членов. Смещение не влияет на вычисление размера нового ограничивающего параллелипипеда и может быть просто добавлено. Например, максимальный размер по оси x может быть вычислен как:

```cpp
    B.max[0] = max(m[0][0] * A.min[0], m[0][0] * A.max[0])
             + max(m[0][1] * A.min[1], m[0][1] * A.max[1])
             + max(m[0][2] * A.min[2], m[0][2] * A.max[2]) + t[0];
```

Таким образом, вычисление ограничивающего параллелипипеда для повернутого AABB с использованием представления min-max может быть реализовано следующим образом:

```cpp
    // Преобразование AABB a матрицей m и переносом t,
    // поиск максимальных экстентов и сохранение результата в AABB b.
    void UpdateAABB(AABB a, float m[3][3], float t[3], AABB &b) {
        // По всем трем осям
        for (int i = 0; i < 3; i++) {
            // Начало с добавления переноса
            b.min[i] = b.max[i] = t[i];
            // Формирование экстента 
            // суммированием меньших и больших членов соответственно
            for (int j = 0; j < 3; j++) {
                float e = m[i][j] * a.min[j];
                float f = m[i][j] * a.max[j];
                if (e < f) {
                    b.min[i] += e;
                    b.max[i] += f;
                } else {
                    b.min[i] += f;
                    b.max[i] += e;
                }
            }
        }
    }
```
Соответственно, код для представления AABB с центральным радиусом становится [Arvo90]:

```cpp
    // Преобразование AABB a с помощью матрицы m и переноса t,
    // поиск максимальных экстентов и сохранение результата в AABB b.
    void UpdateAABB(AABB a, float m[3][3], float t[3], AABB &b) {
        for (int i = 0; i < 3; i++) {
            b.c[i] = t[i];
            b.r[i] = 0.0f;
            for (int j = 0; j < 3; j++) {
                b.c[i] += m[i][j] * a.c[j];
                b.r[i] += Abs(m[i][j]) * a.r[j];
            }
        }
    }
```

Обратите внимание, что вычисление AABB из повернутого AABB эквивалентно вычислению его из свободно ориентированного ограничивающего параллелипипеда. Ориентированные ограничивающие параллелипипеды и тесты их пересечения будут описаны более подробно ниже. Однако между методами, представленными здесь, и методами, которые будут представлены, будет классифицироваться метод сохранения ориентированных ограничивающих параллелипипедов с объектами, но все же пересекающих их как реконструированных AABB (как это сделано здесь). Для этого потребуется дополнительная память для хранения матрицы ориентации. Это также потребует дополнительного умножения матрицы на матрицу для комбинирования матрицы вращения ориентированного ограничивающего параллелипипеда с матрицей преобразования **M**. Преимущество этого решения состоит в том, что реконструированный выровненный по оси параллелипипед будет намного плотнее, начиная с ориентированного параллелипипеда. Проверка соосности по оси также намного дешевле, чем полномасштабная проверка для ориентированных параллелипипедов.

## 4.3 Сферы

Сфера - еще один очень распространенный ограничивающий объем, который по популярности может соперничать с ограничивающим прямоугольником, выровненным по оси. Как и у AABB, у сфер есть недорогой тест на пересечение. Сферы также имеют то преимущество, что они инвариантны относительно вращения, что означает, что их легко преобразовать: их просто нужно перенести в новое положение. Сферы определяются положением центра и радиусом:

```cpp
    // Region R = { (x, y, z) | (x-c.x)∧2 + (y-c.y)∧2 + (z-c.z)∧2 <= r∧2 }
    struct Sphere {
        Point c; // Центр сферы
        float r; // Радиус сферы
    };
```

Ограничивающая сфера, состоящая всего из четырех компонентов, является ограничивающим объемом с наиболее эффективным использованием памяти. Часто центр или начало существующего объекта можно отрегулировать так, чтобы он совпадал с центром сферы, и нужно сохранить только один компонент, радиус. Вычислить оптимальную ограничивающую сферу не так просто, как вычислить оптимальный ограничивающий параллепипед, выровненный по оси. Некоторые методы вычисления ограничивающих сфер рассматриваются в следующих разделах в порядке увеличения точности, в заключение приводится алгоритм вычисления минимальной ограничивающей сферы. Методы, исследованные для алгоритмов неоптимальной аппроксимации, остаются актуальными в том смысле, что их можно применять к другим ограничивающим объемам.

### 4.3.1 Сфера-сфера пересечения

Тест на пересечение двух сфер очень прост. Вычисляется евклидово расстояние между центрами сфер и сравнивается с суммой радиусов сфер. Чтобы избежать часто дорогостоящей операции извлечения квадратного корня, сравниваются квадраты расстояний. Тест выглядит так:

```cpp
    int TestSphereSphere(Sphere a, Sphere b) {
        // Вычисление квадрата расстояния между центрами
        Vector d = a.c - b.c;
        float dist2 = Dot(d, d);
        // Сферы пересекаются, если квадрат расстояния меньше квадрата суммы радиусов
        float radiusSum = a.r + b.r;
        return dist2 <= radiusSum * radiusSum;
    }
```

Хотя тест сферы имеет несколько больше арифметических операций, чем тест AABB, он также имеет меньше ветвей и требует меньше данных для выборки. В современных архитектурах тест сферы, вероятно, немногим быстрее теста AABB. Однако скорость этих простых тестов не должна быть определяющим фактором при выборе между ними. Плотность фактических данных - гораздо более важное соображение.

### 4.3.2 Вычисление ограничивающей сферы

Простую аппроксимативную ограничивающую сферу можно получить, сначала вычислив AABB всех точек. Затем средняя точка AABB выбирается в качестве центра сферы, а радиус сферы устанавливается как расстояние до точки, наиболее удаленной от этой центральной точки. Обратите внимание, что использование геометрического центра (среднего) всех точек вместо средней точки AABB может дать чрезвычайно плохие ограничивающие сферы для неравномерно распределенных точек (до двойного необходимого радиуса). Хотя это быстрый метод, он, как правило, не очень хорош по сравнению с оптимальным методом.

Альтернативный подход к вычислению простой аппроксимированной ограничивающей сферы описан в [Ritter90]. Этот алгоритм пытается найти хорошую начальную почти ограничивающую сферу, а затем за несколько шагов улучшить ее, пока она не ограничит все точки. Алгоритм выполняется за два прохода. На первом проходе находятся шесть (не обязательно уникальных) экстремальных точек по осям системы координат. Из этих шести точек выбирается пара точек, наиболее удаленных друг от друга. (Обратите внимание, что эти две точки не обязательно соответствуют точкам, определяющим самый длинный край AABB набора точек.) Центр сферы теперь выбран как середина между этими двумя точками, а радиус установлен равным половине расстояния между ними. Код для этого первого прохода указан в функциях **MostSeparatedPointsOnAABB()** и **SphereFromDistantPoints()** следующим образом:

```cpp
    // Вычисление индексов двух наиболее разделенных точек, до шести точек, 
    // определяющих AABB, охватывающую набор точек. Возвращаем их как минимум и максимум.
    void MostSeparatedPointsOnAABB(int &min, int &max, Point pt[], int numPts) {
        // Сначала найти самые крайние точки вдоль главных осей
        int minx = 0, maxx = 0, miny = 0, maxy = 0, minz = 0, maxz = 0;
        for (int i = 1; i < numPts; i++) {
            if (pt[i].x < pt[minx].x) minx = i;
            if (pt[i].x > pt[maxx].x) maxx = i;
            if (pt[i].y < pt[miny].y) miny = i;
            if (pt[i].y > pt[maxy].y) maxy = i;
            if (pt[i].z < pt[minz].z) minz = i;
            if (pt[i].z > pt[maxz].z) maxz = i;
        }
        // Вычисление квадратов расстояний для трех пар точек
        float dist2x = Dot(pt[maxx] - pt[minx], pt[maxx] - pt[minx]);
        float dist2y = Dot(pt[maxy] - pt[miny], pt[maxy] - pt[miny]);
        float dist2z = Dot(pt[maxz] - pt[minz], pt[maxz] - pt[minz]);
        // Выбор пары (минимум, максимум) наиболее удаленных точек
        min = minx;
        max = maxx;
        if (dist2y > dist2x && dist2y > dist2z) {
            max = maxy;
            min = miny;
        }
        if (dist2z > dist2x && dist2z > dist2y) {
            max = maxz;
            min = minz;
        }
    }

    void SphereFromDistantPoints(Sphere &s, Point pt[], int numPts) {
        // Поиск наиболее разделенной пары точек, определяющей охватывающий AABB
        int min, max;
        MostSeparatedPointsOnAABB(min, max, pt, numPts);
        // Настройка сферы для охвата этих двух точек
        s.c = (pt[min] + pt[max]) * 0.5f;
        s.r = Dot(pt[max] - s.c, pt[max] - s.c);
        s.r = Sqrt(s.r);
    }
```

Во втором проходе все точки снова проходят. Для всех точек за пределами текущей сферы сфера обновляется до сферы, охватывающей старую сферу и внешнюю точку. Другими словами, диаметр новой сферы простирается от внешней точки до точки на задней стороне старой сферы напротив внешней точки относительно центра старой сферы.

```cpp
    // Для Sphere s и Point p, обновление s (если необходимо), чтобы охватить p
    void SphereOfSphereAndPt(Sphere &s, Point &p) {
        // Вычислить квадрат расстояния между точкой и центром сферы
        Vector d = p - s.c;
        float dist2 = Dot(d, d);
        // Обновить s, только если точка p находится за её пределами
        if (dist2 > s.r * s.r) {
            float dist = Sqrt(dist2);
            float newRadius = (s.r + dist) * 0.5f;
            float k = (newRadius - s.r) / dist;
            s.r = newRadius;
            s.c += d * k;
        }
    }
```
Полный код для вычисления приблизительной ограничивающей сферы выглядит так:

```cpp
    void RitterSphere(Sphere &s, Point pt[], int numPts) {
        // Получить сферу, охватывающую две примерно самые дальние точки
        SphereFromDistantPoints(s, pt, numPts);
        // Увеличить сферу, чтобы включить все точки
        for (int i = 0; i < numPts; i++)
        SphereOfSphereAndPt(s, pt[i]);
    }
```

Начав с лучшего приближения к истинной ограничивающей сфере, можно было ожидать, что полученная сфера будет ещё более плотной. Использование лучшего начального приближения рассматривается в следующем разделе.

### 4.3.3 Ограничивающая сфера из направления максимального распространения

Вместо нахождения пары удаленных точек с помощью AABB, как в предыдущем разделе, предлагаемый подход заключается в анализе облака точек с использованием статистических методов для определения направления максимального распространения [Wu92]. Определим это направление, две наиболее удаленные друг от друга точки при проецировании на эту ось будут использоваться для определения центра и радиуса начальной сферы. На рисунке 4.8 показана разница в разбросе по двум разным осям для одного и того же облака точек.

Среднее значение набора значений данных (то есть сумма всех значений, деленная на количество значений) является мерой центральной тенденции значений, дисперсия является мерой их разброса. Среднее $u$ и дисперсия $σ^2$ задаются как

$$u=\frac{1}{n}\sum_{i=1}^nx_i$$

$$\sigma^2=\frac{1}{n}\sum_{i=1}^n(x_i-u)^2=\frac{1}{n}(\sum_{i=1}^nx_i^2)-u^2$$

Квадратный корень из дисперсии известен как стандартное отклонение. Для значений, распределенных по одной оси, дисперсия легко вычисляется как среднее квадратичное отклонение значений от среднего:

```cpp
    // Вычисление дисперсии набора одномерных значений
    float Variance(float x[], int n) {
        float u = 0.0f;
        for (int i = 0; i < n; i++)
            u += x[i];
        u /= n;
        float s2 = 0.0f;
        for (int i = 0; i < n; i++)
            s2 += (x[i] - u) * (x[i] - u);
        return s2 / n;
    }
```
Обычно нет очевидной прямой интерпретации дисперсии и стандартного отклонения. Однако они важны как сравнительные меры. Для двух переменных ковариация измеряет их тенденцию к изменению вместе. Она вычисляется как среднее значение произведений отклонения значений переменных от их средних значений. Для нескольких переменных ковариация данных обычно вычисляется и выражается в виде матрицы, матрицы ковариации (также называемой матрицей дисперсии-ковариации или матрицей дисперсии).

**Рисунок 4.8** Одно и то же облако точек в проекции на две разные оси. В (а) разброс по оси небольшой. В (б) разброс намного больше. Ограничивающая сфера может быть определена по оси, для которой набор проецируемых точек имеет максимальный разброс.

Ковариационная матрица $C = [c_{ij}]$ для набора из n точек $P_1 , P_2 , ... , P_n$ задаётся

$$c_{ij}=\frac{1}{n}\sum_{k=1}^n(P_{k,i}-u_i)(P_{k,j}-u_j)$$ 

или, что эквивалентно

$$c_{ij}=\frac{1}{n}(\sum_{k=1}^n P_{k,i}P_{k,j})-u_iu_j$$

Член $u_i$ (и $u_j$) - это среднее значение i-й координаты точек, заданный как

$$u_i=\frac{1}{n}\sum_{k=1}^nP_{k,i}$$

Неформально, чтобы увидеть, как работает ковариация, рассмотрим первую формулу ковариации. Когда две переменные имеют тенденцию отклоняться в одном и том же направлении от их соответствующих средних значений, умножение,

$$(P_{k,i}-u_i)(P_{k,j}-u_j)$$

чаще будет положительным, чем отрицательным. Если переменные имеют тенденцию отклоняться в разные стороны, произведение будет чаще отрицательным, чем положительным. Сумма этих произведений определяет взаимозависимость переменных. При реализации с использованием чисел с плавающей запятой одинарной точности первая из двух ковариационных формул имеет тенденцию давать более точные результаты за счет сохранения большего количества битов точности. При использовании двойной точности результаты обычно практически не различаются. Следующий код реализует первую формулу:

```cpp
void CovarianceMatrix(Matrix33 &cov, Point pt[], int numPts) {
    float oon = 1.0f / (float)numPts;
    Point c = Point(0.0f, 0.0f, 0.0f);
    float e00, e11, e22, e01, e02, e12;
    // Вычислить центр масс (центроид) точек
    for (int i = 0; i < numPts; i++)
        c += pt[i];
    c *= oon;
    // Вычислить элементы ковариации
    e00 = e11 = e22 = e01 = e02 = e12 = 0.0f;
    for (int i = 0; i < numPts; i++) {
        // Перенести точки так, чтобы центр масс находился в начале координат
        Point p = pt[i] - c;
        // Вычислить ковариацию перенесенных точек
        e00 += p.x * p.x;
        e11 += p.y * p.y;
        e22 += p.z * p.z;
        e01 += p.x * p.y;
        e02 += p.x * p.z; //?
        e12 += p.y * p.z;
    }
    // Заполнить элементы ковариационной матрицы
    cov[0][0] = e00 * oon;
    cov[1][1] = e11 * oon;
    cov[2][2] = e22 * oon;
    cov[0][1] = cov[1][0] = e01 * oon;
    cov[0][2] = cov[2][0] = e02 * oon;
    cov[1][2] = cov[2][1] = e12 * oon;
}
```

После того, как ковариационная матрица вычислена, ее можно разложить таким образом, чтобы больше узнать о главных направлениях дисперсии. Это разложение выполняется путем вычисления собственных значений и собственных векторов матрицы. Связь между ними такова, что собственный вектор, связанный с собственным значением наибольшей величины, соответствует оси, вдоль которой точечные данные имеют наибольшую дисперсию. Точно так же собственный вектор, связанный с наименьшим собственным значением магнитуды, является осью, вдоль которой данные имеют наименьшую дисперсию. Надежное нахождение собственных значений и собственных векторов матрицы в общем случае является нетривиальной задачей. Как правило, их находят с помощью некоторого (итеративного) численного метода (для которого есть хороший источник [Golub96]).

По определению ковариационная матрица всегда симметрична. В результате он распадается на действительные (а не комплексные) собственные значения и ортонормированный базис собственных векторов. Для симметричных матриц можно использовать более простой подход декомпозиции. Для матрицы среднего размера, как здесь, метод Якоби работает довольно хорошо. Сложные детали метода Якоби выходят за рамки этой книги. Вкратце, однако, алгоритм выполняет ряд шагов преобразования заданной входной матрицы.

Каждый шаг заключается в применении поворота к матрице, приближая матрицу к диагональной матрице (все элементы равны нулю, кроме элементов на диагонали). Когда матрица диагональна, элементы на диагонали являются собственными значениями. При этом все повороты также объединяются в другую матрицу. После выхода эта матрица будет содержать собственные векторы. В идеале это разложение должно выполняться в арифметике с двойной точностью, чтобы минимизировать числовые ошибки. Следующий код для метода Якоби основан на презентации в [Golub96]. Во-первых, это подпрограмма для помощи в вычислении матрицы вращения.

```cpp
    // Симметричное разложение Шура 2 на 2. 
    // Для симметричной матрицы размера n на n и индексов p, q 
    // таких, что 1 <= p < q <= n, 
    // вычисляем пару синус-косинус (s, c), которая будет служить 
    // для формирования матрицы вращения Якоби.
    //
    // Смотрите Golub, Van Loan, Matrix Computations, 4th ed, 
    // страница 478 (в pdf файле 502)
    void SymSchur2(Matrix33 &a, int p, int q, float &c, float &s) {
        if (Abs(a[p][q]) > 0.0001f) {
            float r = (a[q][q] - a[p][p]) / (2.0f * a[p][q]);
            float t;
            if (r >= 0.0f)
                t = 1.0f / (r + Sqrt(1.0f + r*r));
            else
                t = -1.0f / (-r + Sqrt(1.0f + r*r));
            c = 1.0f / Sqrt(1.0f + t*t);
            s = t * c;
        } else {
            c = 1.0f;
            s = 0.0f;
        }
    }
```
С учетом этой вспомогательной функции полный метод Якоби теперь реализован как:

```cpp
// Вычисление собственных векторов и собственных значений симметричной матрицы A, 
// с помощью классического метода Якоби итеративного обновления A как A = J^T * A * J,
// где J = J(p, q, theta) матрица вращения Якоби.
//
// На выходе v будет содержать собственные векторы, а диагональные 
// элементы a являются соответствующими собственными значениями.
//
// Смотрите Golub, Van Loan, Matrix Computations, 4th ed, p428 
// страница 479 (в pdf файле 503)
void Jacobi(Matrix33 &a, Matrix33 &v) {
    int i, j, n, p, q;
    float prevoff, c, s;
    Matrix33 J, b, t;
    // Инициализация v единичной матрицей
    for (i = 0; i < 3; i++) {
        v[i][0] = v[i][1] = v[i][2] = 0.0f;
        v[i][i] = 1.0f;
    }
    // Повторение до некоторого максимального количества итераций
    const int MAX_ITERATIONS = 50;
    for (n = 0; n < MAX_ITERATIONS; n++) {
        // Найти наибольший недиагональный абсолютный элемент a[p][q]
        p = 0; q = 1;
        for (i = 0; i < 3; i++) {
            for (j = 0; j < 3; j++) {
                if (i == j) continue;
                if (Abs(a[i][j]) > Abs(a[p][q])) {
                    p = i;
                    q = j;
                }
            }
        }
        // Вычислить матрицу вращения Якоби J(p, q, theta)
        // (Этот код можно оптимизировать для трех разных случаев вращения)
        SymSchur2(a, p, q, c, s);
        for (i = 0; i < 3; i++) {
            J[i][0] = J[i][1] = J[i][2] = 0.0f;
            J[i][i] = 1.0f;
        }
        J[p][p] = c; J[p][q] = s;
        J[q][p] = -s; J[q][q] = c;
        // Накопите повороты в то, что будет содержать собственные векторы
        v = v * J;
        // Сделать 'a' более диагональной, пока на диагонали не останутся 
        // только собственные значения
        a = (J.Transpose() * a) * J;
        // Вычислить 'норму' недиагональных элементов
        float off = 0.0f;
        for (i = 0; i < 3; i++) {
            for (j = 0; j < 3; j++) {
                if (i == j) continue;
                off += a[i][j] * a[i][j];
            }
        }
        /* off = sqrt(off); not needed for norm comparison */
        // Остановиться, когда норма больше не снижается
        if (n > 2 && off >= prevoff)
        return;
        prevoff = off;
        }
    }
```

Для конкретной матрицы 3 × 3, используемой здесь, вместо применения общего подхода, такого как метод Якоби, собственные значения могут быть непосредственно вычислены из простого кубического уравнения. Тогда собственные векторы можно было бы легко найти, например, с помощью метода исключения Гаусса. Такой подход описан в [Cromwell94]. Учитывая ранее определенные функции, вычисление сферы из двух наиболее удаленных точек (в соответствии с разбросом) теперь выглядит так:

```cpp
    void EigenSphere(Sphere &eigSphere, Point pt[], int numPts) {
        Matrix33 m, v;
        // Вычислить ковариационную матрицу m
        CovarianceMatrix(m, pt, numPts);
        // Разложить её на собственные векторы (в v) и собственные значения (в m)
        Jacobi(m, v);
        // Найти компонент с наибольшим собственным значением (наибольшим разбросом)
        Vector e;
        int maxc = 0;
        float maxf, maxe = Abs(m[0][0]);
        if ((maxf = Abs(m[1][1])) > maxe) maxc = 1, maxe = maxf;
        if ((maxf = Abs(m[2][2])) > maxe) maxc = 2, maxe = maxf;
        e[0] = v[0][maxc];
        e[1] = v[1][maxc];
        e[2] = v[2][maxc];
        // Найти самые крайние точки в направлении ’e’
        int imin, imax;
        ExtremePointsAlongDirection(e, pt, numPts, &imin, &imax);
        Point minpt = pt[imin];
        Point maxpt = pt[imax];
        float dist = Sqrt(Dot(maxpt - minpt, maxpt - minpt));
        eigSphere.r = dist * 0.5f;
        eigSphere.c = (minpt + maxpt) * 0.5f;
    }
```

Модифицированный полный код для расчета приблизительной ограничивающей сферы становится:

```cpp
    void RitterEigenSphere(Sphere &s, Point pt[], int numPts) {
        // Начало со сферой из максимального распространения
        EigenSphere(s, pt, numPts);
        // Увеличение сферы до включения всех точек
        for (int i = 0; i < numPts; i++)
        SphereOfSphereAndPt(s, pt[i]);
    }
```

Тип ковариационного анализа, выполняемый здесь, обычно используется для уменьшения размерности и статистического анализа данных и известен как анализ главных компонентов (PCA). Дополнительную информацию о PCA можно найти в [Jolliffe02]. Собственные векторы ковариационной матрицы также можно использовать для ориентации ориентированного ограничивающего прямоугольника, как описано в разделе 4.4.3.

### 4.3.4 Ограничивающая сфера посредством итеративного уточнения

Основная идея алгоритма, описанного в разделе 4.3.2, заключается в том, чтобы начать с довольно хорошего, слегка недооцененного приближения к фактической наименьшей сфере, а затем увеличивать ее, пока она не охватит все точки. Учитывая лучшую начальную сферу, можно ожидать, что и последняя сфера будет лучше. Следовательно, неудивительно, что выходные данные алгоритма могут быть очень эффективно использованы для самоподдержки итеративным способом. Результирующая сфера одной итерации просто уменьшается на небольшую величину, чтобы сделать ее недооцененной для следующего итеративного вызова.

```cpp
void RitterIterative(Sphere &s, Point pt[], int numPts) {
    const int NUM_ITER = 8;
    RitterSphere(s, pt, numPts);
    Sphere s2 = s;
    for (int k = 0; k < NUM_ITER; k++) {
        // Слегка сжать сферу, чтобы сделать её недооцененной (не ограниченной)
        s2.r = s2.r * 0.95f;
        // Сделать данные снова привязанными к сфере
        for (int i = 0; i < numPts; i++) {
            // Обмен pt[i] с pt[j], где j случайно из интервала [i+1,numPts-1]
            DoRandomSwap();
            SphereOfSphereAndPt(s2, pt[i]);
        }
        // Обновить s при обнаружении более плотной сферы
        if (s2.r < s.r) s = s2;
    }
}
```

Для дальнейшего улучшения результатов точки рассматриваются случайным образом, а не в одном и том же порядке от итерации к итерации. Результирующая сфера обычно намного лучше, чем сфера, созданная методом Ву (описанным в предыдущем разделе), за счет нескольких дополнительных итераций над входными данными. Если применить тот же итерационный подход к алгоритму Ву, результаты будут сопоставимы. Как и в случае со всеми итеративными алгоритмами восхождения на холм этого типа (такими как методы градиентного спуска, имитация отжига или поиск TABU), поиск может застрять в локальных минимумах, и оптимальный результат не гарантируется. Однако возвращаемый результат часто почти оптимален. Результат также очень надежный.

### 4.3.5 Минимальная ограничивающая сфера

Сфера однозначно определяется четырьмя (не копланарными) точками. Таким образом, алгоритм прямого перебора для вычисления минимальной ограничивающей сферы для набора точек должен учитывать все возможные комбинации четырех (затем трех, затем двух) точек, вычисление самой маленькой сферы через эти точки и сохранение сферы, если она содержит все другие точки. Сохраненная сфера с наименьшим радиусом тогда является минимальной ограничивающей сферой. Этот брутфорс алгоритм имеет сложность $O(n^5)$ и поэтому не практичен. К счастью, проблема вычисления минимальной ограничивающей сферы для набора точек хорошо изучена в области вычислительной геометрии, и рандомизированный алгоритм, который работает в течение ожидаемого линейного времени, был дан [Welzl91].

Предположим, что минимальная ограничивающая сфера S была вычислена для набора точек P. Если к P добавляется новая точка Q, то S нужно пересчитывать только в том случае, если Q лежит вне S. Нетрудно видеть, что Q должна лежать на границе новой минимальной ограничивающей сферы для множества точек $P∪{Q}$. Алгоритм Вельцля основан на этом наблюдении, в результате чего получается рекурсивный алгоритм. Он продолжается, поддерживая как набор входных точек, так и набор опор, который содержит точки из входного набора, которые должны лежать на границе минимальной сферы. Следующий фрагмент кода описывает алгоритм Вельцля:


```cpp
    Sphere WelzlSphere(Point pt[], unsigned int numPts, Point sos[], unsigned int numSos) {
        // если нет точек ввода, рекурсия достигла дна. Теперь вычислить 
        // точную сферу на основе точек в наборе опор (от нуля до четырех точек)
        if (numPts == 0) {
            switch (numSos) {
            case 0: return Sphere();
            case 1: return Sphere(sos[0]);
            case 2: return Sphere(sos[0], sos[1]);
            case 3: return Sphere(sos[0], sos[1], sos[2]);
            case 4: return Sphere(sos[0], sos[1], sos[2], sos[3]);
            }
        }
        // Выбрать точку случайным образом (здесь только последняя точка входного набора)
        int index = numPts - 1;
        // Рекурсивно вычислить наименьшую ограничивающую сферу оставшихся точек
        Sphere smallestSphere = WelzlSphere(pt, numPts - 1, sos, numSos); // (*)
        // Если выбранная точка находится внутри этой сферы, она действительно самая маленькая
        if(PointInsideSphere(pt[index], smallestSphere))
        return smallestSphere;
        // В противном случае обновить набор опор, чтобы дополнительно включить новую точку
        sos[numSos] = pt[index];
        // Рекурсивно вычислить наименьшую сферу из оставшихся точек с новыми н.у. (s.o.s.)
        return WelzlSphere(pt, numPts - 1, sos, numSos + 1);
    }
```

Хотя два рекурсивных вызова внутри функции делают функцию дорогостоящей, Вельцл показал, что, если предположить, что точки удаляются из входного набора случайным образом, алгоритм выполняется за ожидаемое линейное время. Обратите внимание, что, как показано, первый рекурсивный вызов (отмеченный звездочкой в коде) может вызвать переполнение стека для входных данных, превышающих несколько тысяч точек. Небольшие изменения в коде позволяют избежать этой проблемы, как описано в [Gärtner99]. Полная реализация приведена в [Capens01].
В Интернете также доступна более сложная реализация, часть библиотеки алгоритмов вычислительной геометрии (Computational Geometry Algorithms Library, CGAL). Для написания надежной реализации алгоритма Вельцля необходимо, чтобы четыре вспомогательные функции для вычисления точных сфер от одной до четырех точек правильно обрабатывали вырожденные входные данные, такие как коллинеарные точки.

Алгоритм Вельцля можно применять для вычисления как ограничивающих кругов, так и шаров более высоких размеров. Однако он не распространяется напрямую на вычисление минимальной сферы, ограничивающей набор сфер. Алгоритм решения последней задачи приведен в [Fischer03]. Подробно рассмотрев сферы, мы теперь обратим внимание на ограничивающие параллелипипеды произвольной ориентации.

## 4.4 Ориентированные ограничивающие параллелипипеды (Oriented Bounding Boxes, OBBs)

Ориентированный ограничивающий параллелипипед (OBB) - это прямоугольный блок, очень похожий на AABB, но с произвольной ориентацией. Есть много возможных представлений OBB: как набор из восьми вершин, набор из шести плоскостей, набор из трех плит (пара параллельных плоскостей), угловая вершина плюс три взаимно ортогональных вектора ребра или центральная точка плюс матрица ориентации и три длины половинного ребра. Последнее обычно является предпочтительным представлением для OBB, поскольку оно позволяет проводить гораздо более дешевый тест на пересечение OBB-OBB, чем другие представления. Этот тест основан на теореме о разделяющей оси, которая более подробно обсуждается в главе 5.

```cpp
// Region R = { x | x = c+r*u[0]+s*u[1]+t*u[2] } , |r|<=e[0], |s|<=e[1], |t|<=e[2]
struct OBB {
    Point c;     // Центральная точка OBB
    Vector u[3]; // Локальные оси x, y и z
    Vector e;    // Положительные значения полуширины OBB по каждой оси
};
```

При 15 числах с плавающей запятой или 60 байтах для чисел с плавающей запятой одинарной точности IEEE OBB является довольно дорогим ограничивающим объемом с точки зрения использования памяти. Требования к памяти можно снизить, сохранив ориентацию не как матрицу, а как углы Эйлера или как кватернион, используя от трех до четырех компонентов с плавающей запятой вместо девяти. К сожалению, для теста пересечения OBB-OBB эти представления должны быть преобразованы обратно в матрицу для использования в тесте эффективной разделительной оси, что является очень дорогостоящей операцией. Поэтому хорошим компромиссом может быть сохранение только двух осей матрицы вращения и вычисление третьей из перекрестного произведения двух других во время тестирования. Эта относительно дешевая операция ЦП позволяет сэкономить три компонента с плавающей запятой, в результате чего экономится 20% памяти.

### 4.4.1 OBB-OBB пересечение

В отличие от предыдущих тестов на пересечение ограничивающего объема, тест на пересечение между двумя ориентированными ограничивающими параллелипипедами на удивление сложен. Поначалу это кажется испытанием, чтобы увидеть, будет ли достаточно одного параллелипипеда, полностью выходящего за границу другого. В простейшей форме этот тест может быть выполнен путем проверки, находятся ли все вершины блока A за пределами плоскостей, определяемых гранями блока B, и наоборот. Однако, хотя этот тест работает в 2D, он не работает правильно в 3D. Он не может справиться, например, со случаем, когда A и B почти пересекаются от рёбра до рёбра, причем рёбра перпендикулярны друг другу. Здесь ни один параллелипипед не находится полностью вне одной стороны другой. Следовательно, простой тест сообщает, что они пересекаются, хотя это не так. Даже в этом случае простой тест может быть полезен. Хотя это не всегда правильно, он консервативен в том, что никогда не перестает обнаруживать столкновение. Только в некоторых случаях он неверно сообщает о перекрытии разделенных полей. Таким образом, он может служить предварительным испытанием для более дорогостоящего точного теста.

**Рисунок 4.9** Два OBB разделяются, если для некоторой оси L сумма их проецируемых радиусов меньше расстояния между их проектируемыми центрами.

Точный тест на пересечение OBB и OBB может быть реализован в терминах так называемого теста разделяющей оси. Этот тест подробно обсуждается в главе 5, но здесь достаточно отметить, что два OBB разделяются, если по отношению к некоторой оси L сумма их радиусов меньше, чем расстояние между проекциями их центральных точек (как показано на рисунке 4.9). То есть, если

$$\mid T · L\mid > r_A + r_B$$

Для OBB можно показать, что не более 15 из этих разделяющих осей должны быть протестированы, чтобы правильно определить статус перекрытия OBB. Эти оси соответствуют трем координатным осям A, трем координатным осям B и девяти осям, перпендикулярным каждой оси. Если блоки не пересекаются ни по одной из 15 осей, они не пересекаются. Если ни одна из осей не обеспечивает этого раньше, значит, блоки должны перекрываться.

Количество операций в тесте можно уменьшить, выразив $B$ в системе координат $A$. Если **t** - вектор перевода из $A$ в $B$ и $R = r_{ij}$ (матрица вращения, переводящая $B$ в систему координат $A$), тесты, которые необходимо выполнить для различных осей $L$, сведены в Таблицу 4.1.

**Таблица 4.1** 15 тестов разделительных осей, необходимых для определения пересечения OBB-OBB. Верхние индексы указывают, из какого OBB берется значение.

Этот тест можно реализовать следующим образом:

```cpp
int TestOBBOBB(OBB &a, OBB &b) {
    float ra, rb;
    Matrix33 R, AbsR;
    // Вычислить матрицу вращения, выражающую b в системе координат a
    for (int i = 0; i < 3; i++)
        for (int j = 0; j < 3; j++)
            R[i][j] = Dot(a.u[i], b.u[j]);
    // Вычислить вектор переноса t
    Vector t = b.c - a.c;
    // Перенос в систему координат
    t = Vector(Dot(t, a.u[0]), Dot(t, a.u[2]), Dot(t, a.u[2]));
    // Вычислить общие подвыражения. Добавить термин эпсилон, 
    // чтобы противодействовать арифметическим ошибкам, когда два ребра параллельны 
    // и их перекрестное произведение (почти) равно нулю (подробности см. в тексте)
    for (int i = 0; i < 3; i++)
        for (int j = 0; j < 3; j++)
            AbsR[i][j] = Abs(R[i][j]) + EPSILON;
    // Тест осей L = A0, L = A1, L = A2
    for (int i = 0; i < 3; i++) {
        ra = a.e[i];
        rb = b.e[0] * AbsR[i][0] + b.e[1] * AbsR[i][1] + b.e[2] * AbsR[i][2];
        if (Abs(t[i]) > ra + rb) return 0;
    }
    // Тест осей L = B0, L = B1, L = B2
    for (int i = 0; i < 3; i++) {
        ra = a.e[0] * AbsR[0][i] + a.e[1] * AbsR[1][i] + a.e[2] * AbsR[2][i];
        rb = b.e[i];
        if (Abs(t[0] * R[0][i] + t[1] * R[1][i] + t[2] * R[2][i]) > ra + rb) return 0;
    }
    // Тест оси L = A0 x B0
    ra = a.e[1] * AbsR[2][0] + a.e[2] * AbsR[1][0];
    rb = b.e[1] * AbsR[0][2] + b.e[2] * AbsR[0][1];
    if (Abs(t[2] * R[1][0] - t[1] * R[2][0]) > ra + rb) return 0;
    
    // Тест оси L = A0 x B1
    ra = a.e[1] * AbsR[2][1] + a.e[2] * AbsR[1][1];
    rb = b.e[0] * AbsR[0][2] + b.e[2] * AbsR[0][0];
    if (Abs(t[2] * R[1][1] - t[1] * R[2][1]) > ra + rb) return 0;

    // Тест оси L = A0 x B2
    ra = a.e[1] * AbsR[2][2] + a.e[2] * AbsR[1][2];
    rb = b.e[0] * AbsR[0][1] + b.e[1] * AbsR[0][0];
    if (Abs(t[2] * R[1][2] - t[1] * R[2][2]) > ra + rb) return 0;

    // Тест оси L = A1 x B0
    ra = a.e[0] * AbsR[2][0] + a.e[2] * AbsR[0][0];
    rb = b.e[1] * AbsR[1][2] + b.e[2] * AbsR[1][1];
    if (Abs(t[0] * R[2][0] - t[2] * R[0][0]) > ra + rb) return 0;

    // Тест оси L = A1 x B1
    ra = a.e[0] * AbsR[2][1] + a.e[2] * AbsR[0][1];
    rb = b.e[0] * AbsR[1][2] + b.e[2] * AbsR[1][0];
    if (Abs(t[0] * R[2][1] - t[2] * R[0][1]) > ra + rb) return 0;

    // Тест оси L = A1 x B2
    ra = a.e[0] * AbsR[2][2] + a.e[2] * AbsR[0][2];
    rb = b.e[0] * AbsR[1][1] + b.e[1] * AbsR[1][0];
    if (Abs(t[0] * R[2][2] - t[2] * R[0][2]) > ra + rb) return 0;

    // Тест оси L = A2 x B0
    ra = a.e[0] * AbsR[1][0] + a.e[1] * AbsR[0][0];
    rb = b.e[1] * AbsR[2][2] + b.e[2] * AbsR[2][1];
    if (Abs(t[1] * R[0][0] - t[0] * R[1][0]) > ra + rb) return 0;

    // Тест оси L = A2 x B1
    ra = a.e[0] * AbsR[1][1] + a.e[1] * AbsR[0][1];
    rb = b.e[0] * AbsR[2][2] + b.e[2] * AbsR[2][0];
    if (Abs(t[1] * R[0][1] - t[0] * R[1][1]) > ra + rb) return 0;

    // Тест оси L = A2 x B2
    ra = a.e[0] * AbsR[1][2] + a.e[1] * AbsR[0][2];
    rb = b.e[0] * AbsR[2][1] + b.e[1] * AbsR[2][0];
    if (Abs(t[1] * R[0][2] - t[0] * R[1][2]) > ra + rb) return 0;

    // Поскольку разделительная ось не найдена, OBB должны пересекаться
    return 1;
}
```

Чтобы сделать тест OBB-OBB как можно более эффективным, важно, чтобы оси проверялись в порядке, указанном в таблице 4.1. Первая причина для использования этого порядка заключается в том, что при тестировании сначала трех ортогональных осей в тестах мало пространственной избыточности, и все пространство быстро покрывается. Во-вторых, с настройкой, приведенной здесь, где A преобразуется в начало координат и выравнивается с осями системы координат, проверка осей A составляет примерно половину стоимости проверки осей B. Хотя здесь это не делается, вычисления **R** и **AbsR** следует чередовать с первыми тремя тестами, чтобы они не выполнялись без необходимости полностью, когда тест OBB завершается в одном из первых нескольких операторов if.

Если OBB используются в приложениях, в которых они часто имеют тенденцию иметь одну ось, выровненную с текущим миром вверх, например, при путешествии по земле, стоит использовать специальные кожухи для этих «вертикально выровненных» OBB. Это упрощение позволяет проводить гораздо более быстрый тест на пересечение, который включает в себя тестирование только четырех разделяющих осей в дополнение к дешевому тесту в вертикальном направлении.

В некоторых случаях выполнение только первых 6 из 15 осевых тестов может привести к более быстрым результатам. В эмпирических тестах [Bergen97] обнаружил, что последние 9 тестов в коде перекрытия OBB определяют непересечение примерно в 15% случаев. Поскольку, возможно, половина всех запросов с самого начала являются положительными, пропуск этих 9 тестов приводит к ложноположительным результатам примерно в 6–7% случаев. Когда тест OBB выполняется как предварительный тест для точного теста на ограниченную геометрию, тест по-прежнему остаётся точным, и никакие столкновения не пропускаются.

### 4.4.2 Повышение надежности теста разделительной оси

Очень важным вопросом, который упускают из виду в некоторых популярных трактовках теоремы о разделяющей оси, является надежность теста. К сожалению, любой код, реализующий этот тест, должен быть очень тщательно разработан, чтобы работать так, как задумано. Когда разделяющая ось формируется путем взятия поперечного произведения ребра из каждого ограничивающего прямоугольника, существует вероятность, что эти ребра параллельны. В результате их векторное произведение является нулевым вектором, все проекции на этот нулевой вектор равны нулю, а сумма произведений с каждой стороны неравенства оси равна нулю. Остается сравнение 0 > 0. В идеальном мире точной арифметической математики это выражение было бы тривиально ложно. В действительности, любая компьютерная реализация должна иметь дело с неточностями, вызванными использованием арифметики с плавающей запятой.

Для оптимизированных неравенств, представленных ранее, случай параллельных ребер соответствует только нулевым элементам матрицы вращения **R**, на которую делается ссылка. Теоретически это еще приводит к сравнению 0 > 0. Однако на практике из-за накопления ошибок матрица вращения не будет идеально ортонормированной, и ее нулевые элементы не будут точно равны нулю. Таким образом, сумма произведений по обе стороны неравенства тоже будет не нулем, а некоторой небольшой ошибкой. Поскольку такое накопление ошибок может привести к изменению знака или сдвигу величины любой из сторон неравенства, результат будет совершенно случайным. Следовательно, если тесты на неравенство не будут выполняться очень тщательно, эти арифметические ошибки могут привести к тому, что (почти) нулевой вектор неправильно интерпретируется как разделительная ось. Таким образом, два перекрывающихся OBB могут ошибочно считаться непересекающимися.

Поскольку правая часть неравенств должна быть больше, когда два OBB взаимопроникают, простое решение проблемы состоит в добавлении небольшого эпсилон-значения к абсолютным значениям матричных элементов, встречающихся в правой части неравенств. Для близких к нулю членов этот эпсилон-член будет доминирующим, и тесты осей, соответствующие (почти) параллельным рёбрам, таким образом, становятся непропорционально консервативными. Для других, отличных от нуля случаев, маленький эпсилон-член просто исчезнет. Обратите внимание, что, поскольку абсолютные значения компонентов матрицы вращения ограничены диапазоном [0, 1], использование эпсилона фиксированной величины отлично работает независимо от размеров задействованных блоков. Устойчивость теста разделяющей оси еще раз рассматривается в главе 5.

### 4.4.3 Вычисление жесткого OBB

**Рисунок 4.10** (а) плохо выровненный и (б) хорошо выровненный OBB.

Вычисление плотно подогнанных ориентированных ограничивающих параллелипипедов - сложная проблема, усугубляемая тем фактом, что разница в объеме между плохо выровненным и хорошо выровненным OBB может быть довольно большой (рисунок 4.10). Существует алгоритм вычисления ограничивающего параллелипипеда минимального объема многогранника, представленный в [O’Rourke85]. Ключевое наблюдение, лежащее в основе алгоритма, заключается в том, что для данного многогранника либо одна грань и одно ребро, либо три ребра многогранника будут на разных гранях его ограничивающего прямоугольника. Таким образом, эти конфигурации ребер и граней можно искать систематическим образом, что дает алгоритм $O(n^3)$. Хотя это интересный теоретический результат, к сожалению, алгоритм слишком сложный и слишком медленный, чтобы иметь большую практическую ценность.

Два других теоретических алгоритма для вычисления близких аппроксимаций ограничивающего параллелипипеда минимального объема представлены в [Barequet99]. Однако авторы признают, что эти алгоритмы, вероятно, слишком сложно реализовать и даже в этом случае будут непрактичными из-за больших накладных расходов на постоянный коэффициент в алгоритмах. Таким образом, с доступными в настоящее время теоретическими алгоритмами, мало пригодными для практического использования, OBB должны быть вычислены с использованием либо приближенных методов, либо методом перебора.

Более простой алгоритм, предложенный в [Barequet99] обеспечивает грубую аппроксимацию оптимального OBB для набора точек, сначала вычисляя минимальный AABB набора. Из набора точек выбирается пара точек на двух параллельных сторонах параллелипипеда, наиболее удаленных друг от друга, чтобы определить направление длины OBB. Затем набор точек проецируется на плоскость, перпендикулярную направлению длины OBB. Та же процедура теперь применяется снова, только на этот раз вычисляется минимальный выровненный по оси прямоугольник с точками на двух параллельных сторонах, наиболее удаленными друг от друга, определяющими вторую ось для OBB. Третья ось OBB перпендикулярна первым двум осям. Хотя этот алгоритм очень легко закодировать, на практике ограничивающие параллелипипеды, намного более близкие к оптимальным, могут быть получены с помощью других алгоритмов аналогичной сложности, как описано ниже.

Для длинных и тонких объектов ось OBB должна быть совмещена с направлением объектов. Для плоского объекта ось OBB должна быть выровнена по нормали к плоскому объекту. Эти направления соответствуют основным направлениям объектов, и здесь можно использовать анализ главных компонент, используемый в разделе 4.3.3.

Вычисление ограничивающих параллелипипедов на основе ковариации вершин модели обычно удовлетворительно работает для моделей, вершины которых равномерно распределены в пространстве модели. К сожалению, влияние внутренних точек часто искажает ковариацию и может заставить OBB принять любую ориентацию независимо от экстремальных точек. По этой причине в идеале следует избегать всех методов вычисления ограничивающих объемов, основанных на взвешивании позиций вершин. Достаточно отметить, что все определяющие характеристики (центр, размеры и ориентация) минимального ограничивающего объема не зависят от кластеризации вершин объекта. Это легко увидеть, добавив (или убрав) лишние вершины вне центра, внутри или на границе ограничивающего объема. Эти действия не влияют на определяющие характеристики объема и, следовательно, не должны влиять на его расчет. Однако добавление дополнительных точек таким образом изменяет ковариационную матрицу точек и, следовательно, любые характеристики OBB, непосредственно вычисленные из матрицы. Ситуацию можно улучшить, рассматривая только экстремальные точки, используя только те точки на выпуклой оболочке модели. Это устраняет внутренние точки, которые больше не могут смещать OBB. Однако даже если все оставшиеся точки являются экстремальными, результирующий OBB все равно может быть сколь угодно плохим из-за распределения точек. Группирование точек по-прежнему будет смещать ось в сторону кластера. Другими словами, использование одних только вершин просто не может дать надежных ковариационных матриц.

Предлагаемое решение - использовать непрерывную формулировку ковариации, вычисляя ковариацию по всей поверхности примитивов [Gottschalk00]. Для расчетов все же следует использовать выпуклую оболочку. В противном случае небольшая внешняя геометрия расширила бы ограничивающую рамку, но не внесла бы достаточного значения для правильного выравнивания рамки. Кроме того, внутренняя геометрия все равно будет искажать ковариацию. Если выпуклая оболочка уже доступна, этот алгоритм $O(n)$. Если необходимо вычислить выпуклую оболочку, она равна $O(n \log n)$.

Даны n треугольников $p_k, q_k, r_k, 0 ≤ k < n$, в выпуклой оболочке ковариационная матрица имеет вид

$$C_{ij}=\Bigl(\frac{1}{a_H}\sum_{0 ≤ k < n}\frac{a_k}{12}(9m_{k,i} m_{k,j} + p_{k,i} p_{k,j} + q_{k,i} q_{k,j} + r_{k,i} r_{k,j})\Bigr) − m_{H,i} m_{H,j} ,$$

<!-- 
$$\Bigl(\bigl\{\{ \mid \}\mid\bigr \}\mid\Bigr)$$
-->

где $a_k = \mid(q_k − p_k) × (r_k − p_k)\mid/2$ это площадь и $m_k = (p_k + q_k + r_k)/3$ центр тяжести треугольника k.

Общая площадь выпуклой оболочки определяется выражением

$$a_H = \sum_{0 ≤ k < n} a_k ,$$

и центр тяжести выпуклой оболочки,

$$m_H =\frac{1}{a_H}\sum_{0 ≤ k < n} a_k m_k ,$$

вычисляется как среднее значение центроидов треугольников, взвешенных по их площади. Индексы i и j указывают, какой компонент координат взят (то есть x, y или z). Код для этого расчета можно найти в общедоступном пакете обнаружения столкновений RAPID. Несколько другая формулировка этой ковариационной матрицы приведена в [Eberly01],
и код доступен на прилагаемом компакт-диске к этой книге.

Только что описанный метод рассматривает многогранник как полое тело, вычисляя ковариационную матрицу по площадям поверхности. Родственный метод, рассматривающий многогранник как твердое тело, описан в [Mirtich96a]. Учитывая предполагаемый многогранник однородной плотности, алгоритм массовых свойств многогранника Миртиха интегрирует по объему многогранника, вычисляя его тензор инерции 3 × 3 (также известный как матрица инерции или массы). Собственные векторы этой симметричной матрицы называются главными осями инерции, а собственные значения - главными моментами инерции. Как и в случае с ковариационными матрицами ранее, метод Якоби может использоваться для извлечения этих осей, которые, в свою очередь, могут затем служить в качестве матрицы ориентации OBB. Подробный псевдокод для вычисления матрицы инерции приведен в статье Миртича. Реализация общедоступного домена на языке C также доступна для загрузки в Интернете. Возвращение к статье Миртича [Eberly03], в котором получен более эффективный с вычислительной точки зрения подход и для которого предоставляется псевдокод.

Обратите внимание, что ни ковариационно-ориентированные, ни ориентированные по инерции ограничивающие параллелипипеды не являются оптимальными. Рассмотрим объект A и связанный с ним OBB B. Пусть A будет расширен добавлением к нему некоторой геометрии, но оставаясь в пределах B. Для обоих методов это, как правило, приведет к другому OBB B' для нового объекта A'. По построению B и B' оба покрывают два объекта A и A'. Однако, поскольку размеры двух OBB в общем случае различны, один OBB должен быть неоптимальным.

### 4.4.4 Оптимизация OBB на основе PCA

Поскольку OBB с выравниванием по ковариации не являются оптимальными, есть основания полагать, что их можно улучшить с помощью небольших модификаций. Например, возможно, OBB можно было бы повернуть вокруг одной из своих осей, чтобы найти ориентацию, для которой его объем наименьший. Один из улучшенных подходов к подгонке OBB - выровнять блок только по одному основному компоненту. Остальные два направления определяются из вычисленного ограничивающего прямоугольника с минимальной площадью проекции всех вершин на перпендикулярную плоскость к выбранной оси. Фактически, этот метод определяет наилучшее вращение вокруг данной оси для получения OBB наименьшего объема.

Такой подход был предложен в [Barequet96], в котором были исследованы три различных метода.

- Параллелипипед всех главных компонент
- Параллелипипед max-главных компонент
- Параллелипипед min-главных компонент

«Параллелипипед всех главных компонент» использует все три основных компонента для выравнивания OBB и эквивалентен методу, представленному в предыдущем разделе. Для параллелипипеда максимальных главных компонент собственный вектор, соответствующий наибольшему собственному значению, выбирается как длина OBB. Затем все точки проецируются на плоскость, перпендикулярную этому направлению. После проекции вычисляется ограничивающий прямоугольник с минимальной площадью проецируемых точек, определяющий оставшиеся два направления OBB. Наконец, блок min-главных компонент выбирает самый короткий главный компонент в качестве начального направления OBB, а затем действует, как в предыдущем методе. На основании эмпирических результатов [Barequet96]
сделал вывод, что метод минимальной главной компоненты работает лучше всего. Также приводится убедительная причина, по которой max-главных компонент не работает лучше: поскольку максимальная главная компонента - это направление с максимальной дисперсией, она будет давать максимально длинный край и, следовательно, вероятно, приведет к большему объему.

Локальный минимальный объем может быть достигнут повторением этого метода для данного начального OBB. Процедура проецирует все вершины на плоскость, перпендикулярную одному из направлений OBB, обновляя OBB для выравнивания с ограничивающим прямоугольником минимальной площади проекции. Итерации будут повторяться до тех пор, пока никакая проекция (вдоль любого направления OBB) не даст улучшения, после чего локальный минимум не будет найден. Этот метод служит отличной оптимизацией блоков, вычисляемых другими методами, такими как метод Миртиха, когда выполняется в качестве этапа предварительной обработки.

Остается проблема вычисления ограничивающего прямоугольника с минимальной площадью набора точек на плоскости. Ключевой вывод здесь сделан из области вычислительной геометрии. Он утверждает, что ограничивающий прямоугольник с минимальной площадью выпуклого многоугольника имеет (по крайней мере) одну сторону, коллинеарную ребру многоугольника [Freeman75].

Таким образом, минимальный прямоугольник можно легко вычислить с помощью простого алгоритма. Сначала вычисляется выпуклая оболочка набора точек, в результате чего получается выпуклый многоугольник. Затем ребро многоугольника рассматривается как одно направление ограничивающего параллелипипеда. Получается перпендикуляр к этому направлению, и все вершины многоугольника проецируются на эти две оси, и вычисляется площадь прямоугольника. Когда все ребра многоугольника были протестированы, ребро (и его перпендикуляр), дающий наименьшую площадь, определяет направления ограничивающего прямоугольника с минимальной площадью. Для каждого рассматриваемого ребра площадь прямоугольника вычисляется за время $O(n)$, общая сложность алгоритма в целом составляет $O(n^2)$. Этот алгоритм может быть реализован следующим образом:

```cpp
    // Вычислить центральную точку, ’c’, и ориентацию оси, u[0] и u[1], 
    // прямоугольника минимальной площади в плоскости xy, содержащего точки pt[].
    float MinAreaRect(Point2D pt[], int numPts, Point2D &c, Vector2D u[2]) {
        float minArea = FLT_MAX;
        // Пройти все рёбра; j отстает от i на 1 по модулю numPts
        for (int i = 0, j = numPts - 1; i < numPts; j = i, i++) {
            // Получить текущее ребро e0 (e0x,e0y), нормализовать
            Vector2D e0 = pt[i] - pt[j];
            e0 /= Length(e0);
            // Получить ось e1, перпендикулярную ребру e0
            Vector2D e1 = Vector2D(-e0.y, e0.x); // = Perp2D(e0)
            // Цикл по всем точкам, чтобы получить максимальные размеры
            float min0 = 0.0f, min1 = 0.0f, max0 = 0.0f, max1 = 0.0f;
            for (int k = 0; k < numPts; k++) {
                // Спроецировать точки на оси e0 и e1 и отслеживать 
                // минимальные и максимальные значения по двум осям
                Vector2D d = pt[k] - pt[j];
                float dot = Dot2D(d, e0);
                if (dot < min0) min0 = dot;
                if (dot > max0) max0 = dot;
                dot = Dot2D(d, e1);
                if (dot < min1) min1 = dot;
                if (dot > max1) max1 = dot;
            }
            float area = (max0 - min0) * (max1 - min1);
            // Если пока что лучше, запомнить площадь, центр и оси
            if (area < minArea) {
                minArea = area;
                c = pt[j] + 0.5f * ((min0 + max0) * e0 + (min1 + max1) * e1);
                u[0] = e0; u[1] = e1;
            }
        }
        return minArea;
    }
```

Прямоугольник, ограничивающий минимальную площадь выпуклого многоугольника, также можно вычислить за время $O(n \log n)$, используя метод *вращающихся измерителей* [Toussaint83]. Алгоритм вращающихся измерителей начинается с ограничения многоугольника четырьмя линиями через крайние точки многоугольника, так что линии определяют прямоугольник. Выбирается хотя бы одна линия, совпадающая с ребром многоугольника. Для каждой итерации алгоритма линии одновременно поворачиваются по часовой стрелке вокруг своих опорных точек, пока линия не совпадет с ребром многоугольника. Теперь линии образуют новый ограничивающий прямоугольник вокруг многоугольника. Процесс повторяется до тех пор, пока линии не будут повернуты на угол 90 градусов от их первоначальной ориентации. Ограничивающий прямоугольник с минимальной площадью соответствует прямоугольнику с наименьшей площадью, определяемым линиями на всех итерациях. Временная сложность алгоритма ограничена стоимостью вычисления выпуклой оболочки. Если она уже доступна, то сложность $O(n)$.

### 4.4.5 Установка OBB методом перебора

Последний рассмотренный здесь подход к подгонке OBB - это просто вычисление OBB брутфорсом. Один из способов выполнить подгонку методом перебора - каким-либо образом параметризовать ориентацию OBB. Пространство ориентаций дискретизируется через равные промежутки времени в процессе параметризации, и сохраняется лучший OBB для всех выбранных вращений. Затем ориентация OBB уточняется путем выборки интервала, в котором был найден лучший OBB при более высоком разрешении субинтервалов. Этот подход к восхождению на холм повторяется с все меньшим и меньшим интервалом разрешения до тех пор, пока не будет практически никакого изменения ориентации для наилучшего OBB.

Для каждой тестируемой системы координат вычисление OBB-кандидата требует преобразования всех вершин в систему координат. Поскольку это преобразование является дорогостоящим, поиск должен завершиться, как только OBB-кандидат станет хуже, чем лучший в настоящее время OBB. Поскольку он дешев в вычислении и имеет относительно хорошее соответствие, OBB, оснащенный PCA, обеспечивает хорошее начальное предположение, увеличивая шансы на раннее отключение во время точечного преобразования [Miettinen02a]. Чтобы еще больше повысить вероятность раннего завершения, (до) шести крайних точек, определяющих предыдущий OBB, должны быть первыми преобразованными вершинами. В [Miettinen02b] сообщается, что более 90% тестов завершаются досрочно с использованием этой оптимизации. Подгонка OBB методом грубой силы обычно приводит к гораздо более точным OBB, чем полученная при подгонке на основе PCA.

Только что описанный подход к восхождению в гору учитывает множество точек выборки в пространстве ориентации перед обновлением лучшего на данный момент OBB. Метод OBB-подгонки на основе оптимизации, описанный в [Lahanas00], поднимается по пространству поиска по одной выборке за раз, но использует технику множественных выборок, чтобы помочь оптимизатору выйти из локальных минимумов.

## 4.5 Ометаемые сферой объёмы

После сфер и параллелипипедов естественно рассматривать цилиндры как ограничивающие объемы.
К сожалению, когда математика проработана, выясняется, что испытание на пересечение для цилиндров довольно дорогое, что делает их менее привлекательными в качестве ограничивающих объемов. Однако, если цилиндр снабжен сферическими торцевыми крышками, результирующий объем цилиндра с крышкой становится более привлекательным ограничивающим объемом. Пусть цилиндр описывается точками A и B (образующими его среднюю ось) и радиусом r. Цилиндр с крышкой был бы объемом, полученным в результате перемещения сферы радиуса r вдоль отрезка AB. Этот объём является частью семейства объёмов, расширений основной сферы.

**Рисунок 4.11** (a) Ометаемая сферой Точка (sphere-swept point, SSP). (b) Ометаемая сферой Линия (sphere-swept line, SSL). (c) Ометаемый сферой Прямоугольник (sphere-swept rectangle, SSR).

Напомним, что тест между двумя сферами вычисляет расстояние между двумя центральными точками, сравнивая результат с суммой радиусов (возведение величин в квадрат, чтобы избежать дорогостоящего квадратного корня). Заменяя центральные точки сферы произвольными внутренними примитивами или средними структурами, можно получить новые ограничивающие объемы. Результирующие объемы эквивалентны охвату внутреннего примитива сферой радиуса r (или, технически, формированию суммы Минковского сферы и примитива). Таким образом, все это семейство ограничивающих объемов вместе называется *ометаемыми сферой объемами* (sphere-swept volumes, SSVs). Все точки на расстоянии r от внутренней медиальной структуры принадлежат SSV. На рисунке 4.11 проиллюстрированы три типа ометаемых сферой объема.

После теста на пересечение сфер тест на пересечение для двух SSV просто сводится к вычислению (возведенного в квадрат) расстояния между двумя внутренними примитивами и его сравнению с (возведенной в квадрат) суммой их объединенных радиусов. Стоимость тестов со сферами полностью определяется стоимостью функции расстояния. Чтобы сделать проверку расстояния как можно более дешевой, внутренние примитивы обычно ограничиваются точками, отрезками линий или прямоугольниками. Результирующие SSV - Ометаемая сферой Точка (SSP), Ометаемая сферой Линия (SSL) и Ометаемый сферой Прямоугольник (SSR) - обычно называются, соответственно, сферами, капсулами и леденцами (lozenge). Последний выглядит как OBB с закругленными углами и краями. Капсулы также называют цилиндрами с крышками или сфероцилиндрами. Структуры данных для капсул и леденцов можно определить следующим образом:

```cpp
    // Region R = { x | (x - [a + (b - a)*t])∧2 <= r } , 0 <= t <= 1
    struct Capsule {
        Point a;
        // Начальная точка отрезка средней линии
        Point b;
        // Конечная точка отрезка средней линии
        float r;
        // Радиус
        };
        // Region R = { x | (x - [a + u[0]*s + u[1]*t]) ∧ 2 <= r } , 0 <= s,t <= 1
        struct Lozenge {
        Point a;     // Начало
        Vector u[2]; // Оси двух рёбер прямоугольника
        float r;     // Радиус
    };
```

Из-за схожести по форме леденцы могут быть жизнеспособной заменой OBB. В условиях непосредственной близости вычисление расстояния леденцов становится менее затратным, чем тест разделительной оси OBB.

### 4.5.1 Пересечение ометаемых сферой объемов

По конструкции все тесты с ометанием сферой могут быть сформулированы одинаково. Сначала вычисляется расстояние между внутренними конструкциями. Затем это расстояние сравнивается с суммой радиусов. Единственная разница между любыми двумя типами тестов с ометанием сфер заключается в расчетах, используемых для вычисления расстояния между внутренними структурами двух объемов. Полезное свойство сферических объемов состоит в том, что вычисление расстояния между внутренними структурами не зависит от того, являются ли внутренние структуры одного типа. Таким образом, можно легко построить тесты смешанного типа или гибридные. Ниже представлены два теста: сфера-капсула и капсула-капсула.

```cpp
    int TestSphereCapsule(Sphere s, Capsule capsule) {
        // Вычислить (возведенное в квадрат) расстояние между центром сферы и отрезком линии капсулы
        float dist2 = SqDistPointSegment(capsule.a, capsule.b, s.c);
        // Если квадрат расстояния меньше квадрата суммы радиусов, они сталкиваются
        float radius = s.r + capsule.r;
        return dist2 <= radius * radius;
    }
```

```cpp
    int TestCapsuleCapsule(Capsule capsule1, Capsule capsule2) {
        // Вычислить (возведенное в квадрат) расстояние между внутренними структурами капсул
        float s, t;
        Point c1, c2;
        float dist2 = ClosestPtSegmentSegment(capsule1.a, capsule1.b,
        capsule2.a, capsule2.b, s, t, c1, c2);
        // Если квадрат расстояния меньше квадрата суммы радиусов, они сталкиваются
        float radius = capsule1.r + capsule2.r;
        return dist2 <= radius * radius;
    }
```

Используемые здесь функции **SqDistPointSegment()** и **ClosestPtSegmentSegment()** находятся в главе 5 (разделы 5.1.2.1 и 5.1.9 соответственно). Тест расстояния для SSR (и, следовательно, путем сокращения, также для SSL и SSP) на основе тестов полупространства приведен в [Larsen99] и [Larsen00].

### 4.5.2 Вычисление ометаемых сферой ограничивающих объемов

Аппарат, необходимый для вычисления SSV, был описан в предыдущих разделах. Например, вычислив главные оси, капсула может быть подогнана с помощью самой длинной оси в качестве длины капсулы. Следующая по длине ось определяет радиус. В качестве альтернативы, длина также может быть подобрана с использованием метода наименьших квадратов для подгонки линии к набору точек. Для SSR будут использоваться все три оси, причем самая короткая ось образует нормаль прямоугольной грани. Смотрите подробнее [Eberly01], [Larsen99], и [Larsen00].

## 4.6 Объемы пересечения полупространства

За исключением сфер, большинство ограничивающих объемов представляют собой выпуклые многогранники. Все эти ограничивающие многогранные объемы могут быть представлены как пересечение набора полупространств, причем плоскости, разделяющие полупространство, совпадают со сторонами ограничивающего объема. Например, AABB и OBB являются пересечением шести полупространств. Тетраэдр - это пересечение четырех полупространств - наименьшее количество полупространств, необходимых для образования замкнутого объема. Как правило, чем больше полупространств используется, тем лучше полученный объем пересечения подходит для объекта. Если ограниченный объект является многогранным, то самый плотный выпуклый ограничивающий объем - это выпуклая оболочка объекта. В этом случае количество граней на корпусе служит практическим верхним пределом того, сколько полупространств необходимо для формирования ограничивающего объема. Выпуклые оболочки являются важными ограничивающими объемами, и подробное рассмотрение алгоритмов обнаружения столкновений для выпуклых оболочек дается в главе 9.

Хотя выпуклые оболочки образуют самые плотные ограничивающие объемы, они не обязательно являются лучшим выбором ограничивающего объема. Некоторые недостатки выпуклых оболочек включают в себя их дороговизну и сложность вычислений, требующие больших объемов памяти для представления и потенциально дорогостоящие операции. Ограничивая количество полупространств, используемых в объеме пересечения, можно сформировать несколько более простых альтернативных ограничивающих объемов. Несколько вариантов описаны в следующих разделах.

**Рисунок 4.12** Плита - это бесконечная область пространства между двумя плоскостями, определяемая нормалью **n** и двумя знаковыми расстояниями от начала координат.

### 4.6.1 Kay–Kajiya объемы на основе плит (Slab)

Объемы Kay–Kajiya, впервые представленные Каем и Каджией для ускорения тестов на пересечение лучей и объектов, представляют собой семейство многосторонних параллелепипедных ограничивающих объемов, основанных на пересечении плит [Kay86]. Плита - это бесконечная область пространства между двумя параллельными плоскостями (Рисунок 4.12). Этот набор плоскостей представлен единичным вектором **n** (нормаль набора плоскостей) и двумя скалярными значениями, дающими знаковое расстояние от начала координат (вдоль **n**) для обеих плоскостей.

```cpp
    // Region R = { (x, y, z) | dNear <= a*x + b*y + c*z <= dFar }
    struct Slab {
        float n[3];  // Нормаль n = (a, b, c)
        float dNear; // Знаковое расстояние от начала координат для ближней плоскости (dNear)
        float dFar;  // Знаковое расстояние от начала координат для дальней плоскости (dFar)
    };
```

Для формирования ограничивающего объема выбирается ряд нормалей. Затем для каждой нормали располагаются пары плоскостей так, чтобы они ограничивали объект с обеих сторон вдоль направления нормали. Для многоугольных объектов положение плоскостей может быть найдено путем вычисления скалярного произведения нормали и каждой вершины объекта. Тогда минимальное и максимальное значения являются необходимыми скалярными значениями, определяющими положения плоскости.

Для образования замкнутого 3D-объема требуется не менее трех плит. И AABB, и OBB являются примерами объемов, образованных на пересечении трех плит. Увеличивая количество плит, можно сделать так, чтобы ограничивающие объемы на основе плиты соответствовали выпуклой оболочке объектов с произвольной плотностью.

Для первоначального применения пересечения лучей быстрая проверка может быть основана на том факте, что параметризованный луч пересекает плиту тогда и только тогда, когда он одновременно находится внутри всех (трех) плит в течение некоторого интервала, или, что эквивалентно, если пересечение интервалов для перекрытие лучей и плит отличное от нуля. Если пары плоскостей имеют одну и ту же нормаль, вычисления могут быть разделены между двумя тестами на пересечение лучей и плоскостей, что повышает производительность теста.

Объемы на основе плит позволяют проводить тесты на быстрое пересечение лучей, разделяя нормали для всех объектов, можно выполнять быстрые объектно-объектные тесты (подробнее об этом в следующем разделе).

### 4.6.2 Дискретно-ориентированные многогранники (Discrete-orientation Polytopes, k-DOPs)

Основанные на той же идее, что и объемы на основе плит Кая–Каджи, объемы, известные как многогранники с дискретной ориентацией (k-DOP) или оболочки фиксированного направления (fixed-direction hulls, FDH), предложенные
[Konečný97] и [Klosowski98]. (Хотя последний, возможно, более описательный термин, первый используется чаще и применяется здесь.) Эти k-DOP представляют собой выпуклые многогранники, почти идентичные объемам на основе плит, за исключением того, что нормали определяются как фиксированный набор осей, общие для всех ограничивающих объемов k-DOP. Нормальные компоненты обычно ограничиваются набором {-1, 0, 1}, а нормали не нормализуются. Эти нормали удешевляют вычисление k-DOP, что важно, поскольку k-DOP необходимо динамически перестраивать. Распределение нормалей между всеми объектами делает хранение k-DOP очень дешевым. Должны быть сохранены только минимальные и максимальные интервалы для каждой оси. Например, 8-DOP становится:

```cpp
    struct DOP8 {
        float min[4]; // Минимальное  расстояние (от начала координат) по осям от 0 до 3
        float max[4]; // Максимальное расстояние (от начала координат) по осям от 0 до 3
    };
```

6-DOP обычно относится к многогранникам с гранями, выровненными по шести направлениям
(±1, 0, 0), (0, ±1, 0), и (0, 0, ±1). Этот 6-DOP, конечно, является AABB, но AABB - это просто особый случай 6-DOP; любой ориентированный ограничивающий параллелипипед можно также описать как 6-DOP. У 8-DOP грани выровнены по восьми направлениям (±1, ±1, ±1) и 12-DOP с 12 направлениями (±1, ±1, 0), (±1, 0, ±1), и (0, ±1, ±1). Пример 2D 8-DOP показан на рисунке 4.13.

14-DOP определяется с использованием комбинированных направлений 6-DOP и 8-DOP. Аналогичным образом формируются 18-DOP, 20-DOP, и 26-DOP. 14-DOP соответствует выровненному по оси прямоугольнику с обрезанными восемью углами. 18-DOP - это AABB, у которого обрезаны 12 рёбер. 18-DOP также называют трибоксом [Crosnier99].

**Рисунок 4.13** 8-DOP для треугольника (3, 1), (5, 4), (1, 5) это {1, 1, 4, −4, 5, 5, 9, 2} для осей (1, 0), (0, 1), (1, 1), (1, −1).

Обратите внимание, что k-DOP - это не просто пересечение плит, а самые плотные плиты, образующие тело. Например, треугольник (0, 0), (1, 0), (0, 1) может быть представлен разными пересечениями плит, но описывает это только один k-DOP. Если и только если плоскости перекрытий имеют общую точку с объемом, образованным пересечением плит, эти плиты определяют k-DOP. Этот критерий герметичности важен, так как тест на пересечение для k-DOP работает не на объеме пересечения, а только на определениях плиты. Без данного ограничения проверка на пересечение была бы совершенно неэффективной.

По сравнению с ориентированными ограничивающими параллелипипедами, тест на пересечение для k-DOP намного быстрее (примерно на порядок), даже для DOP с большим числом элементов, благодаря плоскостям с фиксированным направлением. Что касается хранилища, такой же объем памяти, необходимый для OBB, примерно соответствует объему 14-DOP. k-DOP имеют (вероятно) более плотную посадку, чем OBB, конечно, когда k растет и k-DOP напоминает выпуклую оболочку. Для геометрии, которая плохо совпадает с осями k-DOP, OBB могут быть более тугими. OBB также будет лучше работать в непосредственной близости.

Самый большой недостаток k-DOP состоит в том, что даже если объёмы редко сталкиваются, k-DOP все равно нужно обновлять или «переворачивать». Поскольку эта операция дорогостоящая, по возможности следует избегать операции переворачивания. Обычно это делается путем предварительного тестирования объектов с использованием ограничивающих сфер (без выполнения теста k-DOP, если тест сферы не прошел). В общем, k-DOP работают лучше всего, когда несколько динамических объектов тестируются на многих статических объектах (необходимо обновить несколько k-DOP) или когда один и тот же объект участвует в нескольких тестах (стоимость обновления k-DOP уменьшается по тестам).

Немного другой k-DOP рассматривается в [Zachmann00]. Здесь оси k-DOP выбираются с использованием процесса моделирования отжига, в котором k точек случайным образом распределяются на единичной сфере с учетом того, что для каждой точки P, −P тоже есть в комплекте. Отталкивающая сила между точками используется в качестве температуры отжига.

### 4.6.3 Тест на пересечение k-DOP – k-DOP

Из-за того, что фиксированный набор осей является общим для всех объектов, обнаружение пересечения для k-DOP аналогично тестированию двух AABB на пересечение и не сложнее его. Тест просто проверяет интервалы k/2 на пересечение. Если какие-либо пары интервалов не перекрываются, k-DOP не пересекаются. Только если все пары интервалов перекрываются, k-DOP пересекаются.

```cpp
int TestKDOPKDOP(KDOP &a, KDOP &b, int k) {
    // Проверка на пересечение каких-либо интервалов
    for (int i = 0; i < k/2; i++)
        if (a.min[i] > b.max[i] || a.max[i] < b.min[i])
            return 0;
    // Все интервалы перекрываются, поэтому k-DOP должны пересекаться
    return 1;
}
```

Как и в случае с ориентированными ограничивающими параллелипипедами, порядок, в котором проверяются оси, вероятно, повлияет на производительность. Поскольку интервалы вдоль «близких» направлений, вероятно, будут иметь одинаковый статус перекрытия, последовательные интервальные тесты предпочтительно следует проводить в существенно разных (перпендикулярных) направлениях. Один из способов добиться этого - предварительно обработать порядок глобальных осей с помощью простого жадного алгоритма. Начиная с любой оси, которую нужно протестировать первой, он упорядочит все оси так, чтобы преемником текущей оси была та, скалярное произведение которой с текущей осью было как можно ближе к нулю.

### 4.6.4 Вычисление и настройка k-DOP

Вычисление k-DOP для объекта можно рассматривать как обобщение метода вычисления AABB, так же как тест перекрытия для двух k-DOP на самом деле является обобщением теста перекрытия AABB-AABB. Таким образом, k-DOP просто вычисляется из проекционного распространения вершин объекта вдоль определяющих осей k-DOP. По сравнению с расчетом AABB, единственное отличие состоит в том, что вершины должны быть спроецированы на оси, и нужно учитывать больше осей. Ограничение на сохранение компонентов оси в наборе {−1, 0, 1} делает жестко запрограммированную функцию для вычисления k-DOP менее затратной, чем обычная функция для произвольных направлений, поскольку проекция вершин на эти оси теперь включает не более трех дополнений. Например, 8-DOP вычисляется следующим образом:

```cpp
    // Вычислить 8-DOP для вершин объекта v[] в мировых координатах
    // с помощью осей (1,1,1), (1,1,-1), (1,-1,1) и (-1,1,1)
    void ComputeDOP8(Point v[], int numPts, DOP8 &dop8) {
        // Инициализация 8-DOP в пустой объём
        dop8.min[0] = dop8.min[1] = dop8.min[2] = dop8.min[3] = FLT_MAX;
        dop8.max[0] = dop8.max[1] = dop8.max[2] = dop8.max[3] = -FLT_MAX;
        // Для каждой точки при необходимости обновить границы 8-DOP
        float value;
        for (int i = 0; i < numPts; i++) {
            // Ось 0 = (1,1,1)
            value = v[i].x + v[i].y + v[i].z;
            if (value < dop8.min[0]) dop8.min[0] = value;
            else if (value > dop8.max[0]) dop8.max[0] = value;
            // Ось 1 = (1,1,-1)
            value = v[i].x + v[i].y - v[i].z;
            if (value < dop8.min[1]) dop8.min[1] = value;
            else if (value > dop8.max[1]) dop8.max[1] = value;
            // Ось 2 = (1,-1,1)
            value = v[i].x - v[i].y + v[i].z;
            if (value < dop8.min[2]) dop8.min[2] = value;
            else if (value > dop8.max[2]) dop8.max[2] = value;
            // Ось 3 = (-1,1,1)
            value = -v[i].x + v[i].y + v[i].z;
            if (value < dop8.min[3]) dop8.min[3] = value;
            else if (value > dop8.max[3]) dop8.max[3] = value;
        }
    }
```

Хотя k-DOP инвариантны при перемещении, при вращении объем не выровнен с предварительно заданными осями. Следовательно, как и в случае с AABB, k-DOP необходимо перестраивать при каждом повороте объёма. Простое решение - пересчитать k-DOP с нуля, как описано. Однако, поскольку пересчет k-DOP включает в себя преобразование вершин объекта в новое пространство, это становится дорогостоящим при большом количестве вершин объекта. Более эффективный подход к перестройке - использование метода подъема на холм, подобного тому, который описан в разделе 4.2.5 для вычисления AABB. Единственное отличие состоит в том, что вместо того, чтобы отслеживать шесть ссылок на вершины выпуклой оболочки, альпинист для k-DOP теперь будет отслеживать k ссылок на вершины, по одной для каждого направления грани k-DOP. Если когерентность между кадрами высока, а объекты вращаются между кадрами на небольшие промежутки времени, отслеживание вершин - хороший подход. Однако наихудшая сложность этого метода - $O(n^2)$, и он может плохо работать при низкой когерентности. Восхождение на холм приводит к жесткому ограничению объема.

Другой, приближенный, подход основан на вычислении и сохранении вершин каждого k-DOP для его начальной локальной ориентации во время препроцессора. Затем во время выполнения k-DOP пересчитывается из этих вершин и преобразуется в мировое пространство с помощью текущей матрицы ориентации. Это эквивалентно методу AABB, описанному в Разделе 4.2.6.

Множество вершин k-DOP в его начальной ориентации можно вычислить с помощью отображения преобразования двойственности. Здесь двойственное отображение плоскости $ax+by+cz=1$ точка (a, b, c) и наоборот. Пусть определяющие плоскости k-DOP выражаются уравнениями плоскости. Затем, вычисляя выпуклую оболочку двойственной к этим плоскостям, грани (ребра и вершины) выпуклой оболочки отображаются в вершины (ребра и грани) пересечения исходных плоскостей при преобразовании обратно в соответствии с отображением двойственности. Чтобы эта процедура двойственности работала, k-DOP должен быть преобразован, чтобы содержать начало, если он еще не содержится в k-DOP. Для объемов, образованных пересечением полупространств, точка внутри объема может быть получена с помощью линейного программирования (см. Раздел 9.4.1). 

Другой, более простой вариант - вычислить внутреннюю точку методом попеременной проекции (MAP). Этот метод начинается с произвольной точки в пространстве. Цикл по всем полупространствам в произвольном порядке, точка обновляется, проецируя ее на ограничивающую гиперплоскость текущего полупространства всякий раз, когда она находится за пределами полупространства. Гарантированная сходимость, цикл по всем полупространствам повторяется до тех пор, пока точка не окажется внутри всех полупространств. Если начальная точка лежит за пределами объема пересечения, что вполне вероятно, результирующая точка будет лежать на границе объема пересечения и, в частности, на одной из ограничивающих гиперплоскостей. (Если точка находится внутри объема, методом возвращается сама точка.) Точка внутри объема получается повторением метода чередования проекций с разными начальными точками до тех пор, пока не будет получена вторая точка на другой ограничивающей гиперплоскости. Тогда внутренняя точка - это просто середина двух граничных точек. MAP может очень медленно сходиться для определенных входных данных. Однако для объемов, обычно используемых в качестве ограничивающих объемов, медленная сходимость обычно не является проблемой. Дополнительные сведения о MAP см. [Deutsch01]. Для получения дополнительной информации о преобразованиях двойственности (или полярности) см., например, [Preparata85], [O’Rourke98], or [Berg00].

Более простой способ вычисления начального набора вершин - рассмотреть все комбинации трех не копланарных плоскостей из входного набора граничных плоскостей k-DOP. Каждый такой набор из трех плоскостей пересекается в точке (Раздел 5.4.5 описывает, как вычисляется эта точка). После вычисления всех точек пересечения те, которые находятся перед одной или несколькими граничными плоскостями k-DOP, отбрасываются. Остальные точки являются вершинами k-DOP.

k-DOP также можно перестроить с помощью методов, основанных на линейном программировании, например
описаными в [Konečný97] и [Konečný98]. Более подробная стратегия перестройки представлена u200bu200bв [Fünfzig03]. Линейное программирование описано в разделе 9.4.

### 4.6.5 Приблизительные тесты на пересечение выпуклой оболочки

Проверить разделение между двумя выпуклыми многоугольниками легко (например, с помощью метода вращающихся измерителей, упомянутого в разделе 4.4.4). К сожалению, для многогранников проблема не так проста. Точные методы решения этой проблемы обсуждаются в главе 9. Однако во многих ситуациях полностью точное обнаружение столкновений многогранников может быть ненужным и нежелательным. Ослабив тест для получения приближенных решений, можно получить как более простые, так и более быстрые методы.

Один такой подход поддерживает как определяющие плоскости, так и вершины каждой выпуклой оболочки. Чтобы проверить пересечение двух оболочек, вершины каждой оболочки проверяются относительно плоскостей другой, чтобы увидеть, лежат ли они полностью вне какой-либо одной плоскости. Если это так, то корпуса не пересекаются. Если ни один из наборов вершин не находится вне какой-либо грани другой оболочки, корпуса консервативно считаются перекрывающимися. С точки зрения теста разделительной оси, это соответствует тестированию разделения на нормалях граней обоих оболочек, но не комбинаций рёбер-рёбер обоих.

Другой подход - просто заменить набор вершин набором сфер. Сферы выбираются так, чтобы их объединение аппроксимировало выпуклую оболочку. Теперь тест продолжается путем проверки сфер (вместо вершин) относительно плоскостей. Идея состоит в том, что по сравнению с тестами на вершины необходимо выполнять меньше тестов на сферы. Хотя этот тест быстрее, он менее точен. Для повышения точности при сохранении заданного размера набор сфер часто оптимизируется вручную.

Как и в случае с k-DOP, тестирование можно ускорить, приказав сохраненным плоскостям сделать следующие друг за другом плоскости как можно более перпендикулярными друг другу. Точно так же, чтобы избежать вырожденного поведения из-за кластеризации, вершины (или сферы) могут быть упорядочены случайным образом. Ограничение набора вершин сферой и проверка сферы относительно плоскости перед проверкой всех вершин часто допускают ранние выходы.

По сравнению с другими тестами ограничивающего объема, эти тесты все еще относительно дороги, и им обычно предшествует более дешевый тест ограничивающего объема (например, тест сферы и сферы), чтобы избежать оболочек в тестах, которые находятся достаточно далеко друг от друга и не пересекаются. Методы когерентности, представленные в главе 9, также полезны для минимизации количества тестов оболочек, которые необходимо выполнить.

## 4.7 Другие ограничивающие объемы

В дополнение к ограничивающим объемам, описанным здесь, многие другие типы объёмов были предложены в качестве ограничивающих объёмов. К ним относятся конусы [Held97], [Eberly02],
цилиндры [Held97], [Eberly00], [Schömer00], сферические оболочки [Krishnan98], эллипсоиды
[Rimon92], [Wang01], [Choi02], [Wang02], [Chien03], и зонотопы [Guibas03].
Конусы, цилиндры и эллипсоиды говорят сами за себя. Сферические оболочки - это пересечение объема между двумя концентрическими сферами и конусом с вершиной в центре сферы. Зонотопы - это центрально-симметричные многогранники с определенными свойствами. Эти формы не нашли широкого применения в качестве ограничивающих объемов, отчасти из-за дорогостоящих тестов на пересечение. По этой причине они здесь не рассматриваются.

Следует отметить, что в то время как эллипсоид-эллипсоид является дорогостоящим тестом на пересечение, тесты эллипсоидов по треугольникам и другим многоугольникам можно преобразовать в тестирование сферы по отношению к наклонному треугольнику, применив неравномерное масштабирование к координатному пространству. Таким образом, эллипсоиды являются допустимыми ограничивающими объемами для определенных наборов тестов.

## 4.8 Резюме

Ограничивающие объемы - это простые геометрические формы, используемые для инкапсуляции одного или нескольких объектов большей геометрической сложности. Чаще всего в качестве ограничивающих объемов используются сферы и параллелипипеды. Если требуется действительно точная подгонка, можно использовать объемные плиты или выпуклые оболочки. Ограничивающие объемы используются в качестве ранних тестов на пересечение, прежде чем более дорогие тесты будут выполнены на геометрии, заключенной в них. Как обсуждалось в Разделе 4.1, при выборе формы ограничивающего объема приходится сталкиваться с некоторыми трудностями.
При использовании ограничивающих объемов с более точной подгонкой вероятность раннего отклонения увеличивается, но в то же время тест ограничивающего объема становится более дорогим, а требования к памяти для ограничивающего объема возрастают. Как правило, ограничивающие объемы вычисляются на этапе предварительной обработки и, при необходимости, преобразуются с помощью ограниченных объектов во время выполнения, чтобы соответствовать движениям объектов.

В дополнение к подробному описанию наиболее распространенных ограничивающих объемов и того, как их вычислять, в этой главе описывается, как выполнять тесты на однородные пересечения (между объемами одного типа). Эти тесты были задуманы как тизер к главе 5, в которой подробно рассматриваются (разнородные) тесты пересечения и вычисления расстояний между примитивными геометрическими фигурами, такими как прямые и линейные сегменты, сферы, прямоугольники, треугольники, многоугольники и многогранники.


# Глава 5
# Базовые тесты примитивов

После того, как высокоуровневая система исключила как можно больше объектов из дальнейших тестов на столкновение, все системы столкновения должны выполнить тесты низкого уровня между примитивами или ограничивающими объемами для определения статуса пересечения. В некоторых случаях достаточно простого указания, есть ли пересечение. В других случаях требуется фактическая точка пересечения. В этой главе описывается, как эти низкоуровневые тесты могут быть эффективно выполнены. Кроме того, цель состоит в том, чтобы предоставить достаточно конкретных математических деталей, чтобы можно было вывести тесты, выходящие за рамки данной презентации, с использованием рассмотренных здесь математических идей.

Обратите внимание, что некоторые из представленных здесь математических выражений могут иметь проблемы с числовой точностью при реализации в арифметике с плавающей запятой. Эти проблемы здесь затронуты лишь вкратце. Более глубокое обсуждение вопросов устойчивости из-за проблем с числовой точностью можно найти в главе 11.

## 5.1 Вычисления ближайших точек

Запросы по ближайшим точкам - одни из самых мощных из запросов о конфликтах. Зная самые близкие точки между двумя объектами, имеем расстояние между объектами. Если суммарное максимальное перемещение двух объектов меньше расстояния между ними, столкновение можно исключить. В иерархическом представлении вычисления ближайших точек позволяют исключить из дальнейшего рассмотрения части иерархии, которые никогда не подойдут достаточно близко для столкновения.

Получение ближайших точек между двумя объектами можно рассматривать как проблему минимизации. Один из подходов состоит в том, чтобы сформулировать задачу минимизации и решить ее, используя методы исчисления (например, метод множителей Лагранжа). В этом тексте предпочтение отдается более геометрическому подходу, а в следующих подразделах показано, как можно получить ближайшие точки для различных геометрических объектов.

Обратите внимание, что ближайшие точки между двумя объектами иногда могут поддерживаться постепенно с небольшими затратами, что облегчает быстрое тестирование столкновений. Дополнительное вычисление ближайших точек более подробно рассматривается в главе 9 в контексте столкновения между выпуклыми объектами.

### 5.1.1 Ближайшая точка на плоскости к точке

Для плоскости π, определенной точкой P и нормалью n, все точки X на плоскости удовлетворяют уравнению $\textbf{n}·(X−P)=0$ (то есть вектор от $P$ до $X$ перпендикулярен $\textbf{n}$).
Пусть теперь $Q$ - произвольная точка в пространстве. Ближайшая точка $R$ на плоскости к $Q$ - это ортогональная проекция $Q$ на плоскость, полученная перемещением $Q$ перпендикулярно (относительно $\textbf{n}$) к плоскости. Это, $R = Q − t\textbf{n}$ для некоторого значения $t$, как показано на рисунке 5.1. Подставляя это выражение для R в уравнение плоскости и решая для $t$, получаем:


$\textbf{n} · ((Q − t\textbf{n}) − P) = 0 ⇔$ (вставка R вместо X в уравнение плоскости)

$\textbf{n} · Q − t(\textbf{n} · \textbf{n}) − \textbf{n} · P = 0 ⇔$ (раскрытие скалярного произведения)

$\textbf{n} · (Q − P) = t(\textbf{n} · \textbf{n}) ⇔$ (собираем похожие члены и перемещаем выражение t вправо)

$t = \textbf{n} · (Q − P)/(\textbf{n} · \textbf{n})$ (деление двух частей на $\textbf{n} · \textbf{n}$)

Подстановка этого выражения для $t$ в $R = Q - t\textbf{n}$ дает точку проекции R как

$$R = Q − (\textbf{n} · (Q − P)/(\textbf{n} · \textbf{n}))\textbf{n}.$$

Когда $n$ имеет единицы длины, $t$ упрощается до $t = \textbf{n} · (Q − P)$, давая $R$ просто
$R = Q − (\textbf{n} · (Q − P))\textbf{n}$. Из этого уравнения легко увидеть, что для произвольной точки
$Q$, $t = \textbf{n} · (Q − P)$ соответствует расстоянию со знаком $Q$ от плоскости в единицах длины $n$. Если $t$ положительно, $Q$ находится перед плоскостью (а если отрицательное, $Q$ находится позади плоскости).

Когда плоскость задается в четырехкомпонентном виде $\textbf{n} · X = d$, соответствующее выражение для $t$ - это $t = ((n · Q) − d)/(n · n)$. Таким образом, код для вычисления ближайшей точки на плоскости к точке становится:

```cpp
    Point ClosestPtPointPlane(Point q, Plane p) {
        float t = (Dot(p.n, q) - p.d) / Dot(p.n, p.n);
        return q - t * p.n;
    }
```

**Рисунок 5.1** Плоскость π, заданная буквами P и n. Ортогональная проекция Q на π дает R, ближайшую точку на π к Q.

Если известно, что уравнение плоскости нормализовано, это упрощается до $t = (n · Q) − d$, давая:

```cpp
    Point ClosestPtPointPlane(Point q, Plane p) {
        float t = Dot(p.n, q) - p.d;
        return q - t * p.n;
    }
```
Расстояние со знаком $Q$ до плоскости задается путем простого возврата вычисленного значения $t$:

```cpp
    float DistPointPlane(Point q, Plane p) {
        // return Dot(q, p.n) - p.d; если уравнение плоскости нормализовано (||p.n||==1)
        return (Dot(p.n, q) - p.d) / Dot(p.n, p.n);
    }
```

### 5.1.2 Ближайшая точка на отрезке линии к точке

Пусть AB будет отрезком прямой, заданным конечными точками A и B. Для произвольной точки C задача состоит в том, чтобы определить точку D на AB, ближайшую к C. Как показано на рисунке 5.2, проецирование C на удлиненную линию через AB обеспечивает решение. Если точка проекции P находится внутри сегмента, P сам по себе является правильным ответом. Если P лежит за пределами сегмента, то вместо этого конечная точка сегмента, ближайшая к C, является ближайшей точкой.

**Рисунок 5.2** Три случая проекции C на AB: (a) вне AB на стороне A, (b) внутри AB и (c) вне AB на стороне B.

Любую точку на линии, проходящей через AB, можно параметрически выразить как $P(t) = A +
t (B − A)$. Используя проективные свойства скалярного произведения, t, соответствующее проекции C на прямую, задается выражением $t = (C − A) · \textbf{n}/ \|B − A\|$, где
$n = (B − A)/ \|B − A\|$ - единичный вектор в направлении AB. Поскольку требуется ближайшая точка на отрезке линии, t необходимо ограничить интервалом 0 ≤ t ≤ 1, после чего D можно получить, подставив t в параметрическое уравнение. Реализовано это становится:

```cpp
    // Для данного отрезка ab и точки c вычисляет ближайшую точку d на отрезке ab.
    // Также возвращает t для позиции d, d(t) = a + t*(b - a)
    void ClosestPtPointSegment(Point c, Point a, Point b, float &t, Point &d){
        Vector ab = b – a;
        // Спроецировать c на ab, вычисляя параметризованное положение d(t) = a + t*(b – a)
        t = Dot(c – a, ab) / Dot(ab, ab);
        // Если за пределами сегмента, фикс t (и, следовательно, d) до ближайшей конечной точки
        if (t < 0.0f) t = 0.0f;
        if (t > 1.0f) t = 1.0f;
        // Вычислить прогнозируемое положение из фиксированного t
        d = a + t * ab;
    }
```

If divisions are expensive, the division operation can be postponed by multiply-
ing both sides of the comparisons by the denominator, which as a square term is
guaranteed to be nonnegative. Optimized in this fashion, the code becomes:

```cpp
    // Для данного отрезка ab и точки c вычислить ближайшую точку d на ab.
    // Также возвращает t для параметрической позиции d, d(t) = a + t*(b - a)
    void ClosestPtPointSegment(Point c, Point a, Point b, float &t, Point &d){
        Vector ab = b – a;
        // Спроецировать c на ab, но отложить деление на Dot(ab, ab)
        t = Dot(c – a, ab);
        if (t <= 0.0f) {
            // c выступает за пределы интервала [a, b], на сторону a; фикс к a
            t = 0.0f;
            d = a;
        } else {
            float denom = Dot(ab, ab); // Всегда неотрицательно, т.к denom = ||ab|| ∧ 2
            if (t >= denom) {
                // c проецируется за пределы интервала [a, b] на сторону b; фикс к b
                t = 1.0f;
                d = b;
            } else {
                // c проецируется внутри интервала [a, b]; надо сделать отложенное деление сейчас
                t = t / denom;
                d = a + t * ab;
            }
        }
    }
```

Тот же самый основной метод может использоваться для поиска ближайшей точки на луче или ближайшей точки на линии. Для луча необходимо фиксировать t только тогда, когда она становится отрицательным. Для линии зажимать t вообще не нужно.

#### 5.1.2.1 Расстояние от точки до сегмента
### 5.1.3 Ближайшая точка на AABB к точке
#### 5.1.3.1 Расстояние от точки до AABB
### 5.1.4 Ближайшая точка OBB к точке
#### 5.1.4.1 Расстояние от точки до OBB
#### 5.1.4.2 Ближайшая точка на 3D-прямоугольнике к точке
### 5.1.5 Ближайшая точка на Треугольнике к Точке
### 5.1.6 Ближайшая точка на Тетраэдре к Точке
### 5.1.7 Ближайшая точка Выпуклого многогранника к Точке
### 5.1.8 Ближайшие точки двух Линий
### 5.1.9 Ближайшие точки двух линейных участков
#### 5.1.9.1 2D Пересечение Сегментов
### 5.1.10 Ближайшие точки Отрезка линии и Треугольника
### 5.1.11 Ближайшие точки двух Треугольников
## 5.2 Тестирование пересечения примитивов
### 5.2.1 Тест разделяющей оси
#### 5.2.1.1 Устойчивость теста разделяющей оси
### 5.2.2 Тестирование пересечения Сферы и Плоскости
### 5.2.3 Тестирование пересечения Параллелипипеда и Плоскости
### 5.2.4 Тестирование пересечения Конуса и Плоскости
### 5.2.5 Тестирование пересечения Сферы и AABB
### 5.2.6 Тестирование пересечения Сферы и OBB
### 5.2.7 Тестирование пересечения Сферы и Треугольника
### 5.2.8 Тестирование пересечения Сферы и Многоугольника
### 5.2.9 Тестирование пересечения AABB и Треугольника
### 5.2.10 Тестирование пересечения Треугольника и Треугольника
## 5.3 Пересекающиеся линии, лучи и (направленные) сегменты
### 5.3.1 Пересекающиеся Сегмент и Плоскость
### 5.3.2 Пересекающиеся Луч или Сегмент и Сфера
### 5.3.3 Пересекающиеся Луч или Сегмент и Параллелипипед
### 5.3.4 Пересекающиеся Линия и Треугольник
### 5.3.5 Пересекающиеся Линия и Четырехугольник
### 5.3.6 Пересекающиеся Луч или Сегмент и Треугольник
### 5.3.7 Пересекающиеся Луч или Сегмент и Цилиндр
### 5.3.8 Пересекающиеся Луч или Сегмент и Выпуклый многогранник
## 5.4 Дополнительные тесты
### 5.4.1 Тестирование Точки в многоугольнике
### 5.4.2 Тестирование Точки в Треугольнике
### 5.4.3 Тестирование Точки в Многограннике
### 5.4.4 Пересечение двух Плоскостей
### 5.4.5 Пересечение трех Плоскостей
## 5.5 Тест динамических пересечений
### 5.5.1 Уменьшение вдвое интервала пересечения движущихся объектов
### 5.5.2 Тест разделяющей оси для движущихся выпуклых объектов
### 5.5.3 Пересечение движущейся Сферы относительно Плоскости
### 5.5.4 Пересечение движущихся AABB относительно Плоскости
### 5.5.5 Пересечение движущейся Сферы относительно Сферы
### 5.5.6 Пересечение движущейся сферы относительно треугольника (и многоугольника)
### 5.5.7 Пересечение движущейся сферы относительно AABB
### 5.5.8 Пересечение движущегося AABB относительно AABB
## 5.6 Резюме

# Глава 6
# Иерархии ограничивающих объемов

Обертывание объектов в ограничивающие объемы и выполнение тестов на ограничивающих объемах перед тестированием самой геометрии объекта может привести к значительному повышению производительности. Однако, хотя сами тесты были упрощены, то же количество парных тестов все еще выполняется. Асимптотическая временная сложность остается прежней, а использование ограничивающих объемов улучшает ситуацию на постоянный коэффициент. Путем организации ограничивающих объемов в древовидную иерархию, называемую иерархией ограничивающих объемов (bounding volume hierarchy, BVH), временная сложность может быть уменьшена до логарифмической по количеству выполненных тестов.

Исходный набор ограничивающих объемов образует листовые узлы дерева, которое представляет собой иерархию ограничивающих объемов. Эти узлы затем группируются в небольшие наборы и заключаются в большие ограничивающие объемы. Они, в свою очередь, также сгруппированы и заключены в другие большие ограничивающие объемы рекурсивным образом, что в конечном итоге приводит к древовидной структуре с одним ограничивающим объемом в верхней части дерева. На рисунке 6.1 показана небольшая иерархия AABB, состоящая из пяти объектов.

При наличии иерархии во время тестирования столкновений дочерние элементы не должны проверяться, если их родительский объем не пересекается. Те же самые иерархии ограничивающих объемов также используются, например, в графах сцены и трассировке лучей, а также для отсечения контуров просмотра.

Сравнивая иерархии ограничивающих объемов со схемами пространственного разделения (см. Главу 7), основные различия заключаются в том, что два или более объема в BVH могут занимать одно и то же пространство, а объекты обычно вставляются только в один объем. Напротив, в схеме пространственного разделения разделы не пересекаются, и объекты, содержащиеся в пространственном разделении, обычно могут быть представлены двумя или более разделами.

Важно отметить, что ограничивающий объем родительского узла не обязательно должен охватывать ограничивающие объемы его дочерних узлов. Хотя часто проще построить иерархии, в которых это свойство родитель-потомок имеет значение true, родительский ограничивающий объем должен включать только примитивы объекта, содержащиеся в поддеревьях его дочерних элементов.

**Рисунок 6.1** Иерархия ограничивающего объема из пяти простых объектов. Здесь используются ограничивающие объемы AABB.

Один из подходов к созданию иерархий состоит в том, чтобы дизайнеры или художники вручную создавали их как часть своих иерархий моделирования. Однако создание деревьев вручную - не лучший вариант. Во-первых, дизайнеры склонны мыслить функционально, а не пространственно. Следовательно, вполне вероятно, что, например, все гайки и болты в большой механической конструкции сгруппированы в одном узле. Такая группировка не годится с точки зрения обнаружения столкновений. Во-вторых, иерархия может быть либо слишком мелкой, либо слишком глубокой в неправильных местах. Иерархия моделирования дизайнера была - и, возможно, должна быть - построена для удобного редактирования, а не для обеспечения эффективных запросов пересечения. Хотя дизайнеры теоретически могли бы настроить свои иерархии так, чтобы они были более ориентированы на пространство и лучше подходили для запросов о конфликтах, вряд ли это будет эффективным использованием их времени. Лучшее решение - автоматизировать, где это возможно, создание иерархий из предоставленных моделей. Такая автоматизация не всегда является тривиальным процессом, и, как будет показано в следующем разделе, необходимо рассмотреть множество вопросов.

## 6.1 Вопросы проектирования иерархии

Есть много способов построить иерархию ограничивающего объема. В следующем разделе описывается ряд желаемых характеристик хороших иерархий. Общая функция стоимости, помогающая сравнивать затраты на запросы для различных иерархических схем, находится в Разделе 6.1.2. Наконец, в Разделе 6.1.3 обсуждается вопрос о том, какая степень дерева может обеспечить наилучшую иерархию.

### 6.1.1 Желаемые характеристики BVH

Подобно ограничивающим объемам, было предложено несколько желаемых свойств для ограничивающих иерархий объемов [Kaplan85] [Kay86] [Hubbard96]:

- *Узлы, содержащиеся в любом заданном поддереве, должны находиться рядом друг с другом.* Без явного определения близости, чем ниже по дереву узлы, тем ближе они должны быть друг к другу.
- *Каждый узел в иерархии должен иметь минимальный объем.*
- *Сумма всех ограничивающих объемов должна быть минимальной.*
- *Больше внимания следует уделять узлам около корня иерархии.* Обрезка узла около корня дерева удаляет больше объектов из дальнейшего рассмотрения, чем удаление более глубокого узла.
- *Объем перекрытия родственных узлов должен быть минимальным.*
- *Иерархия должна быть сбалансирована как по структуре узлов, так и по содержанию.* Балансировка позволяет обрезать как можно большую часть иерархии всякий раз, когда ветвь не попадает внутрь.

Для приложений реального времени, особенно игр, важным дополнением к предыдущему списку является требование, чтобы время обработки запросов в наихудшем случае было не намного хуже, чем время запроса в среднем случае. Это требование особенно важно для консольных игр, для которых обычно требуется фиксированная частота кадров (обычно 60 кадров в секунду).

Кроме того, желательно, чтобы иерархия могла создаваться автоматически без вмешательства пользователя. Для приложений реального времени большинство иерархий обычно создается на этапе предварительной обработки, а не во время выполнения. В играх чрезмерное ожидание построения предварительно вычисленных структур может пагубно сказаться на построении и дизайне уровней. Следовательно, хотя предварительные вычисления сокращают время построения, алгоритмы квадратичной сложности и выше, все же, вероятно, будут слишком медленными даже для использования в предварительной обработке. Если иерархия создается во время выполнения, построение иерархии также должно окупаться, поскольку время, затрачиваемое на построение, должно быть меньше времени, сэкономленного при использовании иерархии.

Наконец, очень важным фактором, часто упускаемым из виду при обработке обнаружения коллизий, является общая потребность в памяти для структур данных, используемых для представления иерархии ограничивающих объемов. Например, консольные игры выделяют примерно десятую часть доступной памяти для данных о столкновениях. В то время как встроенная память для консольных систем следующего поколения будет увеличиваться для каждого поколения, соотношение, выделенное для данных обнаружения столкновений, вероятно, останется примерно постоянным, поскольку требования к памяти для других систем (таких как рендеринг, анимация и AI) также растут пропорционально. Эти ограничения памяти устанавливают жесткие ограничения для всех рассматриваемых систем обнаружения столкновений.

### 6.1.2 Функции стоимости

Несколько человек придумали выражения для определения различных частей, влияющих на ожидаемую стоимость запросов иерархии ограничивающих объёмов. Формула стоимости, впервые представленная в [Weghorst84] и адаптирована для ограничения иерархии объёмов с помощью [Gottschalk96] и впоследствии усовершенствована в [Klosowski98] и [He99] :
$$T = N_V C_V + N_P C_P + N_U C_U + C_O.$$

Здесь $T$ - общая стоимость пересечения двух иерархий, $N_V$ - количество пар BV, проверенных на перекрытие, $C_V$ - стоимость тестирования пары BV на перекрытие, $N_P$ - количество протестированных пар примитивов, $C_P$ - стоимость тестирования пары примитивов, $N_U$ - количество узлов, которые необходимо обновить, $C_U$ - это стоимость обновления каждого такого узла, и, где необходимо, $C_O$ - стоимость одноразовой обработки (например, преобразования координат между объектами).

Из этих переменных, например, минимизируются $N_V$ и $N_P$, если ограничивающий объем максимально плотно прилегает к объекту. За счет максимально быстрого выполнения тестов на перекрытие $C_V$ и $C_P$ сводятся к минимуму. К сожалению, увеличение ограничивающего объема обычно увеличивает время выполнения теста на перекрытие. В то же время более жесткий ограничивающий объем, вероятно, приведет к меньшему количеству проверок пересечений. В общем, значения настолько неразрывно связаны, что минимизация одного значения часто приводит к увеличению другого. Поиск компромисса между существующими требованиями является проблемой для всех систем обнаружения столкновений.

### 6.1.3 Степень дерева

Интересный вопрос заключается в том, какую степень или коэффициент ветвления использовать в дереве, представляющем иерархию ограничивающего объема. Что лучше: двоичное, троичное, d-арное (для некоторого d) или дерево с любым количеством дочерних элементов в узле? Дерево с более высокой степенью будет иметь меньшую высоту, что минимизирует время обхода от корня к листу. В то же время на каждом посещаемом узле должно быть затрачено больше работы, чтобы проверить его дочерние узлы на перекрытие. Обратное верно для дерева с низкой степенью: хотя дерево будет большей высоты, на каждый узел тратится меньше работы. С точки зрения размера, d-арное дерево из n листьев имеет $(n − 1)/(d − 1)$ внутренних узлов, всего $(nd − 1)/(d − 1)$ узлов в дереве. Очевидно, что чем больше степень, тем меньше внутренних узлов требуется для формирования дерева.

Вопрос о том, в какой степени использовать, является сложным, и окончательного ответа не последовало. Если посмотреть на фактическое использование, кажется, что двоичные деревья - это, безусловно, наиболее распространенное иерархическое представление. Важная причина в том, что бинарные деревья легче строить и, в некоторой степени, представлять и перемещать, чем другие деревья. Например, при построении дерева сверху вниз, чтобы разделить набор объектов на два подмножества, нужно найти только одну плоскость разделения. Разделение $m$ объектов всего на два (непустых) раздела может быть выполнено $2^{m−1} - 1$ способами, и соответствующие выражения растут экспоненциально (и, следовательно, недопустимо) с увеличением числа разделов.

Аналитические аргументы также были выдвинуты в поддержку выбора бинарных деревьев [Klosowski98] [Konečný98]. Фактическая стоимость запроса коллизии зависит от того, какие правила спуска используются при обходе иерархий. Например, для сбалансированного d-арного дерева из n листьев правила «спуститься с A до B» и «спуститься с A и B одновременно» (оба описаны ниже) имеют затраты, пропорциональные $f(d) = d \log_d (n)$ и $f (d) = d^2 \log_d (n)$, соответственно. Первое минимизируется для $d=2,718$, а второе - для $d=2$, что предполагает использование двоичного или, возможно, троичного дерева в качестве оптимального. Эмпирические результаты также подтверждают выбор $d=2$, но они не являются окончательными, особенно потому, что с деревьями более высоких степеней, похоже, проводилось мало экспериментов.

Проблемы архитектуры платформы также играют важную роль в том, какие типы деревьев работают хорошо. В идеале деревья должны располагаться в памяти так, чтобы узлы располагались в памяти линейно во время обхода. Вопрос об эффективных древовидных структурах кэширования повторно рассматривается в главе 13.

## 6.2 Стратегии построения иерархии конструкций

Поскольку количество возможных деревьев растет экспоненциально с точки зрения количества элементов во входном наборе, исчерпывающий поиск лучшего дерева невозможен. Это исключает возможность поиска оптимального дерева. Вместо этого используются эвристические правила, чтобы направлять построение, исследуя несколько альтернатив на каждом этапе принятия решения, выбирая лучшую альтернативу. Достижение неоптимального решения не обязательно является проблемой, поскольку обычно существует очень большое количество деревьев, которые не слишком далеки от оптимального.

Существует три основных категории методов построения дерева: сверху вниз, снизу вверх и методы вставки (рис. 6.2). Нисходящие (или разделительные) методы осуществляются путем разделения входного набора на два (или более) подмножества, ограничения их в выбранном ограничивающем объеме, а затем рекурсии по ограниченным подмножествам. Благодаря простоте реализации, нисходящие методы являются наиболее популярными. Однако из них обычно не получаются самые лучшие деревья.

```cpp
// Оптимизаторы в Bullet:
Dbvt::optimizeBottomUp()
Dbvt::optimizeTopDown(int bu_treshold)
Dbvt::optimizeIncremental(int passes)
```

**Рисунок 6.2** Небольшое дерево из четырех объектов, построенное с использованием (а) нисходящего, (б) восходящего и (в) вставочного построения.

Восходящие (или агломеративные) методы начинаются с ввода, заданного как листья дерева, а затем группируют два или более из них, чтобы сформировать новый (внутренний) узел, действуя таким же образом, пока все не будет сгруппировано под одним узлом (корень дерева). Хотя восходящие методы могут дать более качественные деревья, чем другие методы, их также труднее реализовать.

Методы вставки создают иерархию постепенно, вставляя объекты по одному в дерево. Положение вставки выбирается таким образом, чтобы минимизировать некоторые затраты на результирующее дерево. Методы вставки считаются интерактивными методами, тогда как методы сверху вниз и снизу вверх считаются автономными, поскольку они требуют, чтобы все примитивы были доступны до начала построения. Преимущество интерактивных методов заключается в том, что они позволяют выполнять обновления во время выполнения. Было проведено очень мало исследований методов вставки для построения иерархий обнаружения столкновений.

Как отмечалось ранее, даже несмотря на то, что большая часть построения иерархии происходит на этапе предварительной обработки, все же важно найти быстрые методы построения. Любые алгоритмы сложности $O(n^2)$ и выше, вероятно, будут слишком медленными для построения иерархий из большего числа примитивов.

Чтобы упростить представление, в следующих разделах обсуждение в основном ограничивается двоичными деревьями. Те же методы обычно применяются к n-арным или даже общим деревьям.

### 6.2.1 Построение сверху вниз

Нисходящий метод можно описать в терминах рекурсивной процедуры. Он начинается с ограничения входного набора примитивов (или объектов) в ограничивающем объеме. Затем эти примитивы делятся на два подмножества. Теперь процедура вызывается рекурсивно, чтобы сформировать подиерархии для двух подмножеств, которые затем подключаются как дочерние к родительскому тому. Рекурсия останавливается, когда входной набор состоит из одного примитива (или, если он выбран, более раннего), и в этот момент процедура просто возвращается после создания ограничивающего объема для примитива. В следующем фрагменте кода показано, как можно реализовать построение сверху вниз.

```cpp
    // Построение дерева сверху вниз. Переставляет массив object[] во время построения
    void TopDownBVTree(Node **tree, Object object[ ], int numObjects)
    {
        assert(numObjects > 0);
        const int MIN_OBJECTS_PER_LEAF = 1;
        Node *pNode = new Node;
        *tree = pNode;
        // Compute a bounding volume for object[0], ..., object[numObjects - 1]
        pNode->BV = ComputeBoundingVolume(&object[0], numObjects);
        if (numObjects <= MIN_OBJECTS_PER_LEAF) {
            pNode->type = LEAF;
            pNode->numObjects = numObjects;
            pNode->object = &object[0]; // Pointer to first object in leaf
        } else {
            pNode->type = NODE;
            // Based on some partitioning strategy, arrange objects into
            // two partitions: object[0..k-1], and object[k..numObjects-1]
            int k = PartitionObjects(&object[0], numObjects);
            // Recursively construct left and right subtree from subarrays and
            // point the left and right fields of the current node at the subtrees
            TopDownBVTree(&(pNode->left), &object[0], k);
            TopDownBVTree(&(pNode->right), &object[k], numObjects - k);
        }
    }
```
Помимо выбора того, какой ограничивающий объем использовать, только один руководящий критерий контролирует структуру результирующего дерева: выбор того, как входной набор разделен на два подмножества. Поскольку набор из $n$ элементов может быть разбит на два непустых подмножества $2^{n−1} - 1$ способами, очевидно, что разумно рассматривать только небольшое подмножество всех разбиений.

Чтобы упростить разбиение, набор обычно делится на подмножества с помощью гиперплоскости разбиения. Поскольку невозможно гарантировать выбор плоскости разделения, которая не пересекает никакие примитивы, любые пересекающиеся примитивы должны учитываться при разделении набора. Одно из решений - разбить примитив на два, назначив части соответствующим подмножествам. Разделение примитивов позволяет уменьшить дочерние ограничивающие объемы, сводя к минимуму их перекрытие, возможно, полностью устраняя его. Недостаток разделенных примитивов состоит в том, что любые разделенные примитивы могут снова стать объектом разделения, что потенциально может привести к огромному увеличению сложности.

Возможно, более распространенное решение - не разделять примитив, а позволить положению его центроида по отношению к плоскости разделения определять, в какое подмножество он входит. Использование центроида для определения, какое подмножество назначить примитиву, для попыток минимизировать перекрытие между родственные ограничивающие объемы. Таким образом, ограничивающий объем будет увеличен по ширине на половину ширины примитива. Если бы примитив вместо этого был произвольно назначен любому подмножеству, в худшем случае ограничивающий объем для подмножества мог быть расширен на полную ширину примитива.

#### 6.2.1.1 Стратегии разбиения

Простой метод разбиения - это *алгоритм среднего отсечения*. Здесь набор разделен на две части равного размера относительно их проекции вдоль выбранной оси, в результате чего получается сбалансированное дерево. Срединное отсечение - лишь одна из возможных стратегий. Возвращаясь к списку желаемых свойств, приведенному ранее, можно указать другие возможные стратегии разделения:

- *Сведение к минимуму суммы объемов (или площадей) дочерних объемов*. Вероятность пересечения ограничивающего объема и любого из двух дочерних объемов может быть пропорциональна их объему. Таким образом, минимизация суммы объемов эффективно сводит к минимуму вероятность пересечения. Для запроса лучей вероятность попадания луча в ограничивающий объем вместо этого пропорциональна площади поверхности ограничивающего объема.
- *Сведение к минимуму максимального объема (площади поверхности) дочерних объемов*. В то время как предыдущая стратегия может привести к тому, что один объем будет намного больше другого, этот подход пытается сделать объемы более равными по размеру, делая больший объем как можно меньше. Это приводит к более сбалансированному запросу, улучшающему поведение в худшем случае.
- *Сведение к минимуму объема (площади поверхности) пересечения дочерних объемов*. Эта стратегия помогает снизить вероятность того, что оба дочерних элемента будут перекрыты и пересечены. В зависимости от используемого ограничивающего объема пересечение может быть сложно построить и даже приблизить.
- *Максимальное разделение дочерних объемов*. Разделение детей, даже если они не пересекаются, может еще больше снизить вероятность того, что оба попадут внутрь.
- *Разделение примитивов поровну между дочерними объёмами*. Эта стратегия представляет собой алгоритм среднего отсечения, упомянутый в начале раздела. Его сила заключается в предоставлении максимально сбалансированной иерархии.
- Комбинации предыдущих стратегий.

Разделение также может дать сбой раньше, до того, как сработает критерий остановки, например, когда:

- Все примитивы попадают на одну сторону плоскости разделения.
- Один или оба дочерних объёма содержат столько же (или почти столько же) примитивов, что и родительский объём.
- Оба дочерних объёма (почти) такие же большие, как и родительский.

Эти условия сбоя также можно рассматривать как критерии остановки. Однако, прежде чем остановиться, разумно попробовать другие критерии разделения. Например, для дерева из параллелипипедов, если не удалось разделить по самой длинной стороне, сначала можно проверить следующую самую длинную сторону, а затем самую короткую. Только в случае неудачи всех трех разделение остановится. Досрочная остановка с помощью $k$ вместо одного примитива на листовой узел имеет преимущество использования меньшего объема памяти. К сожалению, во время листовых тестов вместо одного примитивно-примитивного теста теперь должно выполняться $O(k^2)$ тестов.

Выбор плоскости разделения обычно разбивается на два этапа. Сначала выбирается ось, а затем положение вдоль этой оси. Эти варианты рассматриваются далее.

#### 6.2.1.2 Выбор оси разделения

Из бесконечного числа возможных осей нужно каким-то образом выбрать одну ось в качестве оси разделения. Теоретически можно применить метод итеративной оптимизации (например, восхождение на холм) для определения наилучшей оси. На практике такой подход обычно слишком дорог даже для этапа предварительной обработки. Следовательно, поиск должен быть ограничен небольшим количеством осей, из которых выбирается лучшая. Общие варианты осей для включения в этот ограниченный набор:

1. *Локальные оси координат x, y и z*. Обычно они включаются, поскольку с ними легко выполнять операции. Они также образуют ортогональный набор, который гарантированно охватывает самые разные направления.
2. *Оси из предполагаемого выровненного ограничивающего объема*. Локальные оси пункта 1 соответствуют нормальным граням AABB. Некоторые ограничивающие объемы, такие как k-DOP, имеют дополнительные фиксированные оси, которые также являются естественным выбором для разделения осей.
3. *Оси родительского ограничивающего объема*. Если иерархия построена из OBB, определяющие оси ограничивающего OBB текущего набора при разделении являются хорошими осями-кандидатами. Даже если иерархия построена, скажем, из сфер (которые не имеют очевидных связанных осей), временный OBB все равно может быть вычислен для родительского набора данных, из которого будут извлечены кандидаты на оси разделения.
4. *Оси через две самые дальние точки*. Разделение по оси, проходящей через две самые удаленные точки входного набора, соответствует попытке минимизировать объем дочерних объемов. Почти оптимальное приближение к наиболее удаленным точкам дается простой эвристикой $O(n)$, реализованной как функция **MostSeparatedPointsOnAABB()** в разделе 4.3.2.
5. *Ось наибольшей дисперсии*. Разделение по измерению, в котором входные данные имеют наибольший разброс, также служит для минимизации объема дочерних объемов. В иерархии OBB, в которой OBB подбираются ковариантно, ось наибольшей дисперсии просто соответствует оси, определяющей самую длинную сторону родительского OBB.

Несмотря на то, что полный шаг оптимизации невозможен, после выбора оси разделения можно выполнить небольшое количество шагов подъема для улучшения оси. Один из подходов включает в себя изменение направления оси, замену выбранной оси, если изменённая ось работает лучше, и повторение этого для максимально возможного количества шагов.

Интересным, но в значительной степени неизученным вариантом является применение других статистических методов, кроме анализа главных компонент, к проблеме поиска осей разделения. К ним относятся связанные методы проекционного преследования, анализ независимых компонент и слепое разделение сигналов, которые представляют собой методы для восстановления ненаблюдаемых отдельных компонентов из наблюдаемого смешанного источника. Например, метод прогнозирования в качестве упрощения можно описать как способ получения направления, для которого энтропия (а не дисперсия) прогнозируемых данных максимальна. Поскольку энтропия является мерой информации или «интересности», а кластеры данных будут иметь высокую энтропию, это направление образует хорошую ось кандидата для разделения данных на два или более кластера. Для введения в поиск проекций и независимый компонентный анализ смотрите [Stone98]. Для слепого разделения сигналов смотрите [Cardoso98].

#### 6.2.1.3 Выбор точки разделения

Невозможность оптимизации по всем возможным осям также относится и к выбору точки разделения. Поскольку вдоль оси бесконечно много точек разделения, выбор снова должен быть ограничен небольшим набором вариантов, например:

- *Медиана координат центроида (медиана объекта)*. Разделение на медиане объекта равномерно распределяет примитивы между подмножествами, в результате чего получается сбалансированное дерево. Медиана легко определяется за время $O(n \log n)$ путем сортировки точек или за время $O(n)$ с использованием более сложного метода (см [Cormen90]).
- *Среднее значение координат центроида (среднее значение объекта)*. Хорошо сбалансированные деревья не обязательно обеспечивают лучшее время запроса. Расщепление по локальной оси с наибольшей дисперсией, [Klosowski98] сообщают, что использование среднего значения объекта превосходит использование среднего значения объекта. Они сообщают, что разбиение на среднее значение последовательно дает меньшие деревья объёмов, с меньшим количеством выполняемых операций и, как следствие, более быстрым запросом. Среднее значение объекта находится за время $O(n)$.
- *Медиана протяженности проекции ограничивающего объема (пространственная медиана)*. Разделение по пространственной медиане (таким образом, разделение объема на две равные части) является привлекательным вариантом, поскольку точка разделения находится за постоянное время, исследуя только ограничивающий объем, а не содержащиеся в нем данные. Этот вариант часто используется, когда ось выбирается из родительского тома (например, с использованием правила самой длинной стороны).
- *Разделение в k равномерно расположенных точках по границам проекции ограничивающего объема*. Вместо того, чтобы тратить время на то, что сводится к «разумному угадыванию» хорошей позиции разделения, эта альтернатива грубой силы просто проверяет небольшое количество равномерно расположенных точек вдоль оси, выбирая лучшую.
- *Разделение (случайное подмножество) координат центроида*. Подобно предыдущему методу, разделение между проецируемыми центроидами пытается минимизировать количество примитивов, пересекающих плоскость разделения, за счет проецирования и сортировки центроидов.

**Рисунок 6.3** (a) Расщепление по медиане объекта. (b) Расщепление по среднему объекту. (c) Расщепление по пространственной медиане.

Рисунок 6.3 иллюстрирует некоторые из этих вариантов разделения. Вместо прямого выбора точки разделения подмножества можно строить постепенно. Например, [Zachmann98]
разделяется по оси через две наиболее удаленные точки, a и b. Начиная с добавления граней, связанных с a и b, к двум разным подмножествам, он назначает оставшиеся примитивы подмножеству, ограничивающий объем которого увеличивается меньше с добавлением примитива. Если оба объема увеличиваются на одинаковую величину или не увеличиваются вообще (из-за того, что примитив полностью находится внутри объема), примитив добавляется в набор с меньшим количеством примитивов.

Построение сверху вниз является наиболее распространенным подходом к построению иерархий ограничивающих объемов. К достоинствам можно отнести простоту реализации и быстрое построение дерева. Недостатком является то, что критические решения принимаются на ранней стадии алгоритма, когда вся информация недоступна, деревья обычно не настолько хороши, насколько это возможно.

### 6.2.2 Построение снизу вверх

В отличие от нисходящих методов, восходящие методы сложнее реализовать и имеют более медленное время построения, но обычно дают лучшие деревья [Omohundro89]. Чтобы построить древовидную иерархию снизу вверх, первым делом нужно заключить каждый примитив в ограничивающий объем. Эти объемы образуют листовые узлы дерева. Из полученного набора объемов выбираются два (или более) листовых узла на основе некоторого критерия слияния (также называемого правилом кластеризации). Затем эти узлы связываются в ограничивающем объеме, который заменяет исходные узлы в наборе. Эта процедура соединения повторяется до тех пор, пока набор не будет состоять из одного ограничивающего объема, представляющего корневой узел построенного дерева.

```cpp
    Node *BottomUpBVTree(Object object[], int numObjects){
        assert(numObjects != 0);
        int i, j;
        // Выделите временную память для хранения указателей узлов 
        // на текущий набор активных узлов (первоначально листья)
        NodePtr *pNodes = new NodePtr[numObjects];
        // Сформировать листовые узлы для заданных входных объектов
        for (i = 0; i < numObjects; i++) {
            pNodes[i] = new Node;
            pNodes[i]->type = LEAF;
            pNodes[i]->object = &object[i];
        }
        // Объединить пары вместе, пока не останется только корневой объект
        while (numObjects > 1) {
            // Найти индексы двух ближайших узлов на основе некоторого критерия
            FindNodesToMerge(&pNodes[0], numObjects, &i, &j);
            // Сгруппировать узлы i и j вместе в новый внутренний узел
            Node *pPair = new Node;
            pPair->type = NODE;
            pPair->left = pNodes[i];
            pPair->right = pNodes[j];
            // Вычислить ограничивающий объем для двух узлов
            pPair->BV = ComputeBoundingVolume(pNodes[i]->object, pNodes[j]->object);
            // Удалить два узла из активного набора и добавьть новый узел.
            // Сделано путем помещения нового узла в индекс 'min' и копирования последней записи в 'max'
            int min = i, max = j;
            if (i > j) min = j, max = i;
            pNodes[min] = pPair;
            pNodes[max] = pNodes[numObjects - 1];
            numObjects--;
        }
        // Освободить временное хранилище и возврат корня дерева
        Node *pRoot = pNodes[0];
        delete pNodes;
        return pRoot;
    }
```
Следуя логике предыдущих разделов, одним из наиболее значимых критериев слияния является выбор пары так, чтобы объем их ограничивающего объема был минимизирован. Подход грубой силы для определения того, какие два узла следует объединить, заключается в изучении всех возможных пар, вычислении их ограничивающего объема и выборе пары с наименьшим ограничивающим объемом. Подход грубой силы требует времени $O(n^2)$. Повторите n - 1 раз, чтобы сформировать полное дерево, общее время построения станет $O(n^3)$.

#### 6.2.2.1 Улучшенная конструкция снизу вверх

Более сложная реализация может существенно улучшить производительность метода грубой силы. Вместо того, чтобы постоянно пересчитывать предпочтительные пары минимального объема для каждого узла, узлы могут отслеживать свои предпочтительные узлы сопряжения и новый объем для пары. Тогда в любой момент времени узел с наименьшим сохраненным объемом и его сохраненный узел сопряжения будут лучшей парой узлов для слияния. Эти кортежи (*узел, узел сопряжения, объем*) могут эффективно поддерживаться в такой структуре данных, как приоритетная очередь (куча или двоичное дерево поиска), отсортированные по объему, что обеспечивает быстрый доступ к записи минимального объема.

Всякий раз, когда формируется новая пара, большинство сохраненных пар минимального объема остаются прежними. Затрагиваются только сохраненные пары, включающие один из двух вновь спаренных узлов. Что еще более важно, когда они меняются, сохраненный объем для пары может только увеличиваться. Это позволяет лениво пересчитывать узел сопряжения, задерживая вычисление до момента, когда пара будет извлечена из очереди приоритетов. По сути, алгоритм становится итерацией, в которой лучшая на данный момент пара удаляется из очереди. Если узел уже был спарен, пара просто отбрасывается и извлекается следующая лучшая пара. Если нет, вычисляется лучший узел сопряжения для узла. Если он соответствует сохраненному узлу сопряжения, эта пара должна быть парой с минимальным объемом, и их можно объединить. Если он не совпадает, значит, узел сопряжения должен был быть сопряжен на более раннем этапе, поэтому этот узел и новый узел сопряжения повторно вставляются в очередь приоритетов с новым значением приоритета объема.

Не хватает части, как быстро вычислить узел сопряжения, который образует наименьший объем при сопряжении с заданным узлом запроса. Интересно, что дерево динамического ограничивающего объема (в частности, алгоритм инкрементной вставки сверху вниз, представленный позже) является подходящей структурой данных для хранения восходящих фрагментов дерева в том виде, в каком оно построено! При такой структуре узел сопряжения находится путем поиска от вершины дерева, спускаясь ко всем дочерним элементам, с которыми пересекает объем запроса. Когда объем запроса найден в иерархии, узел сопряжения является другим дочерним элементом родительского тома (то есть одноуровневым узлом). Следующий фрагмент кода демонстрирует, как можно реализовать улучшенный алгоритм.

```cpp
Node *BottomUpBVTree(Object object[], int numObjects){
    PriorityQueue<Pair> q;
    InsertionBVTree t;
    // Связать все объекты в BV, образуя листовые узлы. Вставить листовые узлы 
    // в динамически изменяемое дерево BV, построенное с помощью вставки
    InitializeInsertionBVTree(t, object, numObjects);
    // Для всех узлов сформировать пару ссылок на узел и узел, с которым 
    // он лучше всего сочетается (в результате получается наименьший ограничивающий объем). 
    // Добавить все пары в приоритетную очередь, отсортированную по возрастанию объема
    InitializePriorityQueue(q, object, numObjects);
    while (SizeOf(q) > 1) {
        // Получить наименьшую пару объемов из очереди
        Pair *p = Dequeue(q);
        // Отбросить пару, если узел уже был сопряжен
        if (HasAlreadyBeenPaired(p->node)) continue;
        // Пересчитать лучший узел сопряжения для этого узла, 
        // чтобы проверить, действителен ли еще сохраненный узел пары
        Node *bestpairnode = ComputeBestPairingNodeUsingTree(t, p->node);
        if (p->pairnode == bestpairnode) {
            // Сохраненный узел пары в порядке, соединить два узла вместе;
            // связать узлы вместе под новым узлом
            Node *n = new Node;
            n->left = p->node;
            n->right = p->pairnode;
            // Добавить новый узел в дерево BV; удалить старые узлы, поскольку с ними невозможно установить пару
            Delete(t, p->node);
            Delete(t, p->pairnode);
            Insert(t, n);
            // Вычислить узел сопряжения для нового узла; вставить его в очередь
            Node *newbestpairnode = ComputeBestPairingNodeUsingTree(t, n);
            p = Pair(n, newbestpairnode);
        } else {
            // Узел лучшей пары изменился с момента вставки пары;
            // обновить пару, снова вставить в очередь и попробовать еще раз
            p = Pair(p->node, bestpairnode);
        }
    Enqueue(q, p, VolumeOfBVForPairedNodes(p));
    // Очередь, пара, приоритет
    }
    return Dequeue(q)->node;
}
```
Похожий подход, особенно для построения сферических деревьев, представлен в [Omohundro89].

#### 6.2.2.2 Другие стратегии строительства снизу вверх

При группировке двух объектов под общим узлом пара объектов, дающая наименьший ограничивающий объем, скорее всего, соответствует паре ближайших друг к другу объектов. По существу, критерий слияния часто упрощается до объединения запрашивающего узла с его ближайшим соседом.

Поиск точки (или объекта) из набора точек, ближайших к заданной точке запроса, называется проблемой ближайшего соседа. Эта проблема хорошо изучена, и было предложено множество различных подходов. Для небольшого количества объектов предпочтительнее решение с низким уровнем накладных расходов. Для больших чисел обычно наиболее практичными являются решения, основанные на схемах сегментирования или деревьях k-d. Решение k-d дерева довольно просто реализовать (подробности см. В Разделе 7.3.7). Дерево может быть построено сверху вниз в среднем за время $O(n \log n)$, например, путем разделения текущего набора объектов пополам по медиане объекта.

Запрос ближайшего соседа ограничивается соответствующими частями k-d дерева путем отслеживания границы для ближайшего объекта, найденного на данный момент (см. Раздел 7.3.7). Первоначально это значение устанавливается как расстояние от объекта запроса до объекта корневого узла. По мере нахождения более близких объектов граница соответственно уменьшается. Полупространства дальше, чем граничное расстояние, отсекаются, поскольку они не могут содержать более близкий объект. Когда нельзя отбросить ни одно полупространство, полупространство, содержащее объект запроса, обычно спускается в первое, так как это с большей вероятностью приведет к снижению границы и ускорению поиска.

Проблема k-ближайшего соседа может быть решена с помощью того же базового метода, просто добавив приоритетную очередь из k объектов, которая отслеживает k-ближайшие объекты, видимые до сих пор, обновляя граничное расстояние от последнего (самого дальнего) элемента очереди. В среднем, как поиск, так и вставка в дерево k-d могут быть выполнены за время $O(\log n)$. k-d деревья обсуждаются далее в главах 7 и 13.

С помощью методов, представленных ранее, не было сделано никаких гарантий в отношении баланса дерева, и на самом деле легко найти входные конфигурации, которые вызывают вырожденные деревья. Баланс дерева можно улучшить, формируя не одну, а несколько пар ближайших точек на каждой итерации. Например, когда на каждой итерации формируются все возможные $n/2$ пары, результирующее дерево становится сбалансированным. Это также уменьшит количество итераций, необходимых для формирования дерева с $O(n)$ до $O(\log n)$, сокращая сроки строительства. Поскольку формирование всех возможных пар приведет к худшему дереву по сравнению с формированием одной пары, хорошим компромиссом является формирование k пар для некоторого небольшого значения k.

Для формирования более крупных кластеров объектов можно использовать определенные алгоритмы кластеризации. Один из таких подходов состоит в том, чтобы рассматривать объекты как вершины полного графа и вычислять минимальное охватывающее дерево (minimum spanning tree, MST) для графа с весами ребер, установленными на расстоянии между двумя соединенными объектами или какой-либо подобной мерой кластеризации. Затем MST разбивается на компоненты путем удаления «слишком длинных» ребер, а оставшийся набор непересекающихся (но внутренне связанных) компонентов представляет собой кластеры объектов.

MST можно вычислить, используя, например, алгоритм Прима или алгоритм Крускала. Оба эти алгоритма являются жадными, что означает, что они всегда выбирают для выполнения локально наиболее подходящую альтернативу. Жадные алгоритмы часто неплохо справляются с большинством проблем, но, как правило, они не оптимальны. Однако проблема MST оптимально решается одним из этих двух методов. Из этих двух алгоритм Прима, вероятно, концептуально проще и проще в реализации. Он начинается с любой вершины из начального набора и вырастает из него дерево, находя ребро с наименьшей стоимостью между несвязанной вершиной и деревом. Затем это ребро и вершина соединяются с деревом, и процесс повторяется до тех пор, пока не будут соединены все вершины. Дополнительные сведения о вычислении MST, включая описание алгоритмов Прима и Крускала, см [Cormen90] и восхитительная книга [Skiena98].

#### 6.2.2.3 Снизу вверх n-арные деревья кластеризации

Одним из интересных методов, использующих расчет MST в качестве ключевого шага, является метод восходящей кластеризации, представленный в [Garcia99]. Учитывая набор из n ограничивающих сфер, этот метод начинается с построения графа смежности между сферами. Ребра этого графа содержат групповые затраты (описанные в следующем материале) между парами сфер. Из графа вычисляется MST, из которого, в свою очередь, строится иерархия сфер.

Поскольку количество ребер в полном графе смежности равно $O(n^2)$, что сильно повлияет на время работы алгоритма MST, Гарсия и др. ограничивают количество соединений, которые может иметь каждый ограниченный объект, до некоторого постоянного числа k, уменьшив сложность до $O(n)$. Используя подходящую стратегию разделения пространства, сокращение может быть ограничено примерно k-ближайшими соседями и по-прежнему выполняться за $O(n)$ времени.

С остальными ребрами связана функция кластеризации. Для двух сфер $S_i$ и $S_j$ - с радиусами $r_i$ и $r_j$ соответственно и с расстоянием $d_{ij}$ между их центрами - Гарсиа и др. сначала определяют притяжение между $S_i$ и $S_j$ как $a_{ij}=r_i r_j/d_{ij}^2$.
Эта мера притяжения становится больше, чем больше и ближе две сферы, имитируя интуитивное восприятие того, как будут формироваться кластеры. Чтобы избежать создания больших кластеров на ранних этапах процесса сборки, окончательная функция кластеризации определяется как $r_{ij}^3/a_{ij}$ , где $r_{ij}$ - радиус наименьшей ограничивающей сферы, охватывающей $S_i$ и $S_j$. Это помогает в наказании за группировку двух сфер с высоким притяжением, когда их результирующая ограничивающая сфера будет очень большой.

После того, как граф смежности с соответствующими стоимостями ребер сформирован, вычисляется MST графа. Затем ребра MST сортируются в порядке возрастания стоимости. Из отсортированных ребер они создают то, что они называют двоичным деревом кластеризации (binary clustering tree, BCT), рассматривая ребро за раз, объединяя два узла, связанных с ребром, в новый кластер. Если узел уже является частью кластера, существующий кластер группируется в новый кластер вместо узла. По мере формирования кластеров они ограничиваются наименьшей ограничивающей сферой, содержащей ограничивающие сферы узлов. Им также назначается стоимость соединительного ребра как стоимость группировки. Построение BCT из MST занимает время $O(n \log n)$.

На этом этапе можно было бы остановиться и использовать получившееся двоичное дерево. Однако, как описано, последний шаг алгоритма преобразует BCT в n-арное дерево путем слияния подключенных кластеров, которые имеют схожие затраты на группировку в одном узле. После расчета MST и сортировки ребер в список в порядке возрастания веса веса группируются в набор семейств. Первые два веса в этом списке образуют первое семейство $F_0$. Определяя $u_i$ и $s_i$ как среднее и стандартное отклонение весов в семействе $F_i$, последующий вес $w$ в списке считается принадлежащим семейству $F_i$ if $w < u_i + 2s_i$ . Каждый раз, когда вес добавляется к семейству, соответствующие среднее значение и стандартное отклонение семейства обновляются. Когда выясняется, что вес не принадлежит семье, он и следующий вес в списке образуют новое семейство. Этот процесс повторяется до тех пор, пока все веса в списке не будут присвоены семье. Наконец, когда все семейства определены, BCT преобразуется в n-арное дерево путем слияния всех смежных кластеров, принадлежащих к одному семейству.

### 6.2.3 Инкрементальная (вставная) конструкция

Последний тип подхода к построению - это метод инкремента или вставки. Здесь дерево строится путем вставки одного объекта за раз, начиная с пустого дерева. Объекты вставляются путем нахождения места вставки в дереве, при котором дерево растет как можно меньше в соответствии с метрикой стоимости. Обычно стоимость, связанная с вставкой объекта в заданную позицию, принимается равной стоимости его ограничивающего объема плюс увеличение объема, вызываемого его вставкой во всех предшествующих объемах над ним в дереве.

Если вставляемый объект велик по сравнению с существующими узлами, он, как правило, окажется в верхней части иерархии. Более мелкие объекты с большей вероятностью будут находиться в пределах существующих ограничивающих объемов и вместо этого окажутся внизу. Когда новый объект находится далеко от существующих, он также окажется наверху. В целом, результирующее дерево будет отражать фактическую кластеризацию в исходном наборе объектов.

Поскольку структура дерева зависит от объектов, вставленных в него, и поскольку решения о вставке принимаются на основе текущей структуры, следует, что порядок, в котором вставляются объекты, имеет значение. Использование объектов в порядке, определенном средством разработки, может привести к плохим иерархиям, которые не отражают фактическую кластеризацию объектов. Сортировка данных страдает той же проблемой, только в большей степени. Чтобы избежать вырожденного поведения, лучший подход - это случайное перемешивание объектов перед вставкой.

Простая реализация метода вставки будет заключаться в выполнении одного обхода корневого листа путем последовательного спуска дочернего элемента, для которого вставка будет дешевле. Затем узел вставки будет выбран из посещенных узлов вдоль трассируемого пути, так что общий объем дерева будет минимизирован. Поскольку для каждого вставленного объекта выполняется поиск $O (\log n)$, общая сложность становится $O (n \log n)$. Более продвинутая реализация будет исследовать все дерево, действуя по принципу «лучший - первый», поддерживая фронт поиска с использованием очереди приоритетов, всегда спускаясь к лучшему на данный момент узлу. Оба метода описаны в [Omohundro89] с точки зрения создания сферических деревьев.

Стратегии вставки могут быть такими же быстрыми или даже быстрее, чем методы сверху вниз, и могут дать лучшие результаты. Они считаются интерактивными методами в том смысле, что не все объекты должны присутствовать при запуске процесса. То, что это интерактивные методы, также позволяет использовать их для обновления уже существующего дерева, что делает их полезными для динамических систем. Поэтому несколько удивительно, что очень немногие системы обнаружения столкновений сообщают об использовании дополнительных методов построения.

#### 6.2.3.1 Метод инкрементной конструкции Goldsmith–Salmon

Интересный алгоритм построения иерархий ограничивающих объемов для использования в трассировке лучей описан в [Goldsmith87] с улучшениями, найденными в [Haines88]. Как и раньше, объекты вставляются по одному в наиболее оптимальном месте. Единственный путь от корня к листу проходит, спускаясь в дочерний элемент с наименьшим увеличением площади поверхности ограничивающего объема, если объект должен быть вставлен как его дочерний элемент.

Причина, по которой используется площадь поверхности, следует из результата проективной геометрии, утверждающего, что средняя площадь проекции выпуклого трехмерного объема составляет одну четверть его площади поверхности. Кроме того, можно показать, что условная вероятность того, что случайный луч попадет в заключенный ограничивающий объем B, если он попадет в родительский ограничивающий объем A, пропорциональна отношению площадей их поверхностей. Корневой объем можно удобно использовать в качестве объема А во всех вычислениях, что позволяет избежать деления путем прямого сравнения условных вероятностей.

Поскольку площади поверхности используются только в соотношениях, их нужно указывать только с постоянным коэффициентом, так как постоянный коэффициент компенсирует. Для ограничивающего параллелипипеда размеров $x$, $y$ и $z$ площадь может быть вычислена как $x(y + z) + yz$, а для сферы радиуса $r$ площадь может быть вычислена как $r^2$.

Теперь, когда луч попадает в корневой объем, необходимо выполнить по крайней мере дополнительные k тестов на пересечение, где k - количество потомков корня. Это свойство также сохраняется для любого узла, а не только для корня. С учетом условной вероятности попадания в узел только в случае попадания в его родительский узел общая средняя стоимость попадания в узел становится в k раз больше площади поверхности узла, деленной на площадь поверхности корневого узла. В частности, стоимость корневого узла - это количество дочерних узлов, которые у него есть, а стоимость конечного узла равна нулю (поскольку его стоимость была включена в стоимость родительского узла). Общая стоимость дерева теперь может быть рассчитана за время $O(n)$ как сумма стоимости всех узлов.

Стоимость дерева также может быть вычислена постепенно, по мере построения дерева. Это реализуется путем передачи возрастающей «стоимости наследования» дочерним узлам по мере прохождения иерархии во время вставки. Эта стоимость соответствует увеличению объема родительских объемов из-за вставки объекта в дерево. К этому затем добавляется стоимость вставки объекта в текущее положение в соответствии с тремя различными вариантами вставки:

1. *Объект и листовой узел объединяются в новый узел*. Дополнительное изменение стоимости наследования для этого случая составляет  $d = 2Площади(\text{новый узел})$. Этот случай также применяется при объединении объекта и старого корня в новый корень.
2. Объект добавляется как новый дочерний элемент к существующему узлу. Стоимость существующего старого узла составляет $c = k Площадей(\text{старый узел})$. Новый узел будет стоить $c' = (k + 1)Площадей(\text{новый узел})$. Таким образом, дополнительная стоимость $d = c' − c = k (Площадь(\text{новый узел}) − Площадь(\text{старый узел})) + Площадь(\text{новый узел})$.
3. Объект добавляется ниже в дереве посредством рекурсии в дочерний объём. В этом случае количество дочерних элементов остается неизменным для текущего исследуемого узла. Однако узел может измениться в размере в результате вставки объекта ниже в дереве. Разница в стоимости станет $d = k (Площадь(\text{новый узел} − Площадь(\text{старый узел}))$.

После изучения увеличения стоимости для всех доступных вариантов вставки на каждом этапе выбирается самый дешевый вариант. Может случиться так, что два или более поддерева имеют одинаковое увеличение стоимости. Как правило, это происходит ближе к концу строительства, когда объекты полностью лежат в уже существующих ограничивающих объемах. В этом случае Голдсмит и Сэлмон предлагают разорвать связи, вставив объект в ограничивающий объем, к центру которого он ближе всего, или использовать случайный выбор.

Хейнс указывает, что лучшим правилом выбора является применение методов вставки 1 и 2 ко всем доступным альтернативам вставки и выбор того, который дает лучший результат. В качестве убедительного примера он рассматривает узел с двумя дочерними узлами, одним большим (50% от родительского) и одним довольно маленьким (1% от родительского). Добавлен новый маленький объект, который не вызовет увеличения для большего дочернего элемента, но утроит размер меньшего дочернего элемента до 3%. Согласно исходному методу, новый объект будет вставлен под более крупным дочерним элементом. Однако, когда корневой узел пересекается, более крупный дочерний элемент попадает в 50% случаев, и, следовательно, новый объект также должен пересекаться в половине случаев. Для сравнения, если бы новый объект был вставлен ниже меньшего дочернего объекта, новый объект проверялся бы на пересечение только в 3% случаев. Применяя оба метода 1 и 2 и выбирая узел, соответствующий меньшему значению различного увеличения стоимости, выбирается лучшая позиция вставки.

## 6.3 Обход иерархии

Чтобы определить статус перекрытия двух иерархий ограничивающих объёмов, необходимо установить какое-то правило, определяющее, как спускаться по деревьям, когда их объёмы верхнего уровня перекрываются. Является ли одна иерархия полностью спущенной раньше, чем другая? Они обе пройдены? Это правило спуска лежит в основе кода перекрытия, и в будущем мы рассмотрим несколько альтернатив.

Двумя наиболее фундаментальными методами обхода дерева являются поиск в ширину и поиск в глубину (рисунок 6.4a и b). *Поиск в ширину* (breadth-first search, BFS) исследует узлы на заданной глубине перед тем, как перейти глубже в дерево, тогда как *Поиск в глубину* (depth-first search, DFS) переходит в дерево, ища глубже, а не шире, возвращаясь вверх по дереву, когда оно достигает листьев. Чистый обход в ширину и в глубину считается методами *неинформированного или слепого поиска*. Методы неинформированного поиска не исследуют и не принимают решения об обходе на основе данных, содержащихся в пройденной структуре; они смотрят только на саму структуру, чтобы определить, какие узлы посетить дальше.

**Рисунок 6.4** (a) Поиск в ширину, (b) поиск в глубину и (c) один из возможных порядков поиска «лучший первый».


В отличие от неосведомленных методов - это группа методов *информированного поиска*. Они пытаются использовать известную информацию об исследуемом домене с помощью эвристических правил. Один из таких методов - *поиск лучшего первого* (рисунок 6.4c). Поиск по первому наименованию - это жадный алгоритм, который всегда перемещается к узлу, который имеет наилучшие результаты по некоторому критерию поиска (например, расстояние до установленной цели). Он определяет наиболее результативный ход, поддерживая приоритетную очередь узлов, расширяя лучший на данный момент узел (первый в очереди) и добавляя его дочерние элементы в очередь, повторяя до тех пор, пока поиск не завершится неудачно (из-за исчерпания узлов) или до достижения найденной цели.

DFS кажется наиболее популярным выбором для систем обнаружения столкновений. DFS часто дополняется простой эвристикой для направления поиска, улучшая базовый слепой подход DFS без накладных расходов, например, на полный поиск лучшего первого. По сравнению с DFS, BFS страдает тем фактом, что для объединения всех узлов во время обхода требуется значительный объем памяти. Для запросов непосредственной близости два двоичных дерева с $n$ листами каждое могут потребовать пространства стека для $n^2$ пар узел-узел одновременно. BFS в основном используется в прерываемых системах обнаружения столкновений, для которых важно, чтобы, если (или когда) запрос был прерван, примерно равное количество времени было потрачено во всех частях иерархии.

Точно так же BFS должна быть хорошо настроена для повышения производительности по сравнению с методом обхода на основе DFS с эвристическим управлением. Любое дополнительное время, потраченное на выполнение умного переупорядочения узлов и управление очередью с приоритетами, - это время, когда метод в глубину уже спустился в дочерние узлы.

### 6.3.1 Правила спуска

Вернемся к вопросу о том, как спускаться по иерархиям. Даны две иерархии A и B, есть несколько возможных альтернатив обхода. Например, одну можно пройти полностью раньше другой, или они могут спуститься одновременно. В качестве наглядного примера (из [Chung98]), представьте себе птицу (иерархия A), летящую по трубам нефтеперерабатывающего завода длиной в милю (иерархия B). Представляется несколько возможных правил спуска по иерархиям.

- *Спускаться по A перед спуском B*. Полностью опуститься в листья A перед тем, как начать спускаться в B, может быть довольно плохо. В терминах примера, если птица находится где-то в середине нефтеперерабатывающего завода, все листья иерархии птиц будут перекрывать верхний объем нефтеперерабатывающего завода. Это правило спуска - наихудший из возможных вариантов, поскольку иерархия B будет повторяться столько раз, сколько листьев в иерархии A. Иерархия для A здесь явно контрпродуктивна, в результате требуется больше работы, чем отсутствие иерархии вообще!
- *Спускаться по B перед спуском по A*. Немного лучше спускаться по более крупной иерархии нефтеперерабатывающих заводов перед тем, как спускаться по иерархии птицы. Тем не менее, модель нефтеперерабатывающего завода все еще может содержать множество деталей (таких как гайки и болты), которые немного меньше, чем птица, что приводит к аналогичной ситуации, как и раньше, только в обратном порядке. Многие листья B все еще проходят испытания против всего A.
- *Спускаться по большему объему*. Путем динамического определения, какая иерархия в настоящее время является большей и спуска в нее, можно обойти проблемы с двумя предыдущими методами. Первоначально иерархия нефтеперерабатывающего завода спускается вниз, но когда встречаются маленькие части гаек и болтов, переход переключается на спуск по иерархии птиц, а затем снова возвращается, когда части птицы становятся меньше гаек и болтов. Это одно из наиболее эффективных правил спуска, поскольку оно обеспечивает максимальное уменьшение общего объема для последующих тестов ограничивающего объема. Как и раньше, полезные показатели для сравнения размеров включают объем, площадь поверхности и максимальную длину измерения.
- *Спускаться по A и B одновременно*. Вместо того, чтобы просто спускаться по одной иерархии, иерархии можно спускаться одновременно по обеим. Преимущество одновременного спуска заключается в более быстром переходе к листьям, меньшем количестве тестов на перекрытие внутренних узлов (а также узлов и листьев) и отсутствии накладных расходов на оценку критерия спуска. Однако в примере с птицефабрикой это правило не сокращает пространство поиска так же эффективно, как предыдущее правило.
- *Поочередно спускаться по A и B*. Иерархии также могут быть спущены по ступенчатой схеме, при которой сначала спускается A, затем B, затем снова A и так далее. Это правило спуска очень просто реализовать, и так же, как и при одновременном обходе, не нужно оценивать критерий спуска.
- *Спускаться с перекрытием*. Другой вариант - установить приоритет спуска к тем частям, в которых иерархии перекрываются больше, перед нисходящими частями, в которых перекрытие меньше. Идея состоит в том, что чем больше перекрываются два ограничивающих объема, тем больше вероятность столкновения их объектов.
- *Комбинации предыдущих или других сложных правил на основе истории обхода*.

Какой тип обхода наиболее эффективен, полностью зависит от структуры данных, как показано в примере с нефтеперерабатывающим заводом. В следующих разделах исследуются реализации фреймворка для этих правил на основе обхода в глубину. Для очень больших наборов данных гибридные подходы, такие как сетка деревьев, вероятно, будут более эффективными, чем иерархия одного дерева. Гибридные подходы обсуждаются в разделе 7.3.8.

### 6.3.2 Общий информированный обход в глубину

Многие правила спуска могут быть обработаны простой процедурой, которая повторяется по двум иерархиям. Во-первых, если их верхние ограничивающие объемы не перекрываются, процедура просто возвращается. Если нет, то если оба предоставленных узла являются листовыми узлами, вызывается процедура низкого уровня для столкновения содержащейся геометрии. В противном случае оценивается правило спуска и рекурсивно вызывается код для дочерних узлов иерархии, выбранной правилом для спуска. При прямом переводе в код это становится: (1. Спасибо за вдохновление в используемом здесь коде [Gottschalk00].)

```cpp
// Общий рекурсивный код обхода BVH.
// Предполагает, что у листьев тоже есть BV
void BVHCollision(CollisionResult *r, BVTree a, BVTree b){
    if (!BVOverlap(a, b)) return;
    if (IsLeaf(a) && IsLeaf(b)) {
        // На листовых узлах. Выполнить тесты на столкновение с содержимым листового узла
        CollidePrimitives(r, a, b);
    } else {
        if (DescendA(a, b)) {
            BVHCollision(a->left, b);
            BVHCollision(a->right, b);
        } else {
            BVHCollision(a, b->left);
            BVHCollision(a, b->right);
        }
    }
}
```
В коде функция **BVOverlap()** определяет перекрытие между двумя ограничивающими объемами. **IsLeaf()** возвращает истину, если его аргумент является листовым, а не внутренним узлом. **CollidePrimitives()** сталкивает все содержащиеся примитивы друг с другом, накапливая все зарегистрированные конфликты в предоставленной структуре **CollisionResult**.

**DescendA()** реализует правило спуска и возвращает истину, если иерархия объектов A должна происходить по наследству, или ложь для иерархии объектов B. Важно, чтобы эта подпрограмма правильно обрабатывала случаи, в которых были достигнуты листья A и B, чтобы не было попыток пересечения в лист. Правила спуска «спуск A», «спуск B» и «спуск выше» могут быть легко реализованы в этой структуре следующим образом.

```cpp
    // Правило спуска «Спуск по А»
    bool DescendA(BVTree a, BVTree b){
        return !IsLeaf(a);
    }
    // Правило спуска «Спуск по Б»
    bool DescendA(BVTree a, BVTree b){
        return IsLeaf(b);
    }
    // Правило спуска «Спуск по большему»
    bool DescendA(BVTree a, BVTree b){
        return IsLeaf(b) || (!IsLeaf(a) && (SizeOfBV(a) >= SizeOfBV(b)));
    }
```
Хотя рекурсивная версия кода обхода довольно проста для чтения и понимания, это не самая эффективная форма кода. Итерационная версия с явным стеком переменных позволяет избежать накладных расходов на рекурсивные вызовы функций. Что еще более важно, это позволяет коду завершиться раньше, если ищется только одна точка контакта. Итерационная версия приводится ниже. Обратите внимание, что для обхода дерева в том же порядке, что и в рекурсивной версии кода, занесения в стек должны выполняться в обратном порядке.

```cpp
// Нерекурсивная версия
void BVHCollision(CollisionResult *r, BVTree a, BVTree b){
    Stack s = NULL;
    Push(s, a, b);
    while (!IsEmpty(s)) {
        Pop(s, a, b);
        if (!BVOverlap(a, b)) continue;
        if (IsLeaf(a) && IsLeaf(b)) {
            // At leaf nodes. Perform collision tests on leaf node contents
            CollidePrimitives(r, a, b);
            // Здесь может быть правило выхода (например, выход при первом попадании)
        } else {
            if (DescendA(a, b)) {
                Push(s, a->right, b);
                Push(s, a->left, b);
            } else {
                Push(s, a, b->right);
                Push(s, a, b->left);
            }
        }
    }
}
```

Здесь функции **Push()**, **Pop()**, и **IsEmpty()** реализуют абстрактный тип данных стека. Изучая поток нерекурсивной версии, вскоре становится ясно, что выполняется ненужная работа по помещению новой пары узлов в стек только для того, чтобы она была немедленно удалена во время следующей итерации основного цикла. Избыточной работы можно избежать, слегка изменив код, чтобы позволить последним сложенным значениям назначать непосредственно переменным.

```cpp
// Оптимизированная для стека, нерекурсивная версия
void BVHCollision(CollisionResult *r, BVTree a, BVTree b){
    Stack s = NULL;
    while (1) {
        if (BVOverlap(a, b)) {
            if (IsLeaf(a) && IsLeaf(b)) {
                // На листовых узлах. Выполнить тесты на столкновение с содержимым листового узла
                CollidePrimitives(r, a, b);
                // Здесь может быть правило выхода (например, выход при первом попадании)
            } else {
                if (DescendA(a, b)) {
                    Push(s, a->right, b);
                    a = a->left;
                    continue;
                } else {
                    Push(s, a, b->right);
                    b = b->left;
                    continue;
                }
            }
        }
        if (IsEmpty(s)) break;
        Pop(s, a, b);
    }
}
```
Все рекурсивные функции обхода могут быть преобразованы в итерационные версии описанным здесь способом.

### 6.3.3 Одновременный обход в глубину

Одновременный обход не может быть напрямую обработан предыдущей структурой. Поскольку оба ограничивающих объема спускаются в одно и то же время, вместо двух рекурсивных вызовов теперь четыре для случая узел-узел. Код для одновременного обхода следующий.

```cpp
// Рекурсивный, одновременный обход
void BVHCollision(CollisionResult *r, BVTree a, BVTree b){
    if (!BVOverlap(a, b)) return;
    if (IsLeaf(a)) {
        if (IsLeaf(b)) {
            // На листовых узлах. Выполнить тесты на столкновение с содержимым листового узла
            CollidePrimitives(r, a, b);
            // Could have an exit rule here (eg. exit on first hit)
        } else {
            BVHCollision(a, b->left);
            BVHCollision(a, b->right);
        }
    } else {
        if (IsLeaf(b)) {
            BVHCollision(a->left, b);
            BVHCollision(a->right, b);
        } else {
            BVHCollision(a->left, b->left);
            BVHCollision(a->left, b->right);
            BVHCollision(a->right, b->left);
            BVHCollision(a->right, b->right);
        }
    }
}
```
Интересно сравнить количество операций, задействованных в различных типах обходов. Поскольку предыдущие методы потребовали бы двух дополнительных рекурсивных вызовов для проверки тех же четырех пар узел-узел, в которые спускается одновременный обход, можно ожидать, что одновременный обход потребует около двух третей работы направленных методов (что строго верно только в случае посещения всех узлов).

В частности, рассмотрим наихудший сценарий, в котором два полных бинарных дерева из n уровней каждое находятся в относительном положении, так что все ограничивающие объемные листья перекрываются, но нет столкновения. В этом случае можно показать, что одновременный обход будет выполнять $(2^{2(n−1)} - 1)/3$ внутренних тестов узел-узел и $2^{2(n−1)}$ лист-узел, узел-лист и лист-узел. листовые тесты, всего $(2^{2n} - 1)/3$ теста.

Для сравнения, правила «спуска A» и «спуска B», ориентированные на листья, выполняют $2^{n−1} - 1$ внутренних тестов узел-узел и $(2^n - 1) 2^{n−1}$ листовой узел, узел-лист и лист. -листов всего $2^{2n−1} - 1$ теста. Предел, когда $n$ становится большим между этими двумя суммами, подтверждает соотношение двух третей, неофициально заявленное ранее.

Сложнее предоставить какие-либо конкретные числа для метода информированного обхода, так как шаблон обхода полностью зависит от используемого правила спуска. Одно можно сказать наверняка: общее количество выполненных тестов будет таким же, как и для листовых обходов, поскольку код имеет ту же структуру и сформированы все возможные пути обхода. Трудно сказать, спасет ли использование одновременного обхода что-либо по сравнению с использованием направленного метода, такого как «спуститься выше», который выполняет более эффективный поиск, направляя его туда, где он лучше всего необходим


### 6.3.4 Оптимизированный переход по листу в глубину

Недостатком одновременных и эвристически управляемых методов является то, что тесты на столкновения с участием одних и тех же листьев, вероятно, будут растянуты во времени. Если эти тесты включают в себя какое-либо преобразование данных листа или ограничивающих его объемов (что вполне вероятно), эти преобразования должны повторяться каждый раз, когда лист участвует в запросе. Если эти преобразования являются дорогостоящими, можно реализовать механизм кэширования для хранения данных после их первоначального преобразования.

Компромиссной альтернативой реализации сложной схемы кэширования является правило «по убыванию». Переходя вниз к листьям иерархии A до того, как иерархия B спустится, становится очень легко преобразовать листья A только один раз. Этот компромисс не служит полной заменой механизма кэширования, поскольку таким образом эффективно кэшируется только A-иерархия. Однако, поскольку это настолько просто в реализации, он может служить индикатором того, насколько улучшится схема кэширования. Далее следует фрагмент кода.

```cpp
// Эта процедура повторяется по первой иерархии, по ее листьям.
// Листья трансформируются один раз, а затем передаются 
// вместе со второй иерархией в процедуру поддержки
void BVHCollision(CollisionResult *r, BVTree a, BVTree b){
    if (!BVOverlap(a, b)) return;
    if (!IsLeaf(a)) {
        BVHCollision(a->left, b);
        BVHCollision(a->right, b);
    } else {
        a2 = TransformLeafContentsOnce(a);
        BVHCollision2(r, a2, b);
    }
}
// Подпрограмма поддержки берет то, что известно как лист, и полную иерархию, 
// рекурсивно просматривая иерархию, выполняя низкоуровневые тесты на столкновение 
// лист-лист после достижения конечных точек иерархии
void BVHCollision2(CollisionResult *r, BVTree a, BVTree b){
    if (!BVOverlap(a, b)) return;
    if (!IsLeaf(b)) {
        BVHCollision2(a, b->left);
        BVHCollision2(a, b->right);
    } else {
        // At leaf nodes. Perform collision tests on leaf node contents
        CollidePrimitives(r, a, b);
    }
}
```

## 6.4 Пример иерархии ограничивающих объемов

Все методы построения иерархии, описанные ранее в этой главе, являются общими в том смысле, что они применимы к любому типу ограничивающего объема. Чтобы дополнительно проиллюстрировать, как их можно использовать, в этом разделе подробно рассматриваются несколько конкретных методов, предложенных в литературе и используемых в реальных системах. Их не следует интерпретировать как последнее слово по поводу какой-либо одной техники, просто как один из способов реализации чего-либо.

### 6.4.1 OBB Деревья

Метод построения иерархии OBB-дерева, представленный в [Gottschalk96], осуществляется сверху вниз. Изначально получается плотно прилегающий OBB для исходного набора примитивов. OBB настраивается путем выравнивания осей параллелипипеда с собственными векторами, вычисленными из непрерывной формулировки ковариации, вычисленной для всех граней примитивов, как описано в разделе 4.4.3. Задав параллелипипед, набор разделяется путем разделения по самой длинной оси OBB. Благодаря ковариационной подгонке OBB эта ось соответствует оси наибольшего разброса. Среднее значение объекта (вычисленное из проекции вершин примитива на ось) используется в качестве точки разделения.

Примитивы, пересекающие плоскость разделения, назначаются соответствующему подмножеству полупространства, в котором находятся их центроиды. Если по самой длинной оси не удается создать два непустых подмножества, они вместо этого пробуют другие оси в порядке убывания длины. Если все оси выходят из строя, набор считается неделимым. Однако в общедоступной реализации (называемой RAPID), если начальное разбиение не удается, вместо попытки альтернативных осей набор просто разбивается на две равные части на основе медианы объекта.

Сильная сторона деревьев OBB состоит в том, что они очень хорошо работают в ситуациях параллельной непосредственной близости между двумя поверхностями; то есть, когда все точки первой поверхности близки к какой-то точке на другой поверхности. Также можно показать, что иерархии OBB сходятся квадратично, чтобы соответствовать ограничивающей геометрии, тогда как AABB и сферы сходятся только линейно. Другими словами, если $O(m)$ OBB требуются для аппроксимации некоторой геометрии в пределах заданного допуска, $O(m^2)$ AABB или сферы потребуются для той же задачи. И $N_V$, и $N_P$ в функции стоимости имеют тенденцию быть меньше для деревьев OBB по сравнению с AABB и сферическими деревьями. Однако стоимость теста на перекрытие между двумя OBB, $C_V$, по-прежнему примерно на порядок ниже, чем стоимость теста на перекрытие для AABB и сфер.

### 6.4.2 Деревья AABB и BoxTrees

В [Bergen97] автор описывает построение бинарных деревьев AABB с использованием рекурсивного деления сверху вниз. На каждом шаге набор примитивов жестко ограничен AABB. Затем набор делится на две части путем ортогонального разделения AABB вдоль его самой длинной стороны. Примитивы назначаются двум подмножествам в зависимости от того, на какой стороне плоскости разделения заканчивается средняя точка проекции. Этот метод присваивания минимизирует перекрытие между AABB подмножеств, так как ни один примитив не может выходить за пределы плоскости разделения более чем на половину ее длины.

Затем процедура рекурсивного построения повторяется до тех пор, пока подмножество не будет содержать один примитив. Точка расщепления выбрана в качестве пространственной медианы, разделяющей AABB пополам. Джино ван ден Берген сообщает о лучших характеристиках этого метода, чем при разбиении по медиане объекта. В редком случае, когда все примитивы попадают в один из подмножеств, набор вместо этого разбивается на основе медианы объекта.

Осведомленный метод обхода используется вместе с правилом «спуска большего размера» для обхода деревьев. Вместо перестройки деревьев AABB по мере вращения их объектов, тест OBB используется для сравнения - после преобразования - относительно ориентированных AABB. Поскольку одна и та же относительная ориентация является общей для всех преобразованных пар AABB, матрицу преобразования необходимо вычислять только один раз на запрос, что упрощает тест OBB.

Джино ван ден Берген также сообщает о повышении скорости после выполнения только первых 6 из 15 осевых тестов для тестов AABB с вращением. Это компромисс, который приводит к более дешевому тесту, но также к ложным совпадениям, которые приводят к более (дорогостоящим) примитивным тестам. Такая же оптимизация, примененная к деревьям OBB, не дала никаких изменений.


BoxTree, представленный в [Zachmann95], также является рекурсивно построенной иерархией AABB, определенных в системе координат объекта. Однако здесь, когда ограничивающий прямоугольник разрезан на две (не обязательно равного размера) части плоскостью разделения, результирующие подбоксы непосредственно образуют AABB. Примитивы полностью внутри любого подпункта назначаются соответствующему набору. Любые примитивы, пересекающие плоскость разделения, отправляются в оба ящика, что приводит к дублированию примитивов. В целом, конструкция очень похожа на конструкцию k-d дерева.

Поскольку примитивы, пересекающие плоскость разделения, дублируются, выбор плоскости разделения сделан в попытке сбалансировать дерево и минимизировать количество пересекающихся примитивов. Прежде чем пытаться найти эту плоскость разделения, Захманн сначала проверяет, существует ли плоскость разделения, которая отрезает «большую» (насколько возможно большую) часть пустого пространства от AABB, чтобы она лучше соответствовала содержащейся геометрии. Большой здесь определяется отношением пустого параллелипипеда к его родительскому, которое больше заданной константы. Все три оси AABB проверяются во время этой операции, и используется та, которая дает лучший результат. В дополнение к остановке рекурсии, когда была достигнута определенная глубина или набор примитивов меньше определенного предела, она также останавливается, если один из вложенных блоков содержит почти столько же примитивов, сколько его родительский блок.

Поскольку BoxTrees построены в пространстве модели, во время тестирования они должны преобразовываться по мере преобразования объектов. Однако, поскольку все AABB имеют ту же ориентацию, что и верхний узел, большинство вычислений можно повторно использовать во время обхода иерархии. Чтобы проверить повернутые AABB (теперь OBB), можно использовать тест разделительной оси, который теперь значительно упрощен тем, что 15 осей остаются неизменными на протяжении всего теста. Захманн также описывает альтернативный тест на перекрытие на основе отсечения. Для обхода деревьев Захманн использует метод одновременного обхода.

В более поздней презентации Захманн описывает альтернативную реализацию, в которой вместо непосредственного использования плоскости разделения для определения границы вложенных блоков он определяет две плоскости, которые ограничивают пересекающиеся примитивы с обеих сторон вдоль оси разделения. Затем «левый» вложенный блок становится левой частью родительского AABB, разделенный в позиции самой правой из двух плоскостей, и наоборот для «правого» вложенного блока. Другими словами, дочерние AABB идентичны родительским AABB, за исключением одной стороны. В этом представлении оба дочерних элемента представлены с использованием всего двух (с плавающей запятой) значений с учетом родительского объема [Zachmann00].

Оба метода Джино ван ден Бергена и Захманна работают с произвольными многогранниками или буферами многоугольников. Таким образом, они будут надежно обнаруживать только столкновения с поверхностью. Они не обнаруживают, когда один объект полностью находится внутри другого.

### 6.4.3 Дерево Сферы через разбиение на Октодерево

Популярным подходом к построению дерева сфер из-за его простоты является построение его из октодерева, разбитого на объем объекта [Tzafestas96]. Во-первых, объект заключен в самый маленький охватывающий ограничивающий куб. Этот куб рекурсивно разделен на восемь равных частей, или октантов. Любой октант, содержащий часть объекта, рекурсивно делится до тех пор, пока не будет достигнута заданная глубина дерева. Во время построения каждый занятый узел октодерева описывается сферой, образуя фактическое дерево сфер. Центральная точка октанта используется как центр сферы. Для куба со стороной $s$ радиус сферы $r$ равен $r = s\sqrt{3}/2$. Если исходный ограничивающий объем представляет собой общий AABB вместо куба, радиус октанта со сторонами $x$, $y$ и $z$ становится равным $r = \sqrt{x^2 + y^2 + z^2}/2$.

Чтобы исключить избыточные сферы, которые не влияют на фактическое обнаружение столкновений, можно остановить рекурсию в любых узлах октодерева, которые перекрыты со всех сторон [O’Sullivan99]. Однако это может привести к тому, что столкновения с внутренними частями останутся незамеченными.

Дерево сфер, полученное в результате этого подхода, имеет довольно слабое соответствие. Хаббард предлагает использовать моделирование отжига для сжатия сфер вокруг объекта, сохраняя при этом консервативное покрытие объекта [Hubbard95]. Это включает в себя внесение случайных изменений в сферы, принятие тех, которые создают более плотную сферу, иногда принятие тех, с которыми хуже бороться, застревая в локальных минимумах. К сожалению, как указывает Хаббард, трудно измерить плотность сфер вокруг объектов. Этап моделирования отжига также довольно медленный и может привести к очень неравномерному распределению сфер. Поэтому практическая ценность этого метода несколько ограничена.

### 6.4.4 Дерево Сферы с покрытых сферой поверхностей

Используя базовый метод построения сверху вниз, [Quinlan94] вычисляет деревья сфер из входного набора маленьких сфер, покрывающих все поверхности исходного объекта. Покрытие поверхности выполняется в процессе преобразования сканирования, при котором каждый многоугольник во входном наборе перекрывается регулярной сеткой сфер с центрами сфер в плоскости многоугольников. Каждая из этих сфер, образующих листовые узлы окончательного дерева, помечена многоугольником, который она была создана для покрытия.

Иерархия строится путем деления полного набора листовых сфер на две части примерно одинакового размера. Два поддерева строятся путем рекурсивного вызова алгоритма с каждым из подмножеств. Затем эти поддеревья объединяются в дерево, добавляя их в качестве дочерних к новому родительскому узлу. На каждом этапе набор сфер делится на два подмножества путем включения центров сфер в AABB. AABB делится пополам по самой длинной стороне, и сферы назначаются подмножествам на основе того, в какой половине AABB находится их центр.

Обратите внимание, что этот подход предполагает представление поверхности на основе (выпуклых) многоугольников. Он не обнаруживает столкновения с внутренней частью объекта.

### 6.4.5 Покрытие сферы генерации и сокращения

Интересный метод, который не строит иерархию как таковую, а просто вычисляет набор сфер, объединение которых полностью охватывает данный объект, был предложен Гринспеном и Буртником [Greenspan96]. Их алгоритм состоит из двух шагов. Сначала выполняется этап генерации, на котором объект полностью покрывается большим количеством сфер. Затем на втором этапе обрезки все лишние сферы удаляются. Избыточность здесь означает, что если бы сферы были удалены, объект все равно был бы полностью покрыт оставшимися сферами.

Генераторная часть управляется двумя параметрами. Первый параметр, overshoot, определяет, насколько далеко за поверхность объекта может выходить сфера. Второй параметр, интервал, указывает минимально допустимое расстояние между любыми двумя центрами сфер. Алгоритм выполняется путем создания плотной однородной трехмерной сетки вокруг объекта. Сторона ячейки сетки устанавливается на параметр интервала. Все ячейки помечены как внутренние, внешние или поверхностные, в зависимости от того, полностью ли они находятся внутри объекта, полностью вне объекта или нет. Каждой ячейке также присваивается значение, изначально нулевое. Затем сфера центрируется в каждой ячейке сетки, не отмеченной внешней. Радиусы сфер установлены таким образом, чтобы сферы не выходили за границы объекта больше, чем на параметр превышения.

На этапе отсечения сферы могут быть избыточными либо полностью заключенными в одну (большую) сферу, либо заключенными объединением набора из двух или более сфер. В первом случае каждая сфера просто сравнивается со всеми другими сферами, чтобы увидеть, является ли она избыточной, и в этом случае она удаляется. Этот процесс требует $O(n^2)$ сравнений сфера-сфера. Чтобы справиться со вторым случаем, оставшийся набор сфер перебирается, и для каждой ячейки, полностью содержащейся в сфере, соответствующее значение увеличивается на единицу. После этого каждая ячейка сетки, помеченная как поверхность, имеющая значение 1, должна находиться в одной сфере. Чтобы объект был полностью замкнутым, все такие сферы должны быть включены в окончательный набор. Эти сферы идентифицируются, удаляются и добавляются в окончательный набор. Ячейка помечена как обработанная, что означает, что впредь ее не следует рассматривать.

Когда все такие сферы были добавлены в окончательный набор и больше не существует ячеек со значением 1, все оставшиеся ячейки поверхности должны быть покрыты двумя или более сферами. И наоборот, каждая оставшаяся сфера должна быть полностью охвачена двумя или более сферами. Таким образом, любую сферу можно удалить из набора кандидатов, сохранив при этом полное покрытие объекта. Когда сфера удаляется, содержащиеся в ней ячейки сетки уменьшаются на единицу. Когда это приводит к ячейке сетки со значением 1, соответствующая сфера добавляется к окончательному набору так же, как и раньше. Обработка прекращается, когда не остается никаких сфер-кандидатов или, при желании, просто когда все ячейки поверхности отмечены как обработанные. Несмотря на то, что их алгоритм не переходит к построению иерархии из окончательного набора сфер, любой из ранее описанных методов построения иерархии теперь может быть применен со сферами в качестве входного набора для создания дерева сфер, если это необходимо.

### 6.4.6 k-dop Деревья

В [Klosowski98] деревья k-DOP использовались для обнаружения столкновений между летающим объектом и большой статической средой. Используя построение сверху вниз, они связывают входной набор треугольников в k-DOP, а затем разбивают входной набор на две части, рекурсивно просматривая части. Рекурсия останавливается, когда узлы содержат заданный порог t треугольников. Для статической иерархии они использовали t=1, а для летающего объекта t=40. Обход запроса был таким, что среда полностью была пройдена вниз до того, как пройден вниз объект.

Для построения k-DOP-деревьев сравнивались четыре различных стратегии разделения. Выбор оси был ограничен одной из координатных осей x, y или z на основе критериев минимизации суммы объемов, минимизации максимального объема, использования оси с наибольшей дисперсией и разделения по самой длинной оси родительского объёма. Для определения точки разделения использовались среднее и медианное значение координат центра тяжести треугольника в проекции на ось.

Их результаты показали, что расщепление по среднему всегда приводит к иерархии с меньшим общим объемом, чем при расщеплении по медиане. Стратегия «минимизировать сумму» последовательно давала наименьшую иерархию общего объема, при «минимизации максимума», «наибольшей дисперсии» и «наибольшей оси» результаты были примерно на 7%, 10% и 33% хуже, соответственно. Они также исследовали использование более трех осей координат, в частности, все k / 2, определяющие направления для k-DOP, и сообщили, что на самом деле это не дает улучшения. Однако время предварительной обработки увеличилось в среднем примерно на 30%.

Чтобы переключить k-DOP во время обновления, они использовали более дорогой метод восхождения на холм для корневого узла, так как он и близлежащие узлы наиболее часто посещаются. Приблизительный метод DOP-of-DOP использовался для всех остальных узлов из-за (гораздо) меньших накладных расходов.

Также работая с k-DOP, [Konečný98] вместо этого использует ось наибольшей дисперсии среди набора k / 2 осей фиксированного направления для k-DOP (измеренных по проецируемым центроидам). Затем он разделяет примитивы на два набора одинакового размера.

[Klosowski98] сравнил 6-, 14-, 18- и 26-DOP и обнаружил, что 18-DOP работают лучше всего. Напротив, [Zachmann98] сравнил 6-, 8- и 14-DOP, обнаружив, что 6-DOP (то есть AABB) работают лучше, чем два других. В более поздней работе, используя нестандартные k-DOP, описанные в главе 4, Захманн сообщает об исследовании полного диапазона k=[6 ... 32]. Хотя ни один k не был оптимальным во всех тестах, k=24 показал лучший результат в целом [Zachmann00]. Поскольку эти испытания проводились в различных условиях, напрямую сравнивать результаты сложно.

Используя числа типа double (8 байт) для компонентов вершины и 4-байтовые целые числа для индексов вектора треугольника, Klosowski и другие сообщают, что им требуется $(16k + 108) n$ байтов для хранения всех n треугольников среды, включая саму иерархию. Для k=6, 14, 18 и 26 это становится 204, 332, 396 и 524 байта на входной треугольник соответственно. Это следует сравнить с 412 байтами на входной треугольник, заявленным для пакета обнаружения столкновений на основе OBB RAPID (также с использованием двойников). Что еще хуже, для набора данных из 169 944 треугольников они сообщают, что иерархия с 26 DOP имеет неприличный размер в 69 МБ !


## 6.5 Объединение ограничивающих объемов

Когда иерархии создаются сверху вниз или постепенно, ограничивающие объёмы обычно создаются с нуля с использованием измерений содержащихся данных. При построении снизу вверх альтернативой довольно дорогостоящей операции подгонки ограничивающего объема непосредственно к данным является объединение самих дочерних томов в новый ограничивающий объем. В этом разделе представлены такие операции слияния для AABB, сфер, OBB и k-DOP.

### 6.5.1 Слияние двух AABB

Вычисление охватывающего AABB для двух данных AABB тривиально: стороны охватывающего AABB выбираются так, чтобы они совпадали с минимальной и максимальной сторонами двух данных объемов. Например, для представления min-max AABB включающий AABB вычисляется с помощью следующего кода:

```cpp
    // Вычислить AABB a для AABB a0 и a1
    void AABBEnclosingAABBs(AABB &a, AABB a0, AABB a1){
        for (int i = 0; i < 2; i++) {
            a.min[i] = Min(a0.min[i], a1.min[i]);
            a.max[i] = Max(a0.max[i], a1.max[i]);
        }
    }
```
Другие представления AABB приводят к столь же тривиальным реализациям.

### 6.5.2 Слияние двух сфер

Чтобы вычислить минимальную сферу, ограничивающую две другие сферы, расчет лучше всего разбить на два случая: где одна сфера полностью окружена другой и где они либо частично перекрываются, либо не пересекаются. Чтобы различать эти два случая, пусть две сферы будут $S_0$ и $S_1$ , с центрами $C_0$ и $C_1$ и радиусами $r_0$ и $r_1$ соответственно (рисунок 6.5). Пусть $d = \| C_1 − C_0 \|$ будет расстояние между $C_0$ и $C_1$.
Тогда, если $\mid r_1 − r_0 \mid ≥ d$, одна сфера полностью внутри другой. Простой геометрический аргумент показывает, почему это так. Начните с обеих сфер, центрированных в одном месте. Теперь $d=0$, а расстояние между поверхностями сфер равно $\mid r_1 - r_0 \mid$. Однако очевидно, что это также максимальное расстояние, на которое центры сфер могут быть разделены (и увеличено d) до того, как внутренняя сфера проникает через поверхность внешней сферы, и результат следует.

В первом случае, когда одна сфера находится внутри другой, не нужно рассчитывать новую сферу, и можно просто вернуть большую сферу. Это позволяет избежать дорогостоящей операции извлечения квадратного корня. Во втором случае, когда сферы либо частично перекрываются, либо не пересекаются, радиус r новой сферы составляет половину максимального расстояния между поверхностями сфер; таким образом:

$$r = (d + r_0 + r_1 )/2.$$

**Рисунок 6.5** Объединение сфер $S_0$ и $S_1.$

Центр сферы $C$ вычисляется путем изменения $C_0$ на $r_0$ единиц от $C_1$, а затем обратно к $C_1$ на $r$ единиц:

$$C = C_0 − r_0(C_1 − C_0 )/ \|C_1 − C_0\| + r(C_1 − C_0 )/ \|C_1 − C_0\| = C_0 + (r − r_0 )(C_1 − C_0 )/ \|C_1 − C_0\| .$$

Код для этого:

```cpp
// Вычислить ограничивающую сферу s сфер s0 и s1
void SphereEnclosingSpheres(Sphere &s, Sphere s0, Sphere s1){
    // Вычислить квадрат расстояния между центрами сфер
    Vector d = s1.c - s0.c;
    float dist2 = Dot(d, d);
    if (Sqr(s1.r - s0.r) >= dist2) {
        // Сфера с большим радиусом охватывает другую;
        // просто установить s как большую из двух сфер
        if (s1.r >= s0.r)
            s = s1;
        else
            s = s0;
    } else {
        // Сферы частично перекрываются или не пересекаются
        float dist = Sqrt(dist2);
        s.r = (dist + s0.r + s1.r) * 0.5f;
        s.c = s0.c;
        if (dist > EPSILON)
        s.c += ((s.r - s0.r) / dist) * d;
    }
}
```

### 6.5.3 Слияние двух OBB

Вычислить OBB из двух OBB немного сложнее. Простое решение - использовать методы, представленные в главе 4. Например, 16 вершин двух блоков можно передать непосредственно в функцию **ComputeOBB()** (которая использует собственные векторы ковариационной матрицы для точек в качестве осей блока). Это может быть дополнительно объединено с техникой минимальных главных компонент, описанной в Разделе 4.4.4. Последний используется для построения снизу вверх в алгоритме BoxTree, описанном в [Barequet96].

Недостатком этих методов является стоимость итерационных алгоритмов, используемых для вычисления собственных векторов, что делает их менее подходящими для использования в реальном времени. Альтернативное безытерационное решение представлено в [Eberly00]. Он предлагает комбинировать повороты двух OBB, преобразовывая их в кватернионы, интерполируя между ними посередине, а затем преобразовывая обратно в матрицу вращения, которая теперь определяет оси OBB. Затем через проекцию на эти оси устанавливаются экстенты. Обратите внимание, что в псевдокоде, представленном в [Eberly00], центр OBB определяется до вычисления экстентов OBB. В общем, это не будет максимально плотно прилегать к OBB. Чтобы сделать OBB плотно по отношению к двум OBB, центральная точка должна быть рассчитана после того, как были установлены границы.

### 6.5.4 Слияние двух k-DOP

Объединить два k-DOP так же просто, как объединить два AABB. Для каждой оси k-DOP ограничивающий k-DOP определяется меньшим из минимальных значений и большим из максимальных значений для двух ограничиваемых DOP. По определению, никакие плоскости не могут связываться сильнее, чем они. Реализация поразительно похожа на код слияния AABB.

```cpp
    // Вычислить KDOP d для KDOP d0 и d1
    void KDOPEnclosingKDOPs(KDOP &d, KDOP d0, KDOP d1, int k){
        for (int i = 0; i < k / 2; i++) {
            d.min[i] = Min(d0.min[i], d1.min[i]);
            d.max[i] = Max(d0.max[i], d1.max[i]);
        }
    }
```

## 6.6 Эффективное представление дерева и обход

До сих пор построение иерархии и обход описывались довольно абстрактно. Однако для промышленной реализации важно оптимизировать как код обхода, так и само представление дерева. Поскольку доступ к памяти и промахи в предсказании ветвлений, как правило, приводят к большим потерям в современных архитектурах, две очевидные оптимизации - минимизировать размер задействованных структур данных и упорядочить данные более удобным для кеширования способом, чтобы соответствующая информация обнаруживалась сразу, как возможно.

В этом разделе описываются несколько представлений данных и оптимизации обхода, которые помогают ускорить выполнение запросов на конфликты. Однако всегда помните, что из-за поведения кеша, которое сложно предсказать, некоторые из этих более сложных методов не всегда могут обеспечить ожидаемое ускорение. Если это так, учтите, что сохранение как можно более короткого и простого кода обхода на самом деле может быть простым способом сделать его быстрее. Об эффективном древовидном представлении мы вернемся в главе 13 в контексте оптимизации памяти.

### 6.6.1 Представление массива

Предположим, что полное двоичное дерево из n узлов задано как иерархия столкновений. Это дерево может быть сохранено в массиве из n элементов, отображая его узлы поочередно в ширину.

```cpp
// Первый уровень
array[0] = *(root);
// Второй уровень
array[1] = *(root->left);
array[2] = *(root->right);
// Третий уровень
array[3] = *(root->left->left);
...
```

**Рисунок 6.6** Двоичное дерево (вверху), сохраненное с использованием представления массива без указателей (внизу). Дочерние элементы узла в позиции массива i могут быть найдены в позициях ;$2i + 1$ и $2i + 2$. Обратите внимание на потраченную впустую память (показана серым цветом).

При такой настройке легко проверить, что, находясь в узле, хранящемся в **array[i]**, соответствующий левый дочерний элемент узла будет найден в **array[2*i+1]**, а его правый дочерний элемент - в **array[2*i+2]**. Следовательно, вместо представления дерева с использованием узлов, содержащих левые и правые указатели на дочерние узлы, можно полностью удалить все указатели и сохранить узлы без указателей в массиве, как только что описано (рис. 6.6). Зная это правило индексации потомков, реальное преобразование может быть эффективно записано как простая рекурсивная процедура.

```cpp
    // Для дерева t выводит свои узлы в порядке обхода в ширину в массив узлов n. 
    // Вызов с i = 0.
    void BreadthFirstOrderOutput(Tree *t, Tree n[], int i){
        // Копирование содержимого из узла дерева в дерево в ширину
        n[i].nodeData = t->nodeData;
        // Если у дерева есть левый узел, рекурсивно копировать его поддерево
        if (t->left)
            BreadthFirstOrderOutput(t->left, n, 2*i+1);
        // То же, если у него правильное поддерево
        if (t->right)
            BreadthFirstOrderOutput(t->right, n, 2*i+2);
    }
```
Когда дерево идеально сбалансировано (как предполагаемое полное дерево), это экономит место в памяти и количество операций чтения указателя во время обхода дерева. К сожалению, для несбалансированного дерева все равно необходимо выделить пространство, как если бы дерево было дополнено дополнительными узлами, чтобы сделать его полностью сбалансированным. Что еще хуже, даже один дополнительный узел, добавленный к полностью сбалансированному дереву, добавит к дереву один полный дополнительный уровень, удваивая его пространство для хранения!

Таким образом, это представление наиболее полезно, когда фактические данные узла (его «полезная нагрузка») малы по сравнению с объединенным размером дочерних указателей, или когда дерево действительно полностью сбалансировано (или только несколько узлов на короткой стороне от полного баланса). Например, когда иерархия была построена с использованием критерия разделения на основе медианы, который гарантирует некоторый уровень почти баланса, это может быть полезным представлением.

### 6.6.2 Порядок обхода предзаказа

Даже когда нельзя гарантировать сбалансированность древовидной иерархии, все равно можно выводить данные в более эффективном представлении. Если узлы дерева выводятся в порядке обхода перед порядком, левый дочерний элемент, если он присутствует, всегда будет немедленно следовать за своим родителем. Таким образом, хотя ссылка по-прежнему необходима, чтобы указывать на правый дочерний элемент, необходим только один бит, чтобы указать, есть ли левый дочерний элемент (сразу после текущего узла). На рисунке 6.7 показано двоичное дерево и его узлы, выводимые в порядке обхода перед порядком.

Подпрограмму, которая берет обычное дерево на основе указателя и выводит его в порядке обхода до упорядочения в массив, довольно просто реализовать. Единственная сложность заключается в обновлении указателей правой ссылки, чтобы они указывали на местоположение узла, которое неизвестно на момент записи родительского узла в память. Их можно обработать либо с помощью второго прохода по дереву, либо (лучше) с помощью стека и обратного исправления, как в следующем коде.

**Рисунок 6.7** То же дерево, что и на рис. 6.6, но с выводами узлов в порядке обхода перед порядком. Теперь узлам нужен указатель на правый дочерний элемент (показан стрелкой). Им также нужен бит, чтобы указать, есть ли у узла левый дочерний узел (который, если присутствует, всегда следует сразу за родительским узлом). Здесь этот бит обозначен серым треугольником.

```cpp
// Для дерева t выводит свои узлы в порядке обхода перед порядком в массив узлов n. Вызов с i = 0.
int PreorderOutput(Tree *t, Tree n[], int i){
    // Реализуйте простой стек родительских узлов.
    // Обратите внимание, что указатель стека «sp» автоматически сбрасывается между вызовами
    const int STACK_SIZE = 100;
    static int parentStack[STACK_SIZE];
    static int sp = 0;
    // Копировать содержимое из узла дерева в дерево PTO
    n[i].nodeData = t->nodeData;
    // Установить флаг, указывающий, есть ли левый дочерний элемент
    n[i].hasLeft = t->left != NULL;
    // Если у узла есть правый дочерний элемент, отправить его индекс для обратного исправления
    if (t->right) {
        assert(sp < STACK_SIZE);
        parentStack[sp++] = i;
    }
    // Теперь выполнить рекурсию по левой части дерева
    if (t->left)
        i = PreorderOutput(t->left, n, i + 1);
    if (t->right) {
        // Исправить правую ссылку родительского элемента, чтобы указать на этот узел
        int p = parentStack[--sp];
        n[p].rightPtr = &n[i + 1];
        // Рекурсия по правой части дерева
        i = PreorderOutput(t->right, n, i + 1);
    }
    // Вернуть обновленный индекс массива при выходе
    return i;
}
```

Помимо уменьшения вдвое необходимого количества дочерних указателей, это представление также имеет то преимущество, что оно достаточно дружелюбно к кешу. Левый дочерний элемент, скорее всего, уже находится в кеше, поскольку был получен одновременно с его родительским элементом, что делает обход более эффективным.

### 6.6.3 Смещения вместо указателей

Типичная реализация дерева использует (32-битные) указатели для представления дочерних ссылок узла. Однако для большинства деревьев представление указателя является излишним. Чаще всего, выделяя узлы дерева изнутри массива, вместо этого можно использовать 16-битное значение индекса с начала массива. Это будет работать как для статических, так и для динамических деревьев. Если дерево гарантированно статично, можно получить еще больший диапазон, сделав смещения относительными от родительского узла.

За счет дополнительных накладных расходов на обход также можно комбинировать указатель и представление индекса. Один дополнительный зарезервированный бит может указывать на то, что сохраненное значение следует вместо этого использовать в качестве индекса в отдельном массиве указателей или более широких значений смещения.

### 6.6.4 Структуры, удобные для кеширования (Недвоичные деревья)

Время выполнения в современных архитектурах часто больше ограничено проблемами кеширования, связанными с выборкой данных из памяти, чем количеством выполненных инструкций. Поэтому может окупиться использование нетрадиционных структур, которые, хотя и являются более сложными для прохождения, занимают меньше памяти и имеют более удобный для кеширования шаблон доступа.

Одно из таких возможных представлений - объединение наборов из трех узлов двоичного дерева (родительский плюс левый и правый дочерний) в «трехузел», объединенный узел, содержащий все три узла. Исходный набор из трех узлов имеет две внутренние связи, соединяющие родительский узел с дочерними, и четыре внешних ссылки, соединенных с остальной частью дерева. Новому узлу не нужны никакие внутренние ссылки, только четыре внешних ссылки.

Для четырехуровневого полного двоичного дерева (15 узлов) необходимо 14 внутренних ссылок. Соответствующее трехузловое дерево имеет два уровня (четыре узла) и всего четыре внутренних ссылки (рисунок 6.8). Бинарное дерево с шестью уровнями (63 узла) имеет 62 внутренних ссылки; дерево с тремя узлами только 20. В общем, соответствующее дерево с тремя узлами требует трети связей полного двоичного дерева, что даже лучше, чем при представлении порядка обхода до порядка. Кроме того, трехузлы могут выводиться в ширину, потенциально позволяя верхним n уровням иерархии оставаться в кэше.

Недостатком является дополнительная обработка, необходимая для обхода дерева. Кроме того, когда дерево не завершено, узлы в трехузле становятся пустыми, тратя впустую память. Также необходим флаг, чтобы указать, используется узел или пуст. По этой причине трехузловые деревья лучше подходят для плотных деревьев. Для разреженных деревьев предпочтительнее представление порядка обхода перед порядком.

**Рисунок 6.8** (a) Четырехуровневое двоичное дерево. (b) Соответствующее двухуровневое трехузловое дерево.

Конечно, это представление можно комбинировать с предыдущими методами. Например, сохранение трехузлового дерева в порядке обхода перед порядком со смещениями по отношению к родительским объектам вместо дочерних указателей уменьшило бы объем памяти, используемый для ссылок, до минимума. Связанный с этим метод обсуждается в [Intel99], в котором вместо одной сферы, ограничивающей объем, в качестве ограничивающего объема используется объединение трех сфер, поскольку три сферы прекрасно вписываются в строку кэша.

### 6.6.5 Узел дерева и порядок примитивов

Когда, скажем, используется одновременный обход, четыре рекурсивных вызова генерируются в узловой части алгоритма обхода. Поскольку алгоритм был представлен в Разделе 6.3.3, порядок, в котором были отправлены эти четыре вызова, полностью определялся относительным порядком узлов в двух деревьях. Если текущий запрос предназначен для тестирования, а не для поиска столкновений, или если для удаления ветвей иерархии используется сокращение расстояния, желательно найти пересечения как можно раньше.

Одна из возможностей - попытаться выяснить во время выполнения лучший порядок выполнения рекурсивных вызовов. Это не обязательно просто, поскольку на данный момент ничего не известно о структуре, расположенной ниже по иерархии. Более реальная альтернатива (без дополнительных затрат времени выполнения) - эвристически переставить дочерние узлы родительского узла во время построения, чтобы потомок с большей вероятностью привел к раннему пересечению. Следуя [Haines91a], несколько возможных способов упорядочить узлы (не обязательно для двоичных деревьев) включают:

- *Расположите дочерние элементы так, чтобы листья располагались перед узлами*. Если статус коллизии определяется на уровне примитивов, поскольку все примитивы содержатся в листьях, то листья приходят до того, как примитивы неконечных узлов проверяются как можно раньше.
- *Сначала поместите самые маленькие поддеревья.* Рассматривая узлы как корни поддеревьев иерархии, применяется тот же аргумент. Если сначала иметь узлы с меньшим количеством потомков, листья должны быть достигнуты раньше.
- *Отсортируйте детей по количеству просмотров и тестов*. Основываясь на фактическом использовании, измените иерархию таким образом, чтобы узлы, фактически участвующие в положительных запросах на коллизию, были первыми, а те, которые никогда или редко участвовали, - последними.
- *Отсортируйте детей от ближнего к дальнему по преобладающему направлению запроса*. Если тесты исходят преимущественно из определенного направления, например сверху для иерархии, представляющей землю, имеет смысл отсортировать дочерние элементы так, чтобы первыми были те, которые соответствуют более высокому уровню.

Разумеется, тот же принцип упорядочения применяется к примитивам, хранящимся внутри листа. Когда лист содержит более одного примитива, они могут быть отсортированы по аналогичным правилам. Например, если используются разные типы примитивов, такие как треугольники и четырехугольники, а также поверхности Безье или NURBS, имеет смысл сначала протестировать полигоны, прежде чем выполнять более дорогие тесты с использованием примитивов поверхности.

Также можно упорядочить примитивы для бесплатного получения дополнительной информации об удалении. Скажем, дерево OBB построено из набора многоугольников, представляющих статический мир, с которым сталкиваются в основном сверху. Листовые OBB этого дерева вряд ли будут иметь многоугольники, простирающиеся до самого верхнего угла. Пусть многоугольники переставлены так, чтобы многоугольник с самой высокой вершиной был первым в списке многоугольников. Затем переставьте вершины этого многоугольника так, чтобы самая верхняя вершина была первой в его наборе вершин. Теперь плоскость, определенная миром вверх по нормали, и первая вершина, хранящаяся в листе (которая находится в известной позиции), могут использоваться для быстрого отсеивания столкновений с OBB до того, как будут выполнены другие, более дорогие тесты.

Другие возможные варианты включают сортировку вершин так, чтобы две вершины, образующие самое длинное ребро, были первыми, и размещение вершины первой, которая вместе с центроидом многоугольника (который легко вычисляется из сохраненных вершин) образует ограничивающую сферу многоугольника (центроид центр сферы и вершина, определяющая радиус сферы).

### 6.6.6 О рекурсии

Обход деревьев (двоичных или иных) естественным образом выражается с помощью рекурсии. Однако, как было указано в Разделе 6.3.2, рекурсия - не самая эффективная форма для выражения кода. У него есть несколько других недостатков. Одна из проблем заключается в том, что выход из рекурсии и немедленное возвращение значения не поддерживается в большинстве языков напрямую. Использование переменной-флага для того, чтобы сообщить коду о завершении, не просто чрезмерно сложное и надуманное решение, но требует, чтобы рекурсия «раскрутилась» до самого верха.

Идеальное решение - переписать любой рекурсивный код с использованием явного стека, как описано в Разделе 6.3.2. Поскольку код больше не рекурсивный, из функции можно выйти в любой момент. Дополнительные преимущества включают возможность прервать и возобновить выполнение кода в любой момент, просто сохранив несколько значений переменных. Наличие явного указателя стека позволяет легко обнаруживать ошибки в коде обхода, которые в противном случае могли бы вызвать бесконечную рекурсию, и в целом код легче пройти во время отладки. Явный указатель стека также неявно обеспечивает глубину стека, что упрощает ограничение обходов до указанной максимальной глубины, если это необходимо.

Отсутствие рекурсии также позволяет избежать накладных расходов на вызовы рекурсивных функций. Кроме того, вероятно, потребуется меньше места в стеке, поскольку когда-либо создается только один кадр стека для локальных переменных, что снижает вероятность удаления кэша данных.

Если оставить в стороне все эти соображения, на ранней стадии разработки можно многое сказать о преимуществах использования легкого для чтения рекурсивного кода для быстрого создания прототипов и тестирования. К счастью, как в C, так и в C++ есть альтернативы использованию нерекурсивного кода только для того, чтобы иметь возможность раннего выхода из рекурсивного тестового запроса. В C (и в меньшей степени в C ++) другой вариант - использовать библиотечную функцию *setjmp()* для выхода из рекурсии.  Версия тестового запроса рекурсивного универсального информированного кода обхода в глубину теперь может быть записана как:

```cpp
    // В Bullet не используется и вы тоже jmp не используйте в коде.
    #include <setjmp.h>
    jmp_buf gJmpBuf;
    int BVHTestCollision(BVTree a, BVTree b){
        int r = setjmp(gJmpBuf);
        if (r == 0) {
            BVHTestCollisionR(a, b);
            return 0;
        } else return r - 1;
    }
    // Общий рекурсивный код обхода BVH предполагает, что листья тоже имеют BV
    void BVHTestCollisionR(BVTree a, BVTree b){
        if (!BVOverlap(a, b))
            longjmp(gJmpBuf, 0 + 1); // false
        if (IsLeaf(a) && IsLeaf(b)) {
            if (PrimitivesOverlap(a, b))
                longjmp(gJmpBuf, 1 + 1); // true
        } else {
            if (DescendA(a, b)) {
                BVHTestCollisionR(a->left, b);
                BVHTestCollisionR(a->right, b);
            } else {
                BVHTestCollisionR(a, b->left);
                BVHTestCollisionR(a, b->right);
            }
        }
    }
```
Обратите внимание, что, поскольку *longjmp()* не может возвращать значение 0, он также не может возвращать логическое значение false. Чтобы обойти это небольшое затруднение, к возвращаемому значению необходимо добавить небольшое значение (здесь 1), которое будет вычтено в основной процедуре. В C++ вместо использования *setjmp()* более подходящим вариантом может быть использование обработки исключений для выполнения того же самого.

### 6.6.7 Группировка запросов

В играх нередко бывает несколько тестовых запросов, исходящих из одной и той же области. Типичный пример - проверка колес транспортного средства на столкновение с землей. В идеале эти запросы могут быть заранее организованы в иерархию, позволяющую использовать любой из ранее описанных методов обхода. В примере с транспортным средством это верно, однако в некоторых случаях предварительное вычисление иерархии может оказаться непрактичным.

Теперь, если колеса проверяются на столкновение независимо, поскольку транспортное средство мало по отношению к миру, прохождение запросов через самую верхнюю часть мировой иерархии, скорее всего, будет таким же. Таким образом, полезно перемещать все запросы вместе по мировой иерархии до момента, когда они начинают разветвляться на разные части дерева.

Один из подходов заключается в динамическом вычислении иерархии для объектов запроса, которая автоматически перемещает объекты как один. Для нескольких объектов, таких как четыре колеса, это, вероятно, перебор. Вместо этого объекты можно просто сгруппировать в одном ограничивающем объеме. Затем этот том «сбрасывается» по иерархии, по которой он проверяется, до тех пор, пока не достигнет узла, на котором его должны были бы отбросить оба дочерних объёма. В этой точке дерева текущий узел может эффективно использоваться в качестве альтернативного корневого узла для индивидуальных запросов коллизий объектов с мировой иерархией. Если предположить, что исходные индивидуальные запросы были сферами, проверенными на соответствие мировой иерархии, это выглядело бы следующим образом.

```cpp
    Sphere s[NUM_SPHERES];
    ...
    for (int i = 0; i < NUM_SPHERES; i++)
        if (SphereTreeCollision(s[i], worldHierarchy))
            ...
```

Простое дополнение к подпрограмме **SphereTreeCollision()** позволяет использовать альтернативный стартовый узел для теста.

```cpp
bool SphereTreeCollision(Sphere s, Tree *root){
    // Если установлен альтернативный начальный узел, используйте его;
    // в противном случае используйте предоставленный начальный корневой узел
    if (gStartNode != NULL) root = gStartNode;
        //...исходный код находится здесь...
}
```

Затем, предоставляя функциональные возможности для установки и сброса альтернативного начального узла

```cpp
    // Задает альтернативный начальный узел или нет (если значение null)
    Tree *gStartNode = NULL;
    // Установить новый альтернативный начальный узел
    void BeginGroupedQueryTestVolume(Sphere *s, Tree *root){
        // Спуститься в иерархию, пока данная сфера перекрывает любую 
        // дочернюю ограничивающую сферу (но не обе)
        while (root != NULL) {
            bool OverlapsLeft = root->left && SphereOverlapTest(s, root->left.bvSphere);
            bool OverlapsRight = root->right && SphereOverlapTest(s, root->right.bvSphere);
            if (OverlapsLeft && !OverlapsRight) root = root->left;
            else if (!OverlapsLeft && OverlapsRight) root = root->right;
            else break;
        }
        // Установить его как новый альтернативный начальный узел
        gStartNode = root;
    }
    // Сбросить альтернативный начальный узел
    void EndGroupedQueryTestVolume(void){
        gStartNode = NULL;
    }
```
исходный код теперь может быть очень легко преобразован в сгруппированный запрос со значительной экономией времени на обход.

```cpp
    Sphere s[NUM_SPHERES];
    ...
    // Вычислить ограничивающую сферу для сфер запроса
    Sphere bs = BoundingSphere(&s[0], NUM_SPHERES);
    BeginGroupedQueryTestVolume(bs, worldHierarchy);
    // Выполнить исходные запросы, как и раньше
    for (int i = 0; i < NUM_SPHERES; i++)
        if (SphereTreeCollision(s[i], worldHierarchy))
        ...
    // Сбросить все обратно, чтобы не использовать сгруппированный запрос
    EndGroupedQueryTestVolume();
    ...
```
Обратите внимание, что исходный код запроса остается прежним. Он был заключен в скобки только из-за сгруппированного кода запроса, что упростило последующую адаптацию этого типа оптимизации к существующему коду.

Тип оптимизации, выполненной здесь, можно рассматривать как форму кэширования, и можно было бы отслеживать альтернативный начальный узел от кадра к кадру, постепенно обновляя его, перемещаясь вверх и вниз по дереву по мере перемещения группы объектов. В следующем разделе кэширование рассматривается как средство оптимизации запросов на конфликты.

## 6.7 Улучшенные запросы через кеширование

Кэширование служит очень важным средством оптимизации запросов о конфликтах. Основная идея очень проста. Отслеживая различную информацию о последнем запросе (или запросах) столкновения, в котором был задействован объект, эту информацию часто можно использовать в последующем запросе, чтобы ускорить его за счет «быстрого запуска» вычислений, благодаря пространственной и временной когерентности объекты имеют тенденцию проявляться.

Кэшируемая информация может быть разделена на два типа: *положительная* (это означает, что она помогает более быстро определить, что два объекта сталкиваются) и *отрицательная* (что означает, что она помогает определить разделение двух объектов). Конкретные фрагменты информации, которые могут помочь быстро решить проблемы, связанные с принятием решения, называются *свидетелями* (witnesses). Есть реализация в решателе столкновений GJK-EPA Натанаэля Прессона, 2008.

Помимо кэширования свидетелей и начальных узлов в иерархиях, кеширование также может использоваться, например, для отслеживания как верхней, так и нижней границ расстояния в качестве помощи для исключения или включения объектов из дальнейшей обработки запроса. Идеи кэширования, представленные в следующих разделах, никоим образом не предназначены для полного охвата, а как средство передачи через несколько примеров того, как можно использовать кеширование.

Для облегчения кэширования полезно связывать идентификационный номер с каждым уникальным запросом. Этот номер может затем служить ключом для хэш-таблицы, в которой хранятся кэшированные данные.

Следует иметь в виду, что перезапуск игры, телепортация объектов, активация или деактивация и подобные события могут потенциально нанести ущерб системе кэширования. Важно, чтобы структуры кеша сбрасывались или делались недействительными всякий раз, когда этого требуют события исключения, такие как вышеизложенное.

### 6.7.1 Кэширование поверхности: кеширование пересекающихся примитивов

Наиболее очевидная схема кэширования - хранить один или несколько перекрывающихся примитивов от каждого объекта, когда обнаруживается, что объекты сталкиваются. Эти примитивы служат свидетелями столкновения. В следующий раз, когда те же два объекта будут проверены на перекрытие, эти кешированные примитивы можно будет сначала протестировать, чтобы увидеть, находятся ли они по-прежнему в конфликте. Если это так, тестовый запрос может немедленно вернуться без необходимости проверки полных иерархий, в худшем случае. Недостатком является то, что этот метод кеширования работает только для тестовых запросов. Если, например, нужны все контакты, ни одна схема кеширования этого типа не сможет дать правильный ответ.

Есть две возможные организации кеширования для хранения хранимых примитивов: общий или распределенный кеш. Общий кеш - это глобальный кеш, содержащий любое количество парных записей. Распределенный кеш - это локальный кеш, в котором примитивы хранятся внутри самих объектов.

Общий кеш обычно реализуется в виде хеш-таблицы, в которой конфликтующие примитивы регистрируются под ключом, созданным из двух идентификаторов объектов (таких как их адреса указателей). Преимущество общего кэша заключается в том, что система легко обрабатывает объект, участвующий в любом количестве конфликтов. Недостатки включают стоимость выполнения поиска в хэш-таблице, чтобы увидеть, существует ли пара, и необходимость удаления пары, когда объекты больше не находятся в конфликте. Последнее может быть довольно сложной проблемой и обычно решается с помощью схемы отложенного обновления, в которой пара удаляется только в случае сбоя следующего запроса. К сожалению, это решение хранит мертвые пары в кеше дольше, чем необходимо, заполняя кеш и потенциально вызывая вырожденное поведение.

Преимущество распределенного кеша в том, что кэшированные примитивы доступны мгновенно. Однако, если для каждого объекта кэшируется только один примитив, контакт с несколькими объектами приведет к преждевременной очистке кеша, что сделает его бесполезным. Например, предположим, что есть три объекта в ряду: A, B и C. A находится в контакте с B, который, в свою очередь, контактирует с C. Когда A и B проверяются впервые, примитив-свидетель из A сохраняется. в A и примитив-свидетель из B в B. Затем B проверяется на соответствие C, и другой примитив-свидетель из B сохраняется в B, сбрасывая ранее сохраненный примитив. При повторном тестировании A и B два кэшированных примитива не конфликтуют, и необходимо выполнить полный проход столкновения [Rundberg99].

Эту проблему можно решить, увеличив количество примитивов, которые можно кэшировать внутри объекта. Однако, если разрешить кэширование n примитивов, теперь необходимо будет выполнить до $n^2$ тестов, чтобы определить, сталкиваются ли объекты. Таким образом, по практическим соображениям n ограничено примерно двумя-шестью примитивами. Общий или глобальный кеш коллизий можно реализовать, как показано в следующем фрагменте кода.

```cpp
    int ObjectsCollidingWithCache(Object a, Object b){
        // Проверить, что эта пара объектов уже находится в кеше
        pair = FindObjectPairInCache(a, b);
        if (pair != NULL){
            // Это так, посмотрите, перекрываются ли кешированные примитивы; 
            // если нет, лениво удалить пару из кеша столкновений
            if (PrimitivesOverlapping(pair->objAPrimitives, pair->ObjBPrimitives))
            return COLLIDING;
            else DeleteObjectPairFromCache(a, b);
        }
        // Выполнить полный запрос на столкновение, который кеширует результат
        return ObjectCollidingCachePrims(Object a, Object b);
    }
```

```cpp
    int ObjectCollidingCachePrims(Object a, Object b){
        if (BVOverlap(a, b)) {
            if (IsLeaf(a) && IsLeaf(b)) {
                if (CollidePrimitives(a, b)) {
                    // Когда обнаруживается, что два объекта сталкиваются, 
                    // добавить пару вместе с примитивами-свидетелями в общий кеш
                    AddObjectPairToCache(a, b);
                    return COLLIDING;
                } else return NOT_COLLIDING;
            } else {
            ...
            }
        }
        ...
    }
```

[Rundberg99] идет дальше, чем просто тестирование кэшированных примитивов. Когда кэшированные примитивы не перекрываются, он утверждает, что существует вероятность того, что их соседние примитивы могут конфликтовать, и приступает к тестированию примитивов вокруг кэшированных примитивов, прежде чем в конечном итоге отказаться от тестирования и начать тестирование из корня. Это, конечно, предполагает представление, в котором соседние примитивы легко доступны. Рундберг сообщает о среднем ускорении с 1,1 до 2,0 без замедления.

### 6.7.2 Переднее отслеживание

Когда две иерархии объектов сравниваются друг с другом, выполняется ряд сравнений узел-узел. Эти пары узлов можно рассматривать как образующие узлы дерева, дерева столкновений. Для информированных и чередующихся правил спуска дерево столкновений является двоичным; для правила одновременного спуска это 4-х арное дерево.

Когда два объекта не сталкиваются, так как обход дерева останавливается, когда пара узел-узел не перекрывается, все внутренние узлы дерева столкновений соответствуют сталкивающимся парам узел-узел, а листья являются парами узел-узел, сначала определяется где не было столкновения.

Следовательно, совокупность этих листовых узлов, образующих так называемую переднюю часть дерева, служит свидетельством несвязанности двух объектов (рисунок 6.9).

Поскольку объекты обычно перемещаются относительно друг друга плавно, можно ожидать, что этот фронт по большей части останется неизменным или просто изменится локально. Следовательно, вместо многократного построения и обхода дерева столкновений от корня, эта согласованность может быть использована путем отслеживания и повторного использования фронта между запросами, постепенно обновляя только те части, которые меняются, если таковые имеются.

**Рисунок 6.9** (а) Иерархия для одного объекта. (б) Иерархия для другого объекта. (c) Дерево столкновений, образованное попеременным обходом. Заштрихованная область указывает фронт, на котором объекты (гипотетически) не сталкиваются.

Следуя Ли и Чену [Li98], предположим, что передняя часть содержит n листовых узлов и что дерево столкновений является двоичным (подразумевая, например, что в качестве правила спуска используется «спуск выше»). В двоичном дереве из $n$ листьев легко показать, что количество внутренних узлов равно $n-1$. Когда передняя часть поддерживается, если передняя часть движется вниз, эти внутренние узлы соответствуют работе, сохраненной при использовании передней части в качестве отправной точки, в отличие от тестирования из корня.

Если передние узлы не перемещаются, что происходит только тогда, когда их родительские узлы остаются в конфликте, по крайней мере, $n/2$ родительских узла должны быть проверены на столкновение. Общее количество проверенных узлов, начиная с лицевой стороны, составляет $n + n/2 = 3n/2$. Опять же, это приводит к экономии по $2n$ узлам, протестированным при переходе от корня.

Когда передние узлы перемещаются вверх, количество проверяемых узлов зависит от того, на сколько уровней они перемещаются. Если они перемещаются только на один уровень, общее количество проверенных узлов будет таким же $n + n/2 + n/4 = 7n/4$. Однако в этом случае обход от корня значительно дешевле, так как проверяется только порядок $n$ узлов, или ровно
$n/2 + (n/2 − 1) = n − 1$.

Учитывая вероятности p_D, p_S и p_U - для узла двигаться вниз, оставаться на том же уровне или двигаться вверх - ожидаемое количество узлов, сохраненных при ведении списка разделения, равно

$$s = p_D n + p_S (2n − 3n/2) + p_U (n − 7n/4)
= p_D n + p_S n/2 − p_U 3n/4.$$

Предположим, что передний узел с одинаковой вероятностью будет двигаться вверх, оставаться на том же уровне или двигаться вниз, то есть $p_D = p_S = p_U = 1/3$. Сохраненное количество узлов тогда просто $s = n/4$, что не так эффективно, как может показаться на первый взгляд.

Ясно, что большая часть затрат на обновление фронта заключается в проверке того, остается ли узел на месте или поднимается в дереве столкновений. Кроме того, чтобы иметь возможность проверять родительские узлы на перекрытие, родительские указатели должны быть сохранены в структуре данных, содержащей переднюю часть.

Здесь Ли и Чен предлагают разумный альтернативный подход. Они просто проверяют размер фронта (измеренный в количестве узлов) от одного запроса к другому. Если размер увеличивается, они предсказывают, что объекты приближаются, и оставляют перед следующим запросом. Если вместо этого размер остается прежним, они предсказывают, что объекты удаляются, и передняя часть строится заново с нуля в следующем запросе. Таким образом, родительские узлы передних узлов никогда не проверяются, что позволяет избежать больших затрат. Анализ, аналогичный предыдущему, дает новую функцию стоимости как

$$s = p_D n + p_S n − p_U 0,$$

которая для $p_D = p_S = p_U = 1/3$ - это $s = 2n/3$, резкое улучшение. Что еще более важно, эта функция неотрицательна для любого распределения вероятностей, и поэтому этот метод никогда не должен работать хуже, чем обход от корня.

Чтобы избежать полной перестройки в нестабильных ситуациях, когда фронт будет двигаться вверх только для немедленного движения вниз, они также предлагают отложить перестройку на один запрос. Фактически, фронт создается заново, если он не увеличивался за два последовательных запроса. Из своих тестов на сферическом дереве Ли и Чен сообщают о среднем ускорении на 40% для основного метода обновления спереди. С отложенным обновлением они достигли среднего ускорения в 84%, что недалеко от оптимального ускорения в 100%. Когда обновление было отложено для нескольких запросов, производительность снизилась.

В целом, поскольку экономия пропорциональна количеству конечных узлов на переднем плане, поддержание фронта более полезно для больших иерархий. Для небольших иерархий, в которых можно пропустить только несколько узлов, накладные расходы, вероятно, превысят любую экономию.

## 6.8 Резюме

Иерархии ограничивающих объемов могут использоваться для ускорения как широкой, так и узкофазной обработки. В качестве универсального метода BVH конструируются для удержания объектов в сцене и для отсеивания групп удаленных объектов (когда объемы, ограничивающие группы, не пересекают ограничивающий объем объекта запроса). Как узкофазный метод, BVH строятся по частям (часто сложного) объекта, что позволяет попарным тестам ограничивать примитивно-примитивные тесты теми частями объектов, ограничивающие объемы которых перекрываются.

В этой главе рассматриваются желаемые характеристики BVH. Также были изучены три класса стратегий построения BVH: методы построения сверху вниз, снизу вверх и на основе вставки. Для нисходящих методов становится важным выполнять последовательное разбиение объектов на подгруппы, и было предложено несколько стратегий разбиения. Также были изучены три типа методов обхода: порядок поиска в ширину, в глубину и в первую очередь. Когда два BVH сравниваются друг с другом, имеет смысл рассмотреть, в каком порядке посещаются поддеревья, и в этом отношении было сформулировано несколько правил спуска.

В конце главы исследуется эффективность древовидных представлений и обходов. К этим темам мы вернемся в главе 13.

# Глава 7
# Пространственное разбиение

## 7.1 Равномерная сетка
### 7.1.1 Проблемы с размером ячейки
### 7.1.2 Сетки как массивы связанных списков
### 7.1.3 Хешированное хранилище и бесконечные сети
### 7.1.4 Хранение статических данных
### 7.1.5 Неявные сетки
### 7.1.6 Объектно-объектный тест Равномерной сетки
#### 7.1.6.1 Один тест за раз
#### 7.1.6.2 Все тесты одновременно
### 7.1.7 Дополнительные соображения по сетке
## 7.2 Иерархические сетки
### 7.2.1 Базовая реализация Hgrid
### 7.2.2 Альтернативные иерархические сеточные представления
### 7.2.3 Другие иерархические сетки
## 7.3 Деревья
### 7.3.1 Октодеревья (и Квадродеревья)
### 7.3.2 Назначение объекта Октодерева
### 7.3.3 Коды местоположения и поиск октанта для точки
### 7.3.4 Линейные октодеревья (на основе хэша)
### 7.3.5 Вычисление ключа Мортона
### 7.3.6 Свободные октодеревья
### 7.3.7 k-d Деревья
### 7.3.8 Гибридные схемы
## 7.4 Обход лучей и отрезков направленных линий
### 7.4.1 k-d Тест на пересечение деревьев
### 7.4.2 Тест на пересечение Равномерной сетки
## 7.5 Методы сортировки и поиска
### 7.5.1 Реализация отсортированного связного списка
### 7.5.2 Сортировка по массивам
## 7.6 Ячейки и порталы
## 7.7 Избегание повторного тестирования
### 7.7.1 Битовые флаги
### 7.7.2 Штамп времени
### 7.7.3 Амортизированная очистка штампов времени
## 7.8 Резюме

# Глава 8
# Иерархии деревьев BSP

## 8.1 BSP Деревья
## 8.2 Типы BSP-деревьев
### 8.2.1 BSP-деревья с хранением узлов
### 8.2.2 Деревья BSP с хранением Листов
### 8.2.3 Деревья BSP с твердыми листьями
## 8.3 Построение BSP-дерева
### 8.3.1 Выбор разделяющих плоскостей
### 8.3.2 Оценка разделяющих плоскостей
### 8.3.3 Классификация полигонов по плоскости
### 8.3.4 Разбиение полигонов на плоскости
### 8.3.5 Подробнее об устойчивости к разбиению полигонов
### 8.3.6 Настройка производительности дерева BSP
## 8.4 Использование BSP Дерева
### 8.4.1 Проверка точки на BSP-дереве с твердыми листьями
### 8.4.2 Пересечение луча с твердолистным деревом BSP
### 8.4.3 Многогранники на деревьях BSP с твердыми листьями
## 8.5 Резюме

# Глава 9
# Основанные на выпуклости методы

## 9.1 Обнаружение столкновений на основе границ
## 9.2 Алгоритмы с Ближайшими особенностями
### 9.2.1 Алгоритм V-Clip
## 9.3 Иерархические представления многогранников
### 9.3.1 Иерархия Добкина–Киркпатрика
## 9.4 Линейное и квадратичное программирование
### 9.4.1 Линейное программирование
#### 9.4.1.1 Устранение Фурье–Моцкина
#### 9.4.1.2 Алгоритм Зейделя
### 9.4.2 Квадратичное программирование
## 9.5 Алгоритм Гилберта–Джонсона–Кирти
### 9.5.1 Алгоритм Гилберта–Джонсона–Кирти
### 9.5.2 Нахождение точки минимальной нормы в симплексе
### 9.5.3 GJK, Ближайшие точки и контактные многообразия
### 9.5.4 Восхождение на холм для экстремальных вершин
### 9.5.5 Использование когерентности с помощью кэширования вершин
### 9.5.6 Оптимизация вращающихся объектов
### 9.5.7 GJK для движущихся объектов
## 9.6 Алгоритм разделяющих векторов Чанга–Ванга
## 9.7 Резюме

# Глава 10 
# Обнаружение столкновений с помощью GPU

Сегодня стандартные графические процессоры (graphics processing units, GPU) имеют больше вычислительной мощности, чем основным CPU. Графические процессоры, работающие в очень ограниченной области, что позволяет распараллеливать задачи рендеринга во многих узкоспециализированных вычислительных единицах с глубоким конвейером. Этот параллелизм дает графическим процессорам общее преимущество в скорости, хотя графические процессоры обычно работают на более низких тактовых частотах, чем процессоры. В сочетании с недавними улучшениями графического процессора, такими как повышенная программируемость вершинных и пиксельных шейдеров и введение текстур с плавающей запятой, вычислительная мощность графических процессоров вызвала большой интерес к отображению не связанных с рендерингом вычислений общего назначения, обычно выполняемых на CPU - на GPU. Для обнаружения столкновений есть два основных способа использования графических процессоров: для быстрых методов пересечения на основе пространства изображений или в качестве сопроцессора для ускорения математических или геометрических вычислений. Методы пересечения, основанные на пространстве изображений, основаны на растрировании объектов запроса коллизии в буферы цвета, глубины или трафарета и на этом определении того, находятся ли объекты в пересечении.

Методы, основанные на разнесении изображений, как правило, легко реализовать, работают с любыми растеризуемыми примитивами (включая, например, патчи Безье и NURBS) и не требуют сложных структур данных коллизий, поскольку они работают непосредственно с геометрией визуализации (и, следовательно, также хорошо справляются с деформируемой нестатической геометрией). Поскольку тестирование выполняется с разрешением буфера (буферов), в котором отображаются объекты, все методы обнаружения столкновений в пространстве изображений являются приблизительными. Поэтому они могут сообщать о столкновении, когда два объекта фактически разделены; например, когда два объекта, разделенных небольшим расстоянием, находятся далеко от плоскости обзора визуализации. Они также могут сообщать об отсутствии столкновений, когда объекты действительно сталкиваются; например, когда объекты настолько малы или находятся так далеко от плоскости обзора, что пиксели не растрируются при визуализации объектов. Эти проблемы можно в значительной степени решить, визуализируя объекты как можно ближе к плоскости обзора (без отсечения) и выбирая направление обзора для максимальной проекции на экране. Как будет обсуждаться ниже, методы, основанные на разнесении изображений, также имеют проблемы с полигонами, расположенными ребром к наблюдателю (в том смысле, что они не растеризованы).

Тщательно упорядочивая данные в текстуры, можно также выполнять универсальные вычисления на графическом процессоре с помощью программируемых пиксельных шейдеров (или даже с помощью операций наложения). Например, статическая треугольная сетка может быть представлена рядом текстур, кодирующих значения компонентов вершин и (неявно) связность вершин и граней. Затем с помощью соответствующей программы пиксельного шейдера можно параллельно выполнить тест пересечения лучей для всех закодированных треугольников. Использование графических процессоров для вычислений общего назначения - новая, очень активная область исследований в настоящее время. Например, [Carr02] и [Purcell02] описать усилия, направленные на ускорение тестов на пересечение лучей и треугольников в области трассировки лучей с использованием графических процессоров.

В этой главе рассматривается, как методы обнаружения столкновений на основе изображений могут использоваться для определения пересечения как выпуклых, так и вогнутых объектов. Также описывается алгоритм фильтрации столкновений в пространстве изображений. Ускорение вычислений с помощью GPU здесь не рассматривается.

## 10.1 Взаимодействие с графическим процессором

Использование графических процессоров в качестве вычислительных устройств - означает, что необходимо решить некоторые практические проблемы. На стороне ввода графического процессора это означает, что данные должны быть упакованы в виде потоков вершин или текстур. Такая упаковка требует осторожности. Более серьезная проблема заключается в перемещении результатов, вычисленных на GPU, обратно в основную память. В большинстве современных систем чтение данных обратно из графического процессора влечет за собой значительное снижение производительности, отчасти вызванное остановками и потерей параллелизма из-за обратного чтения. В некоторых случаях обратное считывание буфера неизбежно, но часто алгоритмы могут быть структурированы так, чтобы избежать этого, с помощью аппаратно поддерживаемых запросов окклюзии. Даже когда требуется обратное считывание из буфера, часто можно ограничить объем считываемых данных за счет тщательного проектирования. В следующих двух разделах более подробно обсуждается обратное чтение буфера, подробно рассказывается о том, как его можно уменьшить или даже полностью избежать.

### 10.1.1 Считывание буфера
### 10.1.2 Запросы окклюзии
## 10.2 Тестирование выпуклых объектов
## 10.3 Тестирование вогнутых объектов
## 10.4 Фильтрация столкновений на основе графического процессора
## 10.5 Резюме

# Глава 11 
# Числовая устойчивость

## 11.1 Типы проблем устойчивости
## 11.2 Представление действительных чисел
### 11.2.1 Форматы с плавающей запятой IEEE-754
### 11.2.2 Бесконечная арифметика
### 11.2.3 Источники ошибок с плавающей точкой
## 11.3 Надежное использование чисел с плавающей запятой
### 11.3.1 Сравнение допусков для значений с плавающей запятой
### 11.3.2 Надежность за счет толстых плоскостей
### 11.3.3 Надежность за счет совместного использования расчетов
### 11.3.4 Надежность толстых предметов
## 11.4 Интервальная арифметика
### 11.4.1 Примеры интервальной арифметики
### 11.4.2 Интервальная арифметика при обнаружении столкновений
## 11.5 Точные и полуточные вычисления
### 11.5.1 Точная арифметика с использованием целых чисел
### 11.5.2 Целочисленное деление
### 11.5.3 Пересечение сегментов с использованием целочисленной арифметики
## 11.6 Дальнейшие предложения по повышению надежности
## 11.7 Резюме

# Глава 12 
# Геометрическая устойчивость

## 12.1 Вершинная сварка
## 12.2 Вычисление информации о смежности
### 12.2.1 Вычисление таблицы Vertex-to-Face
### 12.2.2 Вычисление таблицы Edge-to-Face
### 12.2.3 Проверка связности
## 12.3 Дыры, Трещины, Зазоры и Т-образные переходы 
## 12.4 Объединение копланарных граней
### 12.4.1 Проверка копланарности двух многоугольников
### 12.4.2 Проверка плоскостности многоугольника
## 12.5 Триангуляция и выпуклое разбиение
### 12.5.1 Триангуляция путем разрезания ушей
#### 12.5.1.1 Триангуляция многоугольников с отверстиями
### 12.5.2 Выпуклая декомпозиция многоугольников
### 12.5.3 Выпуклое разложение многогранников
### 12.5.4 Работа с «неразложимой» вогнутой геометрией
## 12.6 Проверка непротиворечивости с использованием формулы Эйлера
## 12.7 Резюме

# Глава 13 
# Оптимизация

## 13.1 Кеши процессора
## 13.2 Оптимизация кэша инструкций
## 13.3 Оптимизация кэша данных
### 13.3.1 Оптимизация структуры
### 13.3.2 Квантованные и сжатые данные вершин
### 13.3.3 Предварительная загрузка
## 13.4 Структуры данных и алгоритмы с учетом кеширования
### 13.4.1 Компактное статическое k-d дерево
### 13.4.2 Компактное дерево AABB
### 13.4.3 Кеширование забывчивости
## 13.5 Программное кеширование
### 13.5.1 Пример кэшированной линеаризации
### 13.5.2 Амортизированное кэширование с предсказательной линеаризацией
## 13.6 Сглаживание
### 13.6.1 Анализ псевдонимов на основе типов
### 13.6.2 Ограниченные указатели
### 13.6.3 Избегание сглаживаний
## 13.7 Ветвление
## 13.8 Резюме


# Рекомендации

- Морозова В.Д. Введение в анализ.
- Иванова Е.Е. Дифференциальное исчисление функций одного переменного
- Канатников А.Н., Крищенко А.П. Аналитическая геометрия
- Канатников А.Н., Крищенко А.П. Линейная алгебра
- Канатников А.Н., Крищенко А.П., Четвериков В.Н. Дифференциальное исчисление функций - многих переменных
- Зарубин B.C., Иванова Е.Е., Кувыркин Г.Н. Интегральное исчисление функций одного переменного
- Гаврилов В.Р., Иванова Б.Б., Морозова В.Д. Кратные и криволинейные интегралы. Элементы теории поля
- Агафонов С.А., Герман А.Д., Муратова Т.В. Дифференциальные уравнения
- Власова Е.А. Ряды
- Морозова В.Д. Теория функций комплексного переменного
- Волков И.К., Канатников А.Н. Интегральные преобразования и операционное исчисление
- Мартинсон Л.К., Малов Ю.И. Дифференциальные уравнения математической физики
- Власова Е.А., Зарубин B.C., Кувыркин Г.Н. Приближенные методы математической физики
- Аттетков А.В., Галкин С.В., Зарубин B.C. Методы оптимизации
- Ванько В.И., Ермошина О.В., Кувыркин Г.Н. Вариационное исчисление и оптимальное управление
- Печинкин А.В., Тескин О.И., Цветкова Г.М. и др. Теория вероятностей
- Горяинов В.Б., Павлов И.В., Цветкова Г.М. и др. Математическая статистика
- Волков И.К., Зуев С.М., Цветкова Г.М. Случайные процессы
- Белоусов А.И., Ткачев С.Б. Дискретная математика
- Волков И.К., Загоруйко Е.А. Исследование операций
- Зарубин B.C. Математическое моделирование в технике
# Ресурсы
- [Detexify](http://detexify.kirelabs.org/classify.html)
# Индекс
# О коде
