<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 230 - Глубокое обучение Tips and Tricks Cheatsheet</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport>
<link href=https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-230 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 15px;">   <b>CS 230 - Глубокое обучение</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Tips and tricks</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#data-processing>Обработка данных</a></div> <div class=dropdown-container> <a href=#data-processing><span>Увеличение данных</span></a> <a href=#data-processing><span>Пакетная нормировка</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#running-nn>Обучение нейронной сети</a></div> <div class=dropdown-container> <a href=#running-nn><span>Эпоха</span></a> <a href=#running-nn><span>Мини-пакет</span></a> <a href=#running-nn><span>Функция потерь на основе перекрестной энтропии</span></a> <a href=#running-nn><span>Обратное распространение ошибки</span></a> <a href=#running-nn><span>Градиентный спуск</span></a> <a href=#running-nn><span>Обновление весов</span></a> <a href=#running-nn><span>Проверка градиента</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#parameter-tuning>Настройка параметров</a></div> <div class=dropdown-container> <a href=#parameter-tuning><span>Инициализация Ксавье</span></a> <a href=#parameter-tuning><span>Трансферное обучение</span></a> <a href=#parameter-tuning><span>Скорость обучения</span></a> <a href=#parameter-tuning><span>Адаптивная скорость обучения</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#regularization>Регуляризация</a></div> <div class=dropdown-container> <a href=#regularization><span>Прореживание</span></a> <a href=#regularization><span>Регуляризация веса</span></a> <a href=#regularization><span>Ранняя остановка</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#good-practices>Хорошие практики</a></div> <div class=dropdown-container> <a href=#good-practices><span>Переобучение на небольших пакетах</span></a> <a href=#good-practices><span>Проверка градиента</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/cheatsheet-deep-learning-tips-tricks.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> Посмотреть PDF-версию на GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE --><a aria-hidden=true class=anchor-bis href=#cs-230---deep-learning id=cs-230---deep-learning></a><a href=teaching/cs-230 onclick=trackOutboundLink(this);>CS 230 - Глубокое обучение</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option selected value=en>English</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ja>日本語</option>
        <option value=ko>한국어</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>CS 221 - Artificial Intelligence</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>CS 229 - Machine Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button><B>CS 230 - Глубокое обучение</B></BUTTON>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button>Convolutional Neural Networks</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/recurrent-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-recurrent-neural-networks'" type=button>Recurrent Neural Networks</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/deep-learning-tips-and-tricks/index.html'; oldhref='teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks'" type=button><B>Tips and tricks</B></BUTTON>
  </div>
</div>

<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Шпаргалка с советами и приемами глубокого обучения
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-230-deep-learning on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-230-deep-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i><!-- By --><a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> и <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a>;<a href=https://github.com/AlexandrParkhomenko onclick=trackOutboundLink(this);> Alexandr Parkhomenko</a> и <a href=https://github.com/geotrush onclick=trackOutboundLink(this);>Труш Георгий (Georgy Trush)</a></i>
<h2><a aria-hidden=true class=anchor href=#data-processing id=data-processing></a>Обработка данных</h2>
<p><span class="new-item item-r">Увеличение данных (augmentation)</span> Для правильного обучения моделям глубокого обучения обычно требуется много данных. Часто бывает полезно получить больше данных из существующих, используя методы увеличения данных. Основные из них приведены в таблице ниже. Точнее, с учетом следующего входного изображения, вот методы, которые мы можем применить:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:500px;">
<colgroup>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Оригинал</b></td>
<td align=center><b>Отражение</b></td>
<td align=center><b>Поворот</b></td>
<td align=center><b>Случайное кадрирование</b></td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-original.jpg?fa9abcd4dce13c776d7d10b3a1ec8fad></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-flip.jpg?da4ff42b5d8fc1f2759675e0c6323f8e></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-rotation.jpg?ab180edcbeb006bfbad4fd57aa6433bf></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-crop.jpg?811ab0236837a5eb3106e761b6046424></td>
</tr>
<tr>
<td align=left valign=top>• Изображение без изменений</td>
<td align=left valign=top>• Отражение изображения относительно оси</td>
<td align=left valign=top>• Вращение с небольшим углом<br>
                 • Имитирует неправильную калибровку горизонта</td>
<td align=left valign=top>• Случайный фокус на одной части изображения<br>
                              • Можно сделать несколько случайных обрезок подряд</td>
</tr>
</tbody>
</table>
</center>
</div>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:500px;">
<colgroup>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Сдвиг цвета</b></td>
<td align=center><b>Добавление шума</b></td>
<td align=center><b>Потеря информации</b></td>
<td align=center><b>Изменение контраста</b></td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-shift.jpg?fca805477d241c88166819240ab65ba4></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-noise.jpg?f56920da7d2d08d1041f1b01b92df1f8></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-information-loss.jpg?8563bbe135ffcbe57b9b8529dd80fcb9></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-contrast.jpg?776cd26f62f336949ee237817f6af3a5></td>
</tr>
<tr>
<td align=left valign=top>• Немного изменены нюансы RGB<br>
                 • Получает возникающий при изменении освещения шум
</td>
<td align=left valign=top>• Добавление шума<br>
                 • Толерантнее к качеству изображения
</td>
<td align=left valign=top>• Части изображения игнорируются<br>
                              • Имитирует потенциальную потерю частей изображения</td>
<td align=left valign=top>• Изменяется яркость<br>
                              • Контролирует разницу в экспозиции в зависимости от времени суток</td>
</tr>
</tbody>
</table>
</center>
</div>
<p><span class=remark>Примечание: данные обычно пополняются на лету во время обучения.</span></p>
<br>
<p><span class="new-item item-b">Пакетная нормировка</span> метод адаптивной перепараметризации $\gamma, \beta$, который нормирует пакет $\{x_i\}$. Обозначим $\mu_B, \sigma_B^2$ как среднее значение и дисперсию, которые мы хотим скорректировать для пакета, это делается следующим образом:
</p><div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
Обычно это делается после полносвязного/сверточного слоя и до уровня нелинейности и направлено на повышение скорости обучения и уменьшение сильной зависимости от инициализации.<p></p>
<br>
<h2><a aria-hidden=true class=anchor href=#running-nn id=running-nn></a>Обучение нейронной сети</h2>
<h3>Определения</h3>
<p><span class="new-item item-b">Эпоха</span> в контексте обучения модели эпоха - это термин, используемый для обозначения одной итерации, когда модель видит весь обучающий набор для обновления своих весов.</p>
<br>
<p><span class="new-item item-r">Мини-пакетный градиентный спуск</span> на этапе обучения обновление весов обычно не основывается ни на всем обучающем наборе сразу (из-за сложности вычислений), ни на единственной точке данных (из-за проблем с шумом). Вместо этого этап обновления выполняется для мини-пакетов, где количество точек данных в пакете является гиперпараметром, который мы можем настроить.</p>
<br>
<p><span class="new-item item-b">Функция потерь</span> В целях количественного измерения работы конкретной модели зачастую используется функция потерь $L$ для оценки того, в какой степени фактические выходные данные $y$ правильно предсказываются выходными данными модели $z$.</p>
<br>
<p><span class="new-item item-b">Функция потерь на основе перекрестной энтропии</span> В контексте бинарной классификации в нейронных сетях обычно используется потеря кросс-энтропии $L(z,y)$, которая определяется следующим образом:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<h3>Поиск оптимальных весов</h3>
<p><span class="new-item item-b">Обратное распространение ошибки</span> это метод обновления весов в нейронной сети с учетом фактического и желаемого выходных данных. Производная по каждому весу $w$ вычисляется с использованием цепного правила.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=backpropagation-ltr.png?7ab0719a4825260ef208d87cdd195b9f style="width:100%; max-width: 500px;">
</center>
</div>
<br>
<p>Используя этот метод, каждый вес обновляется с помощью правила:</p>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<p><span class="new-item item-g">Обновление весов</span> В нейронной сети веса обновляются следующим образом:</p>
<p>• Шаг 1: Для пакета обучающих данных Выполнить прямое распространение и получить соответствующие значения функции стоимости.
<br>• Шаг 2: Выполнить обратное распространение ошибки и получить градиенты по каждому весу.
<br>• Шаг 3: Использовать градиенты и обновить веса сети.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=update-weights-en.png?5394a7bb976892418366d08646a0fd09 style="width:100%; min-width: 500px;">
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#parameter-tuning id=parameter-tuning></a>Настройка параметров</h2>
<h3>Инициализация весов</h3>
<p><span class="new-item item-b">Метод инициализации Ксавье (Xavier)</span> вместо того, чтобы инициализировать веса чисто случайным образом, инициализация Ксавье позволяет иметь начальные веса, которые учитывают характеристики, уникальные для архитектуры.</p>
<br>
<p><span class="new-item item-r">Трансферное обучение</span> для обучения модели глубокого обучения требуется много данных и, что ещё более важно, много времени. Часто бывает полезно воспользоваться предварительно обученными весами для огромных наборов данных, обучение которых занимало дни/недели, и использовать их в нашем случае использования. В зависимости от того, сколько данных у нас под рукой, есть несколько способов использовать это:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=18%>
<col width=52%>
<col width=30%>
</colgroup><tbody>
<tr>
<td align=center><b>Размер тренировки</b></td>
<td align=center><b>Иллюстрация</b></td>
<td align=center><b>Пояснение</b></td>
</tr>
<tr>
<td align=center>Маленький</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=transfer-learning-small-ltr.png?bee5e73de8fb2c6297a3a88804fabf5e></td>
<td align=left>Замораживает все слои, тренирует веса на softmax</td>
</tr>
<tr>
<td align=center>Средний</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=transfer-learning-medium-ltr.png?650eae780cff79a9ff0123d62e5812ad></td>
<td align=left>Замораживает большинство слоев, тренирует веса на последних слоях и softmax</td>
</tr>
<tr>
<td align=center>Большой</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=transfer-learning-large-ltr.png?ccdc27259583a57319e0bc39f5d858df></td>
<td align=left>Тренирует веса на слоях и softmax инициализирует веса на предварительно обученных</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>Оптимизация сходимости</h3>
<p><span class="new-item item-b">Скорость обучения</span> Скорость обучения, часто обозначаемая $\alpha$ или иногда $\eta$, указывает, с какой скоростью обновляются веса. Её можно исправить или адаптивно изменить. Самый популярный в настоящее время метод называется Адам, он адаптирует скорость обучения.</p>
<br>
<p><span class="new-item item-g">Адаптивная скорость обучения</span> Изменение скорости обучения при обучении модели может сократить время обучения и улучшить численное оптимальное решение. Хотя оптимизатор Адама является наиболее часто используемым методом, другие также могут быть полезны. Они приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:660px;">
<colgroup>
<col style=width:110px>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Метод</b></td>
<td align=center><b>Пояснение</b></td>
<td align=center><b>Update of $w$</b></td>
<td align=center><b>Update of $b$</b></td>
</tr>
<tr>
<td align=center>Momentum</td>
<td align=left>• Гасит колебания<br>
                 • Улучшение SGD<br>
                 • 2 параметра для настройки</td>
<td align=center>$\displaystyle w-\alpha v_{dw}$</td>
<td align=center>$\displaystyle b-\alpha v_{db}$</td>
</tr>
<tr>
<td align=center>RMSprop</td>
<td align=left>• Среднеквадратичное распространение<br>
                 • Ускоряет алгоритм обучения за счет управления колебаниями</td>
<td align=center>$\displaystyle w-\alpha\frac{dw}{\sqrt{s_{dw}}}$</td>
<td align=center>$\displaystyle b\longleftarrow b-\alpha\frac{db}{\sqrt{s_{db}}}$</td>
</tr>
<tr>
<td align=center>Adam</td>
<td align=left>• Оценка адаптивного момента<br>
                 • Самый популярный метод<br>
                 • 4 параметра для настройки</td>
<td align=center>$\displaystyle w-\alpha\frac{v_{dw}}{\sqrt{s_{dw}}+\epsilon}$</td>
<td align=center>$\displaystyle b\longleftarrow b-\alpha\frac{v_{db}}{\sqrt{s_{db}}+\epsilon}$</td>
</tr>
</tbody>
</table>
</center>
</div>
<p><span class=remark>Примечание: другие методы включают Adadelta, Adagrad и SGD.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#regularization id=regularization></a>Регуляризация</h2>
<p><span class="new-item item-r">Прореживание</span> Dropout - это метод, используемый в нейронных сетях для предотвращения переобучения обучающих данных путем выпадения нейронов с вероятностью $p &gt;0$. Это заставляет модель не слишком полагаться на определенные наборы функций.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=dropout-ltr.png?27ab877c24a915d22e598fb772fcdc96 style="width:100%; max-width: 500px;">
</center>
</div>
<p><span class=remark>Примечание: большинство фреймворков глубокого обучения параметризуют исключение с помощью параметра 'keep' $1-p$.</span></p>
<br>
<p><span class="new-item item-r">Регуляризация весов</span> Чтобы убедиться, что веса не слишком велики и что модель не переобучается на обучающей выборке, обычно выполняются методы регуляризации для весов модели. Основные из них приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:760px;">
  <colgroup>
    <col style=width:33%>
    <col style=width:33%>
    <col style=width:33%>
  </colgroup>
<tbody>
<tr>
<td align=center><b>LASSO</b></td>
<td align=center><b>Ridge</b></td>
<td align=center><b>Elastic Net</b></td>
</tr>
<tr>
<td align=left>• Уменьшает коэффициенты до 0<br>• Подходит для выбора переменных</td>
<td align=left>Делает коэффициенты меньше</td>
<td align=left>Компромисс между выбором переменных и небольшими коэффициентами</td>
</tr>
<tr>
<td align=center><img alt=Lasso class=img-responsive netsrc=teaching/cs-229/illustrations/ src=lasso.png?ad67282f00fc8b2a529e5b15a856f91b></td>
<td align=center><img alt=Ridge class=img-responsive netsrc=teaching/cs-229/illustrations/ src=ridge.png?77abafe4253433af93fb8ffc7d4f6bc7></td>
<td align=center><img alt="Elastic Net" class=img-responsive netsrc=teaching/cs-229/illustrations/ src=elastic-net.png?8cd93eb9df1b6ae667d8eb69d20bf4a1></td>
</tr>
<tr>
<td align=left>$...+\lambda||\theta||_1$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda||\theta||_2^2$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$<br>$\lambda\in\mathbb{R},\alpha\in[0,1]$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Ранняя остановка</span> Этот метод регуляризации останавливает процесс обучения, как только потеря валидации достигает плато или начинает увеличиваться.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=early-stopping-en.png?a8aacdfe0c39776d86764857222e19dd style="width:100%; max-width: 500px;">
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#good-practices id=good-practices></a>Хорошие практики</h2>
<p><span class="new-item item-g">Переобучение на небольших пакетах</span> При отладке модели часто бывает полезно провести быстрые тесты, чтобы увидеть, есть ли какие-либо серьезные проблемы с архитектурой самой модели. В частности, чтобы убедиться, что модель должным образом обучена, на вход сети передается мини-пакет, чтобы увидеть, случится ли на нем переобучение. В случае если этого не происходит, это означает, что модель либо слишком сложна, либо недостаточно сложна, чтобы даже переобучиться на небольшой партии, не говоря уже об обучающем наборе нормального размера.</p>
<br>
<p><span class="new-item item-r">Проверка градиента</span> это метод, используемый во время реализации обратного прохода нейронной сети. Он сравнивает значение аналитического градиента с числовым градиентом в заданных точках и играет роль проверки реализации на корректность.</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:650px; max-width:900px;">
<colgroup>
<col style=width:110px>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Тип</b></td>
<td align=center><b>Числовой градиент</b></td>
<td align=center><b>Аналитический градиент</b></td>
</tr>
<tr>
<td align=center>Формула</td>
<td align=center>$\displaystyle\frac{df}{dx}(x) \approx \frac{f(x+h) - f(x-h)}{2h}$</td>
<td align=center>$\displaystyle\frac{df}{dx}(x) = f'(x)$</td>
</tr>
<tr>
<td align=center>Комментарии</td>
<td align=left valign=top>• Дорого; потери должны вычисляться два раза для каждого измерения<br>
                              • Используется для проверки правильности аналитической реализации<br>
                              • Компромисс при выборе $h$ не слишком малого (числовая нестабильность), но и не слишком большого (плохое приближение градиента)</td>
<td align=left valign=top>• 'Точный' результат<br>
                              • Прямое вычисление<br>
                              • Используемое в окончательной реализации</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>