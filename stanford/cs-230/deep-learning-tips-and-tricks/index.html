<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 230 - Глубокое обучение Tips and Tricks Cheatsheet</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport>
<link href=https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-230 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 15px;">   <b>CS 230 - Глубокое обучение</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Tips and tricks</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#data-processing>Обработка данных</a></div> <div class=dropdown-container> <a href=#data-processing><span>Увеличение данных</span></a> <a href=#data-processing><span>Пакетная нормировка</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#running-nn>Обучение нейронной сети</a></div> <div class=dropdown-container> <a href=#running-nn><span>Эпоха</span></a> <a href=#running-nn><span>Мини-пакет</span></a> <a href=#running-nn><span>Функция потерь на основе перекрестной энтропии</span></a> <a href=#running-nn><span>Обратное распространение</span></a> <a href=#running-nn><span>Градиентный спуск</span></a> <a href=#running-nn><span>Обновление весов</span></a> <a href=#running-nn><span>Проверка градиента</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#parameter-tuning>Настройка параметров</a></div> <div class=dropdown-container> <a href=#parameter-tuning><span>Инициализация Xavier</span></a> <a href=#parameter-tuning><span>Трансферное обучение</span></a> <a href=#parameter-tuning><span>Скорость обучения</span></a> <a href=#parameter-tuning><span>Адаптивная скорость обучения</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#regularization>Регуляризация</a></div> <div class=dropdown-container> <a href=#regularization><span>Прореживание</span></a> <a href=#regularization><span>Регуляризация веса</span></a> <a href=#regularization><span>Ранняя остановка</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#good-practices>Хорошие практики</a></div> <div class=dropdown-container> <a href=#good-practices><span>Переобучение на небольших пакетах</span></a> <a href=#good-practices><span>Проверка градиента</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/cheatsheet-deep-learning-tips-tricks.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> Посмотреть PDF-версию на GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE --><a aria-hidden=true class=anchor-bis href=#cs-230---deep-learning id=cs-230---deep-learning></a><a href=teaching/cs-230 onclick=trackOutboundLink(this);>CS 230 - Глубокое обучение</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option selected value=en>English</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ja>日本語</option>
        <option value=ko>한국어</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>CS 221 - Artificial Intelligence</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>CS 229 - Machine Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button><B>CS 230 - Глубокое обучение</B></BUTTON>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button>Convolutional Neural Networks</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/recurrent-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-recurrent-neural-networks'" type=button>Recurrent Neural Networks</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/deep-learning-tips-and-tricks/index.html'; oldhref='teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks'" type=button><B>Tips and tricks</B></BUTTON>
  </div>
</div>

<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Шпаргалка с советами и приемами глубокого обучения
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-230-deep-learning on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-230-deep-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></i>
<h2><a aria-hidden=true class=anchor href=#data-processing id=data-processing></a>Обработка данных</h2>
<p><span class="new-item item-r">Увеличение данных (augmentation)</span> Для правильного обучения моделям глубокого обучения обычно требуется много данных. Часто бывает полезно получить больше данных из существующих, используя методы увеличения данных. Основные из них приведены в таблице ниже. Точнее, с учетом следующего входного изображения, вот методы, которые мы можем применить:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:500px;">
<colgroup>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Оригинал</b></td>
<td align=center><b>Отражение</b></td>
<td align=center><b>Поворот</b></td>
<td align=center><b>Случайное кадрирование</b></td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-original.jpg?fa9abcd4dce13c776d7d10b3a1ec8fad></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-flip.jpg?da4ff42b5d8fc1f2759675e0c6323f8e></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-rotation.jpg?ab180edcbeb006bfbad4fd57aa6433bf></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-crop.jpg?811ab0236837a5eb3106e761b6046424></td>
</tr>
<tr>
<td align=left valign=top>• Изображение без изменений</td>
<td align=left valign=top>• Отражение изображения относительно оси</td>
<td align=left valign=top>• Вращение с небольшим углом<br>
                 • Имитирует неправильную калибровку горизонта</td>
<td align=left valign=top>• Случайный фокус на одной части изображения<br>
                              • Можно сделать несколько случайных обрезок подряд</td>
</tr>
</tbody>
</table>
</center>
</div>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:500px;">
<colgroup>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
<col style=width:25%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Сдвиг цвета</b></td>
<td align=center><b>Добавление шума</b></td>
<td align=center><b>Потеря информации</b></td>
<td align=center><b>Изменение контраста</b></td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-shift.jpg?fca805477d241c88166819240ab65ba4></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-noise.jpg?f56920da7d2d08d1041f1b01b92df1f8></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-information-loss.jpg?8563bbe135ffcbe57b9b8529dd80fcb9></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=augmentation-contrast.jpg?776cd26f62f336949ee237817f6af3a5></td>
</tr>
<tr>
<td align=left valign=top>• Немного изменены нюансы RGB<br>
                 • Получает возникающий при изменении освещения шум
</td>
<td align=left valign=top>• Добавление шума<br>
                 • Толерантнее к качеству изображения
</td>
<td align=left valign=top>• Части изображения игнорируются<br>
                              • Имитирует потенциальную потерю частей изображения</td>
<td align=left valign=top>• Изменяется яркость<br>
                              • Контролирует разницу в экспозиции в зависимости от времени суток</td>
</tr>
</tbody>
</table>
</center>
</div>
<p><span class=remark>Примечание: данные обычно пополняются на лету во время обучения.</span></p>
<br>
<p><span class="new-item item-b">Batch normalization</span> It is a step of hyperparameter $\gamma, \beta$ that normalizes the batch $\{x_i\}$. By noting $\mu_B, \sigma_B^2$ the mean and variance of that we want to correct to the batch, it is done as follows:
</p><div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
Обычно это делается после полносвязного/сверточного слоя и до уровня нелинейности и направлено на повышение скорости обучения и уменьшение сильной зависимости от инициализации.<p></p>
<br>
<h2><a aria-hidden=true class=anchor href=#running-nn id=running-nn></a>Обучение нейронной сети</h2>
<h3>Определения</h3>
<p><span class="new-item item-b">Эпоха</span> в контексте обучения модели эпоха - это термин, используемый для обозначения одной итерации, когда модель видит весь обучающий набор для обновления своих весов.</p>
<br>
<p><span class="new-item item-r">Мини-пакетный градиентный спуск</span> на этапе обучения обновление весов обычно не основывается на всем обучающем наборе сразу из-за сложности вычислений или одной точки данных из-за проблем с шумом. Вместо этого этап обновления выполняется для мини-пакетов, где количество точек данных в пакете является гиперпараметром, который мы можем настроить.</p>
<br>
<p><span class="new-item item-b">Loss function</span> In order to quantify how a given model performs, the loss function $L$ is usually used to evaluate to what extent the actual outputs $y$ are correctly predicted by the model outputs $z$.</p>
<br>
<p><span class="new-item item-b">Cross-entropy loss</span> In the context of binary classification in neural networks, the cross-entropy loss $L(z,y)$ is commonly used and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<h3>Поиск оптимальных весов</h3>
<p><span class="new-item item-b">Обратное распространение</span> это метод обновления весов в нейронной сети с учетом фактического и желаемого выходных данных. Производная по каждому весу $w$ вычисляется с использованием цепного правила.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=backpropagation-ltr.png?7ab0719a4825260ef208d87cdd195b9f style="width:100%; max-width: 500px;">
</center>
</div>
<br>
<p>Используя этот метод, каждый вес обновляется с помощью правила:</p>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<p><span class="new-item item-g">Обновление весов</span> В нейронной сети веса обновляются следующим образом:</p>
<p>• Шаг 1: Для пакета обучающих данных Выполнить прямое распространение и получить соответствующие значения функции стоимости.
<br>• Шаг 2: Выполнить обратное распространение ошибки и получить градиенты по каждому весу.
<br>• Шаг 3: Использовать градиенты и обновить веса сети.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=update-weights-en.png?5394a7bb976892418366d08646a0fd09 style="width:100%; min-width: 500px;">
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#parameter-tuning id=parameter-tuning></a>Настройка параметров</h2>
<h3>Инициализация весов</h3>
<p><span class="new-item item-b">Метод инициализации Завьера (Xavier)</span> вместо того, чтобы инициализировать веса чисто случайным образом, инициализация Xavier позволяет иметь начальные веса, которые учитывают характеристики, уникальные для архитектуры.</p>
<br>
<p><span class="new-item item-r">Трансферное обучение</span> для обучения модели глубокого обучения требуется много данных и, что ещё более важно, много времени. Часто бывает полезно воспользоваться предварительно обученными весами для огромных наборов данных, обучение которых занимало дни/недели, и использовать их в нашем случае использования. В зависимости от того, сколько данных у нас под рукой, есть несколько способов использовать это:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=18%>
<col width=52%>
<col width=30%>
</colgroup><tbody>
<tr>
<td align=center><b>Размер тренировки</b></td>
<td align=center><b>Иллюстрация</b></td>
<td align=center><b>Пояснение</b></td>
</tr>
<tr>
<td align=center>Маленький</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=transfer-learning-small-ltr.png?bee5e73de8fb2c6297a3a88804fabf5e></td>
<td align=left>Freezes all layers, тренирует веса на softmax</td>
</tr>
<tr>
<td align=center>Средний</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=transfer-learning-medium-ltr.png?650eae780cff79a9ff0123d62e5812ad></td>
<td align=left>Freezes most layers, тренирует веса на последних слоях и softmax</td>
</tr>
<tr>
<td align=center>Большой</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=transfer-learning-large-ltr.png?ccdc27259583a57319e0bc39f5d858df></td>
<td align=left>Тренирует веса на слоях и softmax инициализирует веса на предварительно обученных</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3>Оптимизация сходимости</h3>
<p><span class="new-item item-b">Learning rate</span> The learning rate, often noted $\alpha$ or sometimes $\eta$, indicates at which pace the weights get updated. It can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate.</p>
<br>
<p><span class="new-item item-g">Адаптивная скорость обучения</span> Изменение скорости обучения при обучении модели может сократить время обучения и улучшить численное оптимальное решение. Хотя оптимизатор Адама является наиболее часто используемым методом, другие также могут быть полезны. Они приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:660px;">
<colgroup>
<col style=width:110px>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Метод</b></td>
<td align=center><b>Пояснение</b></td>
<td align=center><b>Update of $w$</b></td>
<td align=center><b>Update of $b$</b></td>
</tr>
<tr>
<td align=center>Momentum</td>
<td align=left>• Гасит колебания<br>
                 • Улучшение SGD<br>
                 • 2 параметра для настройки</td>
<td align=center>$\displaystyle w-\alpha v_{dw}$</td>
<td align=center>$\displaystyle b-\alpha v_{db}$</td>
</tr>
<tr>
<td align=center>RMSprop</td>
<td align=left>• Среднеквадратичное распространение<br>
                 • Ускоряет алгоритм обучения за счет управления колебаниями</td>
<td align=center>$\displaystyle w-\alpha\frac{dw}{\sqrt{s_{dw}}}$</td>
<td align=center>$\displaystyle b\longleftarrow b-\alpha\frac{db}{\sqrt{s_{db}}}$</td>
</tr>
<tr>
<td align=center>Adam</td>
<td align=left>• Оценка адаптивного момента<br>
                 • Самый популярный метод<br>
                 • 4 параметра для настройки</td>
<td align=center>$\displaystyle w-\alpha\frac{v_{dw}}{\sqrt{s_{dw}}+\epsilon}$</td>
<td align=center>$\displaystyle b\longleftarrow b-\alpha\frac{v_{db}}{\sqrt{s_{db}}+\epsilon}$</td>
</tr>
</tbody>
</table>
</center>
</div>
<p><span class=remark>Примечание: другие методы включают Adadelta, Adagrad и SGD.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#regularization id=regularization></a>Регуляризация</h2>
<p><span class="new-item item-r">Dropout</span> Dropout is a technique used in neural networks to prevent overfitting the training data by dropping out neurons with probability $p &gt;0$. It forces the model to avoid relying too much on particular sets of features.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=dropout-ltr.png?27ab877c24a915d22e598fb772fcdc96 style="width:100%; max-width: 500px;">
</center>
</div>
<p><span class=remark>Remark: most deep learning frameworks parametrize dropout through the 'keep' parameter $1-p$.</span></p>
<br>
<p><span class="new-item item-r">Регуляризация веса</span> Чтобы убедиться, что веса не слишком велики и что модель не переобучается на обучающей выборке, обычно выполняются методы регуляризации для весов модели. Основные из них приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:760px;">
  <colgroup>
    <col style=width:33%>
    <col style=width:33%>
    <col style=width:33%>
  </colgroup>
<tbody>
<tr>
<td align=center><b>LASSO</b></td>
<td align=center><b>Ridge</b></td>
<td align=center><b>Elastic Net</b></td>
</tr>
<tr>
<td align=left>• Уменьшает коэффициенты до 0<br>• Подходит для выбора переменных</td>
<td align=left>Делает коэффициенты меньше</td>
<td align=left>Компромисс между выбором переменных и небольшими коэффициентами</td>
</tr>
<tr>
<td align=center><img alt=Lasso class=img-responsive netsrc=teaching/cs-229/illustrations/ src=lasso.png?ad67282f00fc8b2a529e5b15a856f91b></td>
<td align=center><img alt=Ridge class=img-responsive netsrc=teaching/cs-229/illustrations/ src=ridge.png?77abafe4253433af93fb8ffc7d4f6bc7></td>
<td align=center><img alt="Elastic Net" class=img-responsive netsrc=teaching/cs-229/illustrations/ src=elastic-net.png?8cd93eb9df1b6ae667d8eb69d20bf4a1></td>
</tr>
<tr>
<td align=left>$...+\lambda||\theta||_1$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda||\theta||_2^2$<br>$\lambda\in\mathbb{R}$</td>
<td align=left>$...+\lambda\Big[(1-\alpha)||\theta||_1+\alpha||\theta||_2^2\Big]$<br>$\lambda\in\mathbb{R},\alpha\in[0,1]$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Ранняя остановка</span> Этот метод регуляризации останавливает процесс обучения, как только потеря валидации достигает плато или начинает увеличиваться.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=early-stopping-en.png?a8aacdfe0c39776d86764857222e19dd style="width:100%; max-width: 500px;">
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#good-practices id=good-practices></a>Хорошие практики</h2>
<p><span class="new-item item-g">Переобучение на небольших пакетах</span> При отладке модели часто бывает полезно провести быстрые тесты, чтобы увидеть, есть ли какие-либо серьезные проблемы с архитектурой самой модели. В частности, чтобы убедиться, что модель может быть должным образом обучена, внутри сети передается мини-пакет, чтобы увидеть, может ли он переобучиться. Если это невозможно, это означает, что модель либо слишком сложна, либо недостаточно сложна, чтобы даже переобучиться на небольшой партии, не говоря уже об обучающем наборе нормального размера.</p>
<br>
<p><span class="new-item item-r">Проверка градиента</span> это метод, используемый во время реализации обратного прохода нейронной сети. Он сравнивает значение аналитического градиента с числовым градиентом в заданных точках и играет роль проверки правильности.</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:650px; max-width:900px;">
<colgroup>
<col style=width:110px>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Тип</b></td>
<td align=center><b>Числовой градиент</b></td>
<td align=center><b>Аналитический градиент</b></td>
</tr>
<tr>
<td align=center>Формула</td>
<td align=center>$\displaystyle\frac{df}{dx}(x) \approx \frac{f(x+h) - f(x-h)}{2h}$</td>
<td align=center>$\displaystyle\frac{df}{dx}(x) = f'(x)$</td>
</tr>
<tr>
<td align=center>Комментарии</td>
<td align=left valign=top>• Дорого; потери должны вычисляться два раза для каждого измерения<br>
                              • Используется для проверки правильности аналитической реализации<br>
                              • Компромисс при выборе $h$ не слишком малого (числовая нестабильность) или слишком большого (плохое приближение градиента)</td>
<td align=left valign=top>• 'Точный' результат<br>
                              • Прямое вычисление<br>
                              • Используемое в окончательной реализации</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>