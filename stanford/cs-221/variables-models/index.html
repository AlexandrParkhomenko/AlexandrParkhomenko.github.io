<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 221 - Variables-based Models Cheatsheet</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport><link href=https://stanford.edu/~shervine/teaching/cs-221/cheatsheet-variables-models rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-221 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 12px;">   <b>CS 221 - Artificial Intelligence</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Variables-based models</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#factor-graphs>Факторные графы</a></div> <div class=dropdown-container> <a href=#factor-graphs><span>Арность</span></a> <a href=#factor-graphs><span>Вес присвоения</span></a> <a href=#factor-graphs><span>Задачи удовлетворения ограничений</span></a> <a href=#factor-graphs><span>Непротиворечивое присвоение</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#dynamic-ordering>Динамическое упорядочивание</a></div> <div class=dropdown-container> <a href=#dynamic-ordering><span>Зависимые факторы</span></a> <a href=#dynamic-ordering><span>Поиск с возвратом</span></a> <a href=#dynamic-ordering><span>Прямая проверка</span></a> <a href=#dynamic-ordering><span>Наиболее ограниченная переменная</span></a> <a href=#dynamic-ordering><span>Наименьшее ограниченное значение</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#approximate-methods>Аппроксимационные методы</a></div> <div class=dropdown-container> <a href=#approximate-methods><span>Лучевой поиск</span></a> <a href=#approximate-methods><span>Итерированные условные режимы</span></a> <a href=#approximate-methods><span>выборка по Гиббсу</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#factor-graph-transformations>Преобразования факторных графов</a></div> <div class=dropdown-container> <a href=#factor-graph-transformations><span>Кондиционирование</span></a> <a href=#factor-graph-transformations><span>Устранение</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#bayesian-networks>Байесовские сети</a></div> <div class=dropdown-container> <a href=#bayesian-networks><span>Определение</span></a> <a href=#bayesian-networks><span>Локально нормализованные</span></a> <a href=#bayesian-networks><span>Маргинализация</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#probabilistic-program>Вероятностная программа</a></div> <div class=dropdown-container> <a href=#probabilistic-program><span>Концепция</span></a> <a href=#probabilistic-program><span>Сводка</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#inference>Байесовский вывод</a></div> <div class=dropdown-container> <a href=#inference><span>Алгоритм прямого-обратного хода</span></a> <a href=#inference><span>выборка по Гиббсу</span></a> <a href=#inference><span>Сглаживание Лапласа</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-221-artificial-intelligence/blob/master/en/cheatsheet-variables-models.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> Посмотреть PDF-версию на GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE -->
  <a aria-hidden=true class=anchor-bis href=#cs-221---artificial-intelligence id=cs-221---artificial-intelligence></a><a href=teaching/cs-221 onclick=trackOutboundLink(this);>CS 221 - Artificial Intelligence</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option selected value=en>English</option>
        <option value=fr>Français</option>
        <option value=tr>Türkçe</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button><B>CS 221 - Artificial Intelligence</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>CS 229 - Machine Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button>CS 230 - Deep Learning</button>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>Reflex</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/states-models/index.html'; oldhref='teaching/cs-221/cheatsheet-states-models'" type=button>States</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-221/variables-models/index.html'; oldhref='teaching/cs-221/cheatsheet-variables-models'" type=button><B>Variables</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/logic-models/index.html'; oldhref='teaching/cs-221/cheatsheet-logic-models'" type=button>Logic</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Модели на основе переменных с CSP и байесовскими сетями
</h1>
<i><!-- By --><a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> и <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a>;<a href=https://github.com/AlexandrParkhomenko onclick=trackOutboundLink(this);> Alexandr Parkhomenko</a> и {здесь можете быть Вы}</i>
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-221-artificial-intelligence on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-221-artificial-intelligence onclick=trackOutboundLink(this);>Star</a></div>
<h2>Задачи удовлетворения ограничений</h2>
<p>В этом разделе наша цель - найти максимальное присвоение веса моделям на основе переменных. Одно из преимуществ по сравнению с моделями, основанными на состояниях, состоит в том, что эти алгоритмы более удобны для кодирования специфичных для задачи ограничений.</p>
<h3><a aria-hidden=true class=anchor href=#factor-graphs id=factor-graphs></a>Факторные графы</h3>
<p><span class="new-item item-b">Определение</span> Фактор-граф, также называемый марковским случайным полем, представляет собой набор переменных $X=(X_1,...,X_n)$, где $X_i\in\textrm{Domain}_i$ и $m$ факторов $f_1,...,f_m$ с каждым $f_j(X)\geqslant 0$.</p>
<div class=mobile-container>
<center>
  <img alt="Factor graph" class=img-responsive netsrc=teaching/cs-221/illustrations/ src=factor-graph.png?6889f9b0508e74da8aaddcaf898b57ef style=width:100%;max-width:400px>
</center>
</div>
<br>
<p><span class="new-item item-r">Объем и арность</span> Объем фактора $f_j$ - это набор переменных, от которых он зависит. Размер этого набора называется арностью.</p>
<p><span class=remark>Примечание: факторы арности 1 и 2 называются соответственно унарными и бинарными.</span></p>
<br>
<p><span class="new-item item-b">Вес присвоения</span> каждое присвоение $x=(x_1,...,x_n)$ дает весовой коэффициент $\textrm{Weight}(x)$, определяемый как произведение всех факторов $f_j$, примененных к этому назначению. Его выражение опредляется следующим образом:</p>
<div class=mobile-container>
\[\boxed{\textrm{Weight}(x)=\prod_{j=1}^mf_j(x)}\]
</div>
<br>
<p><span class="new-item item-g">Задачи удовлетворения ограничений</span> Сonstraint satisfaction problem (CSP) - факторный граф, в котором все факторы бинарны; мы называем их ограничениями:
</p><div class=mobile-container>
\[\boxed{\forall j\in[\![1,m]\!],\quad f_j(x)\in\{0,1\}}\]
</div>
Здесь ограничение $j$ с присвоением $x$ считается выполненным тогда и только тогда, когда $f_j(x)=1$.<p></p>
<br>
<p><span class="new-item item-g">Непротиворечивое присвоение</span> Присвоение $x$ CSP называется непротиворечивым тогда и только тогда, когда $\textrm{Weight}(x)=1$, т.е. все ограничения выполняются.</p>
<div class=mobile-container>
<center>
  <img alt="Consistent assignment" class=img-responsive netsrc=teaching/cs-221/illustrations/ src=consistent-assignment.png?b00b47ff7756953951802408a27cc818 style=width:100%;max-width:400px>
</center>
</div>
<br>
<h3><a aria-hidden=true class=anchor href=#dynamic-ordering id=dynamic-ordering></a>Динамическое упорядочивание</h3>
<p><span class="new-item item-g">Зависимые факторы</span> Набор зависимых факторов переменной $X_i$ с частичным присвоением $x$ называется $D(x,X_i)$ и обозначает набор факторов, которые связывают $X_i$ с уже присвоенными переменными.</p>
<br>
<p><span class="new-item item-r">Поиск с возвратом</span> Backtracking search - это алгоритм, используемый для нахождения максимального веса факторного графа. На каждом этапе он выбирает неназначенную переменную и исследует её значения с помощью рекурсии. Динамическое упорядочение (<i>то есть</i> выбор переменных и значений) и опережение (<i>то есть</i> раннее устранение несовместимых вариантов) могут использоваться для более эффективного изучения графика, хотя время выполнения в худшем случае остается экспоненциальным: O(|Domain|n).</p>
<br>
<p><span class="new-item item-b">Прямая проверка</span> это эвристика упреждающего просмотра за один шаг. Она упреждающе удаляет несогласованные значения из доменов соседних переменных. Она имеет следующие характеристики:
</p><ul>
<li>После присвоения переменной $X_i$, она удаляет несовместимые значения из доменов всех своих соседей.
</li><li>Если какой-либо из этих доменов становится пустым, мы останавливаем локальный поиск с возвратом.
</li><li>Если мы отменим присвоение переменной $X_i$, мы должны восстановить домен её соседей.
</li></ul><p></p>
<br>
<p><span class="new-item item-g">Наиболее ограниченная переменная</span> Это эвристика упорядочения на уровне переменных, которая выбирает следующую неназначенную переменную, которая имеет наименьшее количество согласованных значений. Это приводит к тому, что непоследовательные присвоения терпят неудачу раньше при поиске, что обеспечивает более эффективное сокращение.</p>
<br>
<p><span class="new-item item-g">Наименее ограниченное значение</span> Это эвристика упорядочивания на уровне значений, которая назначает следующее значение, которое дает наибольшее количество согласованных значений соседних переменных. Интуитивно эта процедура сначала выбирает значения, которые с наибольшей вероятностью будут работать.</p>
<p><span class=remark>Примечание: на практике эта эвристика полезна, когда все факторы являются ограничениями.</span></p>
<div class=mobile-container>
<center>
  <img alt="Forward checking with most constrained variable and least constrained value" class=img-responsive netsrc=teaching/cs-221/illustrations/ src=fw-mcv-lcv.png?d5645d9513af10fa804fb0377fa12dc0 style=width:100%;max-width:450px>
</center>
</div>
<p><i>Приведенный выше пример является иллюстрацией задачи о трех цветах с поиском с возвратом в сочетании с наиболее ограниченным исследованием переменных и эвристикой наименее ограниченного значения, а также прямой проверкой на каждом шаге.</i></p>
<br>
<p><span class="new-item item-g">Согласованность дуги</span> Мы говорим о непротиворечивости дуги переменной $X_l$ относительно $X_k$ при обеспечении для каждого $x_l \in \textrm{Domain}_l$:
</p><ul>
<li> унарные множители $X_l$ не равны нулю,
</li><li> существует по крайней мере один $x_k \in \textrm{Domain}_k$. Для него любой множитель между $X_l$ и $X_k$ отличен от нуля.
</li></ul>
<p></p>
<br>
<p><span class="new-item item-r">AC-3</span> Алгоритм AC-3 - это многоэтапная эвристика упреждающего просмотра, которая применяет упреждающую проверку ко всем соответствующим переменным. После заданного присвоения она выполняет прямую проверку, а затем последовательно обеспечивает согласованность дуги по отношению к соседям переменных, для которых домен изменяется во время процесса.</p>
<p><span class=remark>Примечание: AC-3 может быть реализован как итеративно, так и рекурсивно.</span></p>
<br>
<h3><a aria-hidden=true class=anchor href=#approximate-methods id=approximate-methods></a>Аппроксимационные методы</h3>
<p><span class="new-item item-r">Лучевой поиск</span> (примечание переводчика: оптимизированный Поиск по первому наилучшему совпадению) - это приближенный алгоритм, расширяющий частичные присвоения $n$ переменных коэффициента ветвления $b=|\textrm{Domain}|$ исследуя $K$ лучших путей на каждом этапе. Размер луча $K \in \{1,...,b^n\}$ определяет компромисс между эффективностью и точностью. Этот алгоритм имеет временную сложность $O(n \cdot Kb\log(Kb))$.</p>
<p><i>Пример ниже иллюстрирует возможный лучевой поиск при параметрах $K = 2$, $b = 3$ и $n = 5$.</i></p>
<div class=mobile-container>
<center>
  <img alt="Beam search" class=img-responsive netsrc=teaching/cs-221/illustrations/ src=beam-search.png?146370731c85c0c07bab7eced4259779 style=width:100%;max-width:450px>
</center>
</div>
<br>
<p><span class=remark>Примечание: $K=1$ соответствует жадному поиску, тогда как $K\rightarrow+\infty$ эквивалентно поиску по дереву BFS.</span></p>
<br>
<p><span class="new-item item-b">Итерированные условные режимы</span> Iterated conditional modes (ICM) представляет собой итерационный приближенный алгоритм, который изменяет присвоение факторному графу одной переменной за раз до сходимости. На шаге $i$ мы присваиваем $X_i$ значение $v$, которое максимизирует произведение всех факторов, связанных с этой переменной.</p>
<p><span class=remark>Примечание: ICM может застрять в локальных минимумах.</span></p>
<br>
<p><span class="new-item item-b">Выборка по Гиббсу</span> это итеративный приближенный метод; который изменяет присвоение факторному графу одной переменной за раз до сходимости. На шаге $i$:
</p><ul>
<li> мы присваиваем каждому элементу $u \in \textrm{Domain}_i$ вес $w(u)$. Вес является произведением всех связанных с этой переменной факторов,
</li><li> мы выбираем $v$ из индуцированного $w$ распределения вероятностей и присваиваем его $X_i$.
</li></ul>
<p></p>
<p><span class=remark>Примечание: Выборку по Гиббсу можно рассматривать как вероятностный аналог ICM. Преимущество этого метода заключается в возможности избежать локальных минимумов в большинстве случаев.</span></p>
<br>
<h3><a aria-hidden=true class=anchor href=#factor-graph-transformations id=factor-graph-transformations></a>Преобразования факторных графов</h3>
<p><span class="new-item item-g">Независимость</span> Пусть $A,B$ - разбиение переменных $X$. Мы говорим, что $A$ и $B$ независимы, если между $A$ и $B$ нет ребер, и пишем:</p>
<div class=mobile-container>
\[\boxed{A\perp\!\!\!\!\perp B}\]
</div>
<p><span class=remark>Примечание: независимость - ключевое свойство, которое позволяет нам решать подзадачи параллельно.</span></p>
<br>
<p><span class="new-item item-r">Условная независимость</span> Мы говорим, что $A$ и $B$ условно независимы для данного $C$, если принятое условие $C$ дает граф, в котором $A$ и $B$ независимы. В этом случае пишется:</p>
<div class=mobile-container>
\[\boxed{A\perp\!\!\!\!\perp B|C}\]
</div>
<br>
<p><span class="new-item item-b">Кондиционирование</span> это преобразование переменных в независимые. Факторный граф разбивается на более мелкие части. Их можно решать параллельно и использовать обратный поиск. Чтобы поставить условие на переменную $X_i=v$, делать так:
</p><ul>
<li>Рассмотреть все зависящие от $X_i$ множители $f_1,...,f_k$
</li><li>Удалить $X_i$ и $f_1,...,f_k$
</li><li>Добавить $g_j(x)$ для $j \in \{1,...,k\}$ по определению:
<div class=mobile-container>
\[\boxed{g_j(x)=f_j(x\cup \{X_i:v\})}\]
</div>
</li></ul><p></p>
<br>
<p><span class="new-item item-b">Марковское ограждение</span> Пусть $A\subseteq X$ - подмножество переменных. Мы определяем $\textrm{MarkovBlanket}(A)$ как соседей $A$, которые не находятся в $A$.</p>
<br>
<p><span class="new-item item-r">Утверждение</span> Пусть $C=\textrm{MarkovBlanket}(A)$ и $B=X\backslash(A\cup C)$. Тогда у нас есть:</p>
<div class=mobile-container>
\[\boxed{A \perp\!\!\!\!\perp B|C}\]
</div>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=markov-blanket-proposition.png?bc9d269bafce0976a8b6674d5d4939c2 style=width:100%;max-width:450px;>
</center>
</div>
<br>
<p><span class="new-item item-g">Устранение</span> Исключение - это преобразование факторного графа с удалением $X_i$ из графа и решением небольшой подзадачи с условием марковского ограждения:
</p><ul>
<li>Рассмотреть все факторы $f_{i,1},...,f_{i,k}$ с зависимостью от $X_i$
</li><li>Удалить $X_i$ и $f_{i,1},...,f_{i,k}$
</li><li>Добавить $f_{\textrm{new},i}(x)$ по определению:
<div class=mobile-container>
\[\boxed{f_{\textrm{new},i}(x)=\max_{x_i}\prod_{l=1}^kf_{i,l}(x)}\]
</div>
</li></ul><p></p>
<br>
<p><span class="new-item item-b">Ширина дерева</span> Древовидная ширина факторного графа - это максимальная арность любого фактора, созданного путем исключения переменных с наилучшим порядком переменных. Другими словами,</p>
<div class=mobile-container>
\[\boxed{\textrm{Treewidth} = \min_{\textrm{orderings}} \max_{i\in \{1,...,n\}} \textrm{arity}(f_{\textrm{new},i})}\]
</div>
<p>Пример ниже иллюстрирует случай факторного графа с шириной дерева 3.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=treewidth.png?451373e68c20903fa9c3fc9dccf6f4b9 style=width:100%;max-width:400px;>
</center>
</div>
<p><span class=remark>Примечание: поиск лучшего порядка переменных - это NP-сложная задача.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#bayesian-networks id=bayesian-networks></a>Байесовские сети</h2>
<p>В этом разделе нашей целью будет вычисление условных вероятностей. Какова условная вероятность запроса при данных наблюдениях?</p>
<h3>Введение</h3>
<p><span class="new-item item-g">Объяснение</span> Предположим, что причины $C_1$ и $C_2$ влияют на эффект $E$. Обусловление эффекта $E$ и одной из причин (скажем, $C_1$) изменяет вероятность другой причины (скажем, $C_2$). В этом случае мы говорим, что $C_1$ объяснил $C_2$.</p>
<br>
<p><span class="new-item item-g">Направленный ациклический граф</span> Directed acyclic graph (DAG) - это конечный ориентированный граф без ориентированных циклов.</p>
<br>
<p><span class="new-item item-r">Байесовская сеть</span> Bayesian network - это ориентированный ациклический граф (DAG), который определяет совместное распределение по случайным величинам $X=(X_1,...,X_n)$ как произведение локальных условных распределений, по одному для каждого узла:</p>
<div class=mobile-container>
\[\boxed{P(X_1=x_1,...,X_n=x_n)\triangleq\prod_{i=1}^np(x_i|x_{\textrm{Parents}(i)})}\]
</div>
<p><span class=remark>Примечание: Байесовские сети - это фактор-графы, пропитанные языком вероятностей.</span></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=bayesian-network.png?437e5479b93706125334e1718a749a1a style=width:100%;max-width:360px;>
</center>
</div>
<br>
<p><span class="new-item item-b">Локально нормализованные</span> для каждого $x_{\textrm{Parents}(i)}$ все факторы являются локальными условными распределениями. Следовательно, они должны удовлетворить:</p>
<div class=mobile-container>
\[\boxed{\sum_{x_i}p(x_i|x_{\textrm{Parents}(i)})=1}\]
</div>
<p>В результате суббайесовские сети и условные распределения согласованы.</p>
<p><span class=remark>Примечание: локальные условные распределения являются истинными условными распределениями.</span></p>
<br>
<p><span class="new-item item-g">Маргинализация</span> маргинализация листового узла приводит к байесовской сети без этого узла.</p>
<br>
<h3><a aria-hidden=true class=anchor href=#probabilistic-program id=probabilistic-program></a>Вероятностные программы</h3>
<p><span class="new-item item-b">Концепция</span> вероятностная программа случайным образом присваивает переменные. Таким образом, мы можем записывать сложные байесовские сети, которые генерируют назначения, без необходимости явно указывать связанные вероятности.</p>
<p><span class=remark>Примечание: примеры вероятностных программ включают скрытую марковскую модель (Hidden Markov model, HMM), факторную HMM, наивный байесовский алгоритм, скрытое распределение Дирихле, болезни и симптомы (SBD-LDA) и стохастические блочные модели.</span></p>
<br>
<p><span class="new-item item-g">Сводка</span> В таблице ниже приведены общие вероятностные программы, а также их приложения:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:700px; max-width:850px;">
<colgroup>
<col style=width:140px>
<col style=width:270px>
<col style=width:100%>
<col style=width:160px>
</colgroup>
<tbody>
<tr>
<td align=center><b>Программа</b></td>
<td align=center><b>Алгоритм</b></td>
<td align=center><b>Иллюстрация</b></td>
<td align=center><b>Пример</b></td>
</tr>
<tr>
<td align=center valign=center>Markov Model</td>
<td align=left valign=center>Создаёт $X_i\sim p(X_i|X_{i-1})$</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=probabilistic-programs-1.png?6e4d6ca0714baa89294b193bc49fa832></td>
<td align=center>Языковое моделирование</td>
</tr>
<tr>
<td align=center valign=center>Hidden Markov Model<br>(HMM)</td>
<td align=left valign=center>Создаёт $H_t\sim p(H_t|H_{t-1})$<br>
                              Создаёт $E_t\sim p(E_t|H_{t})$</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=probabilistic-programs-2.png?9775f4e07376395a94d34d4339b7aac5></td>
<td align=center>Трекинг объектов</td>
</tr>
<tr>
<td align=center valign=center>Factorial HMM</td>
<td align=left valign=center>Создаёт $H_t^o\underset{\small o\in\{a,b\}}{\sim} p(H_t^o|H_{t-1}^o)$<br>
                              Создаёт $E_t\sim p(E_t|H_t^a,H_t^b)$</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=probabilistic-programs-3.png?49285b53aba41464df086b86841a02f8></td>
<td align=center>Трекинг нескольких объектов</td>
</tr>
<tr>
<td align=center valign=center>Naive Bayes</td>
<td align=left valign=center>Создаёт $Y\sim p(Y)$<br>
                              Создаёт $W_i\sim p(W_i|Y)$</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=probabilistic-programs-4.png?bf75f98f3cf02c590d9050d53eb2365f></td>
<td align=center>Классификация документов</td>
</tr>
<tr>
<td align=center valign=center>Latent Dirichlet Allocation<br>(LDA)</td>
<td align=left valign=center>Создаёт $\alpha\in\mathbb{R}^K$ distribution<br>
                              Создаёт $Z_i\sim p(Z_i|\alpha)$<br>
                              Создаёт $W_i\sim p(W_i|Z_i)$</td>
<td align=center><img class=img-responsive netsrc=teaching/cs-221/illustrations/ src=probabilistic-programs-5.png?42bff30421fe4f7acf5881f6bd7cd191></td>
<td align=center>Тематическое моделирование</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h3><a aria-hidden=true class=anchor href=#inference id=inference></a>Байесовский вывод</h3>
<p><span class="new-item item-g">Общая стратегия вероятностного вывода</span> Стратегия вычисления вероятности $P(Q | E=e)$ запроса $Q$ при наличии свидетельства (англ: evidence) $E=e$ следующая:
</p><ul>
<li><u>Шаг 1</u>: Удалить неявляющиеся предками запроса $Q$ или свидетельства $E$ переменные путем маргинализации
</li><li><u>Шаг 2</u>: Преобразовать байесовскую сеть в факторный граф
</li><li><u>Шаг 3</u>: Улучшить состояние свидетельства $E=e$
</li><li><u>Шаг 4</u>: Удалить отключенные от запроса $Q$ узлы путем маргинализации
</li><li><u>Шаг 5</u>: Запустить вероятностный алгоритм вывода (вручную, variable elimination, Gibbs sampling, particle filtering)
</li></ul><p></p>
<br>
<p><span class="new-item item-r">Алгоритм прямого-обратного хода</span> этот алгоритм вычисляет точное значение $P(H = h_k | E = e)$ (запрос сглаживания) для любого $k \in \{1, ..., L\}$ в случае HMM размера $L$. Чтобы сделать так, мы выполняем 3 шага:
</p><div class=mobile-container>
<ul>
<li><u>Шаг 1</u>: для $i \in \{1,..., L\}$, посчитать $F_i(h_i) = \sum_{h_{i-1}} F_{i-1}(h_{i-1})p(h_{i}|h_{i-1})p(e_i|h_i)$
</li><li><u>Шаг 2</u>: для $i \in \{L,..., 1\}$, посчитать $B_i(h_i) = \sum_{h_{i+1}} B_{i+1}(h_{i+1})p(h_{i+1}|h_i)p(e_{i+1}|h_{i+1})$
</li><li><u>Шаг 3</u>: для $i \in \{1,...,L\}$, посчитать $S_i(h_i) = \frac{F_i(h_i)B_i(h_i)}{\sum_{h_i}F_i(h_i)B_i(h_i)}$
</li></ul>
</div>
с условием $F_0 = B_{L+1} = 1$. Из этой процедуры и этих обозначений мы получаем это
<div class=mobile-container>
\[\boxed{P(H = h_k | E = e) = S_k(h_k)}\]
</div>
<p></p>
<p><span class=remark>Примечание: этот алгоритм интерпретирует каждое присвоение как путь, в котором каждое ребро $h_{i-1} \rightarrow h_i$ имеет вес $p(h_{i}|h_{i-1})p(e_i|h_i)$.</span></p>
<br>
<p><span class="new-item item-b">Выборка по Гиббсу</span> Этот алгоритм представляет собой итеративный приближенный метод. Он использует небольшой набор назначений (частиц) для представления большого распределения вероятностей. Из случайного присвоения $x$, Выборка по Гиббсу выполняет следующие шаги для $i\in \{1,...,n\}$ до сходимости:
</p><ul>
<li> Для всех $u \in \textrm{Domain}_i$, вычислить вес $w(u)$ присвоения $x$, где $X_i = u$
</li><li> Произвести выборку $v$ из индуцированного $w$ распределения вероятностей: $v \sim P(X_i = v | X_{-i} = x_{-i})$
</li><li> Установить $X_i = v$
</li></ul><p></p>
<p><span class=remark>Примечание: $X_{-i}$ обозначает $X \backslash \{X_i\}$, а $x_{-i}$ представляет соответствующее присвоение.</span></p>
<br>
<p><span class="new-item item-g">Фильтрация частиц</span> Этот алгоритм аппроксимирует апостериорную плотность переменных состояния с учетом данных наблюдений путем отслеживания $K$ частиц за раз. Начиная с набора частиц $C$ размера $K$, мы итеративно выполняем следующие 3 шага:
</p><ul>
<li><u>Шаг 1</u>: предложение - Для каждой старой частицы $x_{t-1} \in C$, выбрать $x$ из распределения вероятности перехода $p(x | x_{t-1})$ и добавить $x$ к множеству $C'$.
</li><li><u>Шаг 2</u>: взвешивание - Взвесить каждый $x$ из множества $C'$ как $w(x)=p(e_t|x)$, где $e_t$ - свидетельство в момент времени $t$.
</li><li><u>Шаг 3</u>: повторная выборка - выборка $K$ элементов из множества $C'$ с использованием индуцированного $w$ распределения вероятностей и сохранение их в $C$: это текущие частицы $x_t$.
</li></ul><p></p>
<p><span class=remark>Примечание: более дорогая версия этого алгоритма также отслеживает прошлые частицы на этапе предложения.</span></p>
<br>
<p><span class="new-item item-g">Максимальное правдоподобие</span> Если мы не знаем локальных условных распределений, мы можем изучить их, используя максимальное правдоподобие.</p>
<div class=mobile-container>
\[\boxed{\max_\theta\prod_{x\in\mathcal{D}_{\textrm{train}}}p(X=x;\theta)}\]
</div>
<br>
<p><span class="new-item item-g">Сглаживание Лапласа</span> для каждого распределения $d$ и частичного присвоения $(x_{\textrm{Parents}(i)},x_i)$ добавьте $\lambda$ к $\textrm{count}_d(x_{\textrm{Parents}(i)},x_i)$, затем нормализуйте, чтобы получить оценки вероятности.</p>
<br>
<p><span class="new-item item-r">Алгоритм Expectation-Maximization (EM)</span> алгоритм максимизации ожидания дает эффективный метод оценки параметра $\theta$ посредством оценки максимального правдоподобия путем многократного построения нижней границы правдоподобия (E-шаг) и оптимизации этой нижней границы (M-шаг) следующим образом:
</p><ul>
<li>Шаг E: Оценить апостериорную вероятность $q(h)$ прихода каждой точки данных $e$ из определенного кластера $h$ следующим образом:
<div class=mobile-container>
\[\boxed{q(h)=P(H=h|E=e;\theta)}\]
</div>
</li><li>M-шаг: использовать апостериорные вероятности $q(h)$ в качестве весовых коэффициентов для конкретных кластеров точек данных $e$ и определить $\theta$ через максимальное правдоподобие.
</li></ul><p></p>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>