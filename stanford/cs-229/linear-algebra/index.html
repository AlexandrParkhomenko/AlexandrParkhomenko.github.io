<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 229 - Памятка: Линейная Алгебра и Исчисление</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport>
<link href=https://stanford.edu/~shervine/teaching/cs-229/refresher-algebra-calculus rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 15px;">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Algebra and Calculus</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#notations>Общие обозначения</a></div> <div class=dropdown-container> <a href=#notations><span>Определения</span></a> <a href=#notations><span>Основные матрицы</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#operations>Матричные операции</a></div> <div class=dropdown-container> <a href=#operations><span>Умножение</span></a> <a href=#operations><span>Прочие операции</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#properties>Свойства матрицы</a></div> <div class=dropdown-container> <a href=#properties><span>Норма</span></a> <a href=#properties><span>Eigenvalue/eigenvector</span></a> <a href=#properties><span>Сингулярное разложение</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#calculus>Матричное исчисление</a></div> <div class=dropdown-container> <a href=#calculus><span>Градиент</span></a> <a href=#calculus><span>Гессиан</span></a> <a href=#calculus><span>Операции</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> Посмотреть PDF-версию на GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE -->
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>

<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>CS 221 - Artificial Intelligence</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button><B>CS 229 - Machine Learning</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button>CS 230 - Deep Learning</button>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/probability/index.html'; oldhref='teaching/cs-229/refresher-probabilities-statistics'" type=button>Probabilities</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-229/linear-algebra/index.html'; oldhref='teaching/cs-229/refresher-algebra-calculus'" type=button><B>Algebra</B></BUTTON>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/unsupervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-unsupervised-learning'" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/deep-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-deep-learning'" type=button>Deep Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/machine-learning-tips-and-tricks/index.html'; oldhref='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Памятка: Линейная Алгебра и Исчисление
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-229-machine-learning on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i><!-- By --><a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> и <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a>;<a href=https://github.com/AlexandrParkhomenko onclick=trackOutboundLink(this);> Alexandr Parkhomenko</a> и {здесь можете быть Вы}</i>
<h2><a aria-hidden=true class=anchor href=#notations id=notations></a>Общие обозначения</h2>
<h3>Определения</h3>
<p><span class="new-item item-b">Вектор</span> Мы обозначаем $x\in\mathbb{R}^n$ вектор с $n$ элементами, где $x_i\in\mathbb{R}$∈ i-й элемент:</p>
<div class=mobile-container>
\[x=\left(\begin{array}{c}x_1\\x_2\\\vdots\\x_n\end{array}\right)\in\mathbb{R}^n\]
</div>
<br>
<p><span class="new-item item-b">Матрица</span> Мы обозначаем $A\in\mathbb{R}^{m\times n}$ матрица с $m$ строками и $n$ столбцами, где $A_{i,j}\in\mathbb{R}$ - запись, расположенная в i-й строке и j-м столбце:</p>
<div class=mobile-container>
\[A=\left(\begin{array}{ccc}A_{1,1}&amp; \cdots&amp;A_{1,n}\\\vdots&amp;&amp; \vdots\\A_{m,1}&amp; \cdots&amp;A_{m,n}\end{array}\right)\in\mathbb{R}^{m\times n}\]
</div>
<p><span class=remark>Примечание: вектор $x$, определенный выше, можно рассматривать как матрицу 1×n и, в частности, называется вектор-столбец.</span></p>
<br>
<h3>Основные матрицы</h3>
<p><span class="new-item item-b">Матрица идентичности</span> единичная матрица $I\in\mathbb{R}^{n\times n}$ является квадратной матрицей с единицами на диагонали и нулем во всех остальных местах:</p>
<div class=mobile-container>
\[I=\left(\begin{array}{cccc}1&amp;0&amp; \cdots&amp;0\\0&amp; \ddots&amp; \ddots&amp; \vdots\\\vdots&amp; \ddots&amp; \ddots&amp;0\\0&amp; \cdots&amp;0&amp;1\end{array}\right)\]
</div>
<p><span class=remark>Примечание: для всех матриц $A\in\mathbb{R}^{n\times n}$ имеем $A\times I=I\times A=A$.</span></p>
<br>
<p><span class="new-item item-b">Диагональная матрица</span> Диагональная матрица $D\in\mathbb{R}^{n\times n}$ представляет собой квадратную матрицу с ненулевыми значениями на её диагонали и нулевыми везде:</p>
<div class=mobile-container>
\[D=\left(\begin{array}{cccc}d_1&amp;0&amp; \cdots&amp;0\\0&amp; \ddots&amp; \ddots&amp; \vdots\\\vdots&amp; \ddots&amp; \ddots&amp;0\\0&amp; \cdots&amp;0&amp;d_n\end{array}\right)\]
</div>
<p><span class=remark>Примечание: мы также отбозначаем $D$ как $\textrm{diag}(d_1,...,d_n)$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#operations id=operations></a>Матричные операции</h2>
<h3>Умножение</h3>
<p><span class="new-item item-r">Вектор-вектор</span> существует два типа векторно-векторных произведений:
</p><ul>
<li>внутреннее произведение: для $x,y\in\mathbb{R}^n$, у нас есть:
<div class=mobile-container>
\[\boxed{x^Ty=\sum_{i=1}^nx_iy_i\in\mathbb{R}}\]
</div>
</li><li>внешнее произведение: для $x\in\mathbb{R}^m, y\in\mathbb{R}^n$, у нас есть:
<div class=mobile-container>
\[\boxed{xy^T=\left(\begin{array}{ccc}x_1y_1&amp; \cdots&amp;x_1y_n\\\vdots&amp;&amp; \vdots\\x_my_1&amp; \cdots&amp;x_my_n\end{array}\right)\in\mathbb{R}^{m\times n}}\]
</div>
</li></ul>
<p></p>
<br>
<p><span class="new-item item-r">Матрица-вектор</span> Произведение матрицы A∈Rm×n и вектора $x\in\mathbb{R}^{n}$ - это вектор размера $\mathbb{R}^{m}$, такой что:
</p><div class=mobile-container>
\[\boxed{Ax=\left(\begin{array}{c}a_{r,1}^Tx\\\vdots\\a_{r,m}^Tx\end{array}\right)=\sum_{i=1}^na_{c,i}x_{i}\in\mathbb{R}^{m}}\]
</div>
где $a_{r,i}^T$ - векторные строки, а $a_{c,j}$ - векторные столбцы $A$, а $x_i$ - элементы $x$.<p></p>
<br>
<p><span class="new-item item-r">Матрица-матрица</span> Произведение матриц $A\in\mathbb{R}^{m\times n}$ и $B\in\mathbb{R}^{n\times p}$ матрица размера $\mathbb{R}^{n\times p}$ такая, что:
</p><div class=mobile-container>
\[\boxed{AB=\left(\begin{array}{ccc}a_{r,1}^Tb_{c,1}&amp; \cdots&amp;a_{r,1}^Tb_{c,p}\\\vdots&amp;&amp; \vdots\\a_{r,m}^Tb_{c,1}&amp; \cdots&amp;a_{r,m}^Tb_{c,p}\end{array}\right)=\sum_{i=1}^na_{c,i}b_{r,i}^T\in\mathbb{R}^{n\times p}}\]
</div>
где $a_{r,i}^T, b_{r,i}^T$ - векторные строки и $a_{c,j}, b_{c,j}$ - векторные столбцы $A$ и $B$ соответственно<p></p>
<br>
<h3>Прочие операции</h3>
<p><span class="new-item item-g">Транспонирование</span> Транспонирование матрицы $A\in\mathbb{R}^{m\times n}$, обозначается $A^T$, таково, что её элементы переворачиваются:</p>
<div class=mobile-container>
\[\boxed{\forall i,j,\quad\quad A_{i,j}^T=A_{j,i}}\]
</div><br>
<p><span class=remark>Примечание: для матриц $A,B$ имеем $(AB)^T=B^TA^T$.</span></p>
<br>
<p><span class="new-item item-g">Обращение</span> Обратная квадратная матрица $A$ обозначается как $A^{-1}$ и является единственной матрицей, такой что:</p>
<div class=mobile-container>
\[\boxed{AA^{-1}=A^{-1}A=I}\]
</div>
<p><span class=remark>Примечание: не все квадратные матрицы обратимы. Также для матриц $A,B$, мы имеем $(AB)^{-1}=B^{-1}A^{-1}$</span></p>
<br>
<p><span class="new-item item-g">След (Trace)</span> След квадратной матрицы $A$, обозначается $\textrm{tr}(A)$, представляет собой сумму её диагональных элементов:</p>
<div class=mobile-container>
\[\boxed{\textrm{tr}(A)=\sum_{i=1}^nA_{i,i}}\]
</div>
<p><span class=remark>Примечание: для матриц $A,B$ имеем $\textrm{tr}(A^T)=\textrm{tr}(A)$ и $\textrm{tr}(AB)=\textrm{tr}(BA)$</span></p>
<br>
<p><span class="new-item item-g">Определитель</span> определитель квадратной матрицы $A\in\mathbb{R}^{n\times n}$, обозначается $|A|$ или $\textrm{det}(A)$ рекурсивно выражается через $A_{\backslash i, \backslash j}$, которая является матрицей A без её i-й строки и j-го столбца, следующим образом:</p>
<div class=mobile-container>
\[\boxed{\textrm{det}(A)=|A|=\sum_{j=1}^n(-1)^{i+j}A_{i,j}|A_{\backslash i,\backslash j}|}\]
</div>
<p><span class=remark>Примечание: $A$ обратима тогда и только тогда, когда $|A|\neq0$. Также, $|AB|=|A||B|$ и $|A^T|=|A|$.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#properties id=properties></a>Свойства матрицы</h2>
<h3>Определения</h3>
<p><span class="new-item item-r">Симметричное разложение</span> Данная матрица $A$ может быть выражена в терминах её симметричной и антисимметричной частей следующим образом:</p>
<div class=mobile-container>
\[\boxed{A=\underbrace{\frac{A+A^T}{2}}_{\textrm{Симметричная}}+\underbrace{\frac{A-A^T}{2}}_{\textrm{Антисимметричная}}}\]
</div>
<br>
<p><span class="new-item item-b">Норма</span> Норма - это функция $N:V\longrightarrow[0,+\infty[$ где $V$ - векторное пространство, и такая, что для всех $x,y\in V$, есть:
</p><ul>
<li>$N(x+y)\leqslant N(x)+N(y)$
</li><li>$N(ax)=|a|N(x)$ для скаляра
</li><li>если $N(x)=0$, тогда $x=0$</li></ul><p></p>
<p>Для $x\in V$ наиболее часто используемые нормы приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table>
<tbody>
<tr>
<td align=center><b>Норма</b></td>
<td align=center><b>Обозначение</b></td>
<td align=center><b>Определение</b></td>
<td align=center><b>Вариант использования</b></td>
</tr>
<tr>
<td align=center>Manhattan, $L^1$</td>
<td align=center>$||x||_1$</td>
<td align=center>$\displaystyle\sum_{i=1}^n|x_i|$</td>
<td align=center>LASSO regularization</td>
</tr>
<tr>
<td align=center>Euclidean, $L^2$</td>
<td align=center>$||x||_2$</td>
<td align=center>$\displaystyle\sqrt{\sum_{i=1}^nx_i^2}$</td>
<td align=center>Ridge regularization</td>
</tr>
<tr>
<td align=center>$p$-norm, $L^p$</td>
<td align=center>$||x||_p$</td>
<td align=center>$\displaystyle\left(\sum_{i=1}^nx_i^p\right)^{\frac{1}{p}}$</td>
<td align=center>Hölder inequality</td>
</tr>
<tr>
<td align=center>Infinity, $L^{\infty}$</td>
<td align=center>$||x||_{\infty}$</td>
<td align=center>$\underset{i}{\textrm{max }}|x_i|$</td>
<td align=center>Uniform convergence</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-r">Линейная зависимость</span> Набор векторов называется линейно зависимым, если один из векторов в наборе может быть определен как линейная комбинация других.</p>
<p><span class=remark>Примечание: если ни один вектор не может быть записан таким образом, то векторы называются линейно независимыми.</span></p>
<br>
<p><span class="new-item item-b">Ранг матрицы</span> Ранг данной матрицы $A$ обозначается $\textrm{rank}(A)$ и является размерностью векторного пространства, порожденного его столбцами. Это эквивалентно максимальному количеству линейно независимых столбцов $A$.</p>
<br>
<p><span class="new-item item-r">Положительная полуопределенная матрица</span> Матрица $A\in\mathbb{R}^{n\times n}$ является положительно полуопределенной (positive semi-definite, PSD) и обозначается как $A\succeq 0$, если у нас есть:</p>
<div class=mobile-container>
\[\boxed{A=A^T}\quad\textrm{ and }\quad\boxed{\forall x\in\mathbb{R}^n,\quad x^TAx\geqslant0}\]
</div>
<p><span class=remark>Примечание: аналогично, матрица $A$ называется положительно определенной и обозначается как $A\succ0$, если это матрица PSD, которая удовлетворяет всем ненулевым векторам $x$, $x^TAx&gt;0$.</span></p>
<br>
<p><span class="new-item item-b">Собственное значение, собственный вектор</span> Для матрицы $A\in\mathbb{R}^{n\times n}$ $\lambda$ называется собственным значением $A$, если существует вектор $z\in\mathbb{R}^n\backslash\{0\}$, называемый собственным вектором, такой, что у нас есть:</p>
<div class=mobile-container>
\[\boxed{Az=\lambda z}\]
</div>
<br>
<p><span class="new-item item-r">Спектральная теорема</span> Пусть $A\in\mathbb{R}^{n\times n}$. Если $A$ симметрична, то $A$ диагонализуема действительной ортогональной матрицей $U\in\mathbb{R}^{n\times n}$. Обозначим $\Lambda=\textrm{diag}(\lambda_1,...,\lambda_n)$, у нас есть:</p>
<div class=mobile-container>
\[\boxed{\exists\Lambda\textrm{ диагональ},\quad A=U\Lambda U^T}\]
</div>
<br>
<p><span class="new-item item-g">Сингулярное разложение</span> Для данной матрицы $A$ размеров $m\times n$ разложение по сингулярным числам (singular-value decomposition, SVD) представляет собой метод факторизации, который гарантирует существование унитарных матриц $U$ $m\times m$, диагональных $\Sigma$ $m\times n$ и унитарных матриц $V$ $n\times n$, таких что:</p>
<div class=mobile-container>
\[\boxed{A=U\Sigma V^T}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#calculus id=calculus></a>Матричное исчисление</h2>
<p><span class="new-item item-b">Градиент</span> Пусть $f:\mathbb{R}^{m\times n}\rightarrow\mathbb{R}$ - функция, а $A\in\mathbb{R}^{m\times n}$ - матрица. Градиент $f$ относительно $A$ представляет собой матрицу размера $m\times n$, отмеченную как $\nabla_A f(A)$, такую, что:</p>
<div class=mobile-container>
\[\boxed{\Big(\nabla_A f(A)\Big)_{i,j}=\frac{\partial f(A)}{\partial A_{i,j}}}\]
</div>
<p><span class=remark>Примечание: градиент $f$ определяется только тогда, когда $f$ - функция, возвращающая скаляр.</span></p>
<br>
<p><span class="new-item item-b">Гессиан</span> Пусть $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ функция, а $x\in\mathbb{R}^{n}$ - вектор. Гессиан $f$ относительно $x$ является симметричной матрицей размера $n\times n$, обозначенной как $\nabla_x^2 f(x)$, такой что:</p>
<div class=mobile-container>
\[\boxed{\Big(\nabla_x^2 f(x)\Big)_{i,j}=\frac{\partial^2 f(x)}{\partial x_i\partial x_j}}\]
</div>
<p><span class=remark>Примечание: гессиан функции $f$ определяется только тогда, когда $f$ является функцией, возвращающей скаляр.</span></p>
<br>
<p><span class="new-item item-r">Градиентные операции</span> Для матриц $A,B,C$ следует иметь в виду следующие свойства градиента:</p>
<div class=mobile-container>
\[\boxed{\nabla_A\textrm{tr}(AB)=B^T}\quad\quad\boxed{\nabla_{A^T}f(A)=\left(\nabla_Af(A)\right)^T}\]
\[\boxed{\nabla_A\textrm{tr}(ABA^TC)=CAB+C^TAB^T}\quad\quad\boxed{\nabla_A|A|=|A|(A^{-1})^T}\]
</div>
<br>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>