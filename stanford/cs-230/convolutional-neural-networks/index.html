<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 230 - Convolutional Neural Networks Cheatsheet</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport>
<link href=https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-230 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 15px;">   <b>CS 230 - Глубокое обучение</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Convolutional Neural Nets</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#overview>Обзор</a></div> <div class=dropdown-container> <a href=#overview><span>Структура архитектуры</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#layer>Типы слоёв</a></div> <div class=dropdown-container> <a href=#layer><span>Свертка</span></a> <a href=#layer><span>Пулинг</span></a> <a href=#layer><span>Полносвязный</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#filter>Фильтрация гиперпараметров</a></div> <div class=dropdown-container> <a href=#filter><span>Размеры</span></a> <a href=#filter><span>Шаг</span></a> <a href=#filter><span>Дополнение</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#hyperparameters>Настройка гиперпараметров</a></div> <div class=dropdown-container> <a href=#hyperparameters><span>Совместимость параметров</span></a> <a href=#hyperparameters><span>Сложность модели</span></a> <a href=#hyperparameters><span>Рецептивное поле</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#activation-function>Функции активации</a></div> <div class=dropdown-container> <a href=#activation-function><span>Блок линейной ректификации</span></a> <a href=#activation-function><span>Softmax</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#object-detection>Обнаружение объектов</a></div> <div class=dropdown-container> <a href=#object-detection><span>Типы моделей</span></a> <a href=#object-detection><span>Обнаружение</span></a> <a href=#object-detection><span>Пересечение по объединению</span></a> <a href=#object-detection><span>Подавление немаксимума</span></a> <a href=#object-detection><span>YOLO</span></a> <a href=#object-detection><span>R-CNN</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#face>Проверка/распознавание лиц</a></div> <div class=dropdown-container> <a href=#face><span>Обучение одним выстрелом</span></a> <a href=#face><span>Сиамская сеть</span></a> <a href=#face><span>Triplet loss</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#style-transfer>Перенос нейронного стиля</a></div> <div class=dropdown-container> <a href=#style-transfer><span>Активация</span></a> <a href=#style-transfer><span>Матрица стилей</span></a> <a href=#style-transfer><span>Функция стоимости стиля/контента</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#ct-architectures>Архитектуры вычислительных трюков</a></div> <div class=dropdown-container> <a href=#ct-architectures><span>Generative Adversarial Net</span></a> <a href=#ct-architectures><span>ResNet</span></a> <a href=#ct-architectures><span>Inception Network</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/cheatsheet-convolutional-neural-networks.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> Посмотреть PDF-версию на GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE --><a aria-hidden=true class=anchor-bis href=#cs-230---deep-learning id=cs-230---deep-learning></a><a href=teaching/cs-230 onclick=trackOutboundLink(this);>CS 230 - Глубокое обучение</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option selected value=en>English</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ja>日本語</option>
        <option value=ko>한국어</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>CS 221 - Artificial Intelligence</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>CS 229 - Machine Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button><B>CS 230 - Глубокое обучение</B></BUTTON>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button><B>Convolutional Neural Networks</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/recurrent-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-recurrent-neural-networks'" type=button>Recurrent Neural Networks</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/deep-learning-tips-and-tricks/index.html'; oldhref='teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks'" type=button>Tips and tricks</button>
  </div>
</div>

<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Шпаргалка по Сверточным Нейронным Сетям
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-230-deep-learning on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-230-deep-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></i>
<h2><a aria-hidden=true class=anchor href=#overview id=overview></a>Обзор</h2>
<p><span class="new-item item-r">Архитектура традиционного</span> Сверточные нейронные сети, также известные как (Convolutional neural networks, CNN), представляют собой особый тип нейронных сетей, которые обычно состоят из следующих слоев:</p>
<div class=mobile-container>
<center>
  <img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=architecture-cnn-en.jpeg?3b7fccd728e29dc619e1bd8022bf71cf style=width:100%;max-width:900px>
</center>
</div>
<br>
<p>Слой свертки и слой пулинга можно настроить с учетом гиперпараметров, которые описаны в следующих разделах.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#layer id=layer></a>Типы слоёв</h2>
<p><span class="new-item item-b">Convolution layer (CONV)</span> The convolution layer (CONV) uses filters that perform convolution operations as it is scanning the input $I$ with respect to its dimensions. Its hyperparameters include the filter size $F$ and stride $S$. The resulting output $O$ is called <i>feature map</i> or <i>activation map</i>.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=convolution-layer-a.png?1c517e00cb8d709baf32fc3d39ebae67 style=width:100%;max-width:450px>
</center>
</div>
<br>
<p><span class=remark>Примечание: шаг свертки также может быть обобщен на одномерные и трехмерные случаи.</span></p>
<br>
<p><span class="new-item item-b">Слой Пулинга</span> Pooling (POOL) - это операция понижающей дискретизации, обычно применяемая после сверточного слоя, который обеспечивает некоторую пространственную инвариантность. В частности, max-пулинг и усредненный пулинг - это особые виды пулинга, в которых берется максимальное и среднее значение соответственно.</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:400px; max-width:720px;">
<colgroup>
<col style=width:115px>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Тип</b></td>
<td align=center>Max-пулинг</td>
<td align=center>Усредненный пулинг</td>
</tr>
<tr>
<td align=center><b>Цель</b></td>
<td align=left>Каждая операция пулинга выбирает максимальное значение текущего просмотра</td>
<td align=left>Каждая операция пулинга усредняет значения текущего представления</td>
</tr>
<tr>
<td align=center><b>Иллюстрация</b></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=max-pooling-a.png?711b14799d07f9306864695e2713ae07></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=average-pooling-a.png?58f9ab6d61248c3ec8d526ef65763d2f></td>
</tr>
<tr>
<td align=center><b>Комментарии</b></td>
<td align=left>• Сохраняет обнаруженные функции<br>• Most commonly used
</td>
<td align=left>• Downsamples feature map<br>• Используется в LeNet</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-b">Полносвязный</span> Fully Connected (FC) слой работает на сглаженном входе, где каждый вход подключен ко всем нейронам. Уровни FC, если они присутствуют, обычно находятся ближе к концу архитектур CNN и могут использоваться для оптимизации целей, таких как оценки классов.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=fully-connected-ltr.png?32caf9e07c79d652faa292812579d063 style="width:100%; max-width:500px;">
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#filter id=filter></a>Фильтрация гиперпараметров</h2>
<p>Слой свертки содержит фильтры, для которых важно знать значение его гиперпараметров.</p>
<p><span class="new-item item-b">Dimensions of a filter</span> A filter of size $F\times F$ applied to an input containing $C$ channels is a $F \times F \times C$ volume that performs convolutions on an input of size $I \times I \times C$ and produces an output feature map (also called activation map) of size $O \times O \times 1$.
</p><div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=dimensions-filter-en.png?7ce161e129a392a1804a231536b59f45 style=width:100%;>
</center>
</div>
<br>
<i>Remark: the application of $K$ filters of size $F\times F$ results in an output feature map of size $O \times O \times K$.</i>
<br><br>
<p><span class="new-item item-b">Stride</span> For a convolutional or a pooling operation, the stride $S$ denotes the number of pixels by which the window moves after each operation.
</p><div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=stride.png?36b5b2e02f7e02c3c4075a9d836c048c style=width:100%;max-width:700px>
</center>
</div>
<br>
<br>
<p><span class="new-item item-b">Zero-padding</span> Zero-padding denotes the process of adding $P$ zeroes to each side of the boundaries of the input. This value can either be manually specified or automatically set through one of the three modes detailed below:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:700px;">
  <colgroup>
    <col style=width:115px;>
    <col style=width:33%>
    <col style=width:33%>
    <col style=width:33%>
  </colgroup>
<tbody>
<tr>
<td align=center><b>Режим</b></td>
<td align=center>Действительный</td>
<td align=center>Такой же</td>
<td align=center>Полный</td>
</tr>
<tr>
<td align=center><b>Значение</b></td>
<td align=center>$P = 0$</td>
<td align=left>$P_\text{start} = \Bigl\lfloor\frac{S \lceil\frac{I}{S}\rceil - I + F - S}{2}\Bigr\rfloor$<br>$P_\text{end} = \Bigl\lceil\frac{S \lceil\frac{I}{S}\rceil - I + F - S}{2}\Bigr\rceil$</td>
<td align=left>$P_\text{start}\in[\![0,F-1]\!]$<br><br>$P_\text{end} = F-1$</td>
</tr>
<tr>
<td align=center><b>Иллюстрация</b></td>
<td align=center><img alt="Padding valid" class=img-responsive netsrc=teaching/cs-230/illustrations/ src=padding-valid-a.png?1f58d78612f6202ce201620919d71609></td>
<td align=center><img alt="Padding same" class=img-responsive netsrc=teaching/cs-230/illustrations/ src=padding-same-a.png?8b680283b10a6e131209b74e21a61213></td>
<td align=center><img alt="Padding full" class=img-responsive netsrc=teaching/cs-230/illustrations/ src=padding-full-a.png?b51e98467c8a77574c7e8f108654ad95></td>
</tr>
<tr>
<td align=center><b>Цель</b></td>
<td align=left>• Без дополнения<br>• Отбрасывает последнюю свертку при несовпадении размеров</td>
<td align=left>• Padding such that feature map size has size $\Bigl\lceil\frac{I}{S}\Bigr\rceil$<br>• Размер вывода математически удобен<br>• Также называется 'половинным' дополнением</td>
<td align=left>• Максимальное дополнение. С ним концевые свертки применяются к пределам ввода<br>• Фильтр 'видит' вход от начала до конца</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#hyperparameters id=hyperparameters></a>Настройка гиперпараметров</h2>
<p><span class="new-item item-r">Совместимость параметров в сверточном слое</span> Обозначим $I$ длину входного размера объёма, $F$ длину фильтра, $P$ длину дополнения нулями, $S$ шаг, затем выходной размер $O$ карты функций по этому измерению определяется как:</p>
<div class=mobile-container>
\[\boxed{O=\frac{I-F+P_\text{start} + P_\text{end}}{S}+1}\]
</div>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=parameter-compatibility-en.jpeg?bc91caf0473dc42f1a495946f67726d3 style=width:100%;max-width:630px>
</center>
</div>
<br>
<p><span class=remark>Remark: often times, $P_\text{start} = P_\text{end} \triangleq P$, in which case we can replace $P_\text{start} + P_\text{end}$ by $2P$ in the formula above.</span></p>
<br>
<p><span class="new-item item-r">Понимание сложности модели</span> Чтобы оценить сложность модели, часто бывает полезно определить количество параметров, которые будет иметь её архитектура. В данном слое сверточной нейронной сети это делается следующим образом:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:680px; max-width:900px;">
<colgroup>
<col style=width:120px>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>CONV</b></td>
<td align=center><b>POOL</b></td>
<td align=center><b>FC</b></td>
</tr>
<tr>
<td align=center><b>Иллюстрация</b></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=table-conv.png?79f617dcf0ac221ddfaf21694f6e08ad style="width:100%; max-width:155px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=table-pool.png?e8528df02bafea0840916a83482e42e9 style="width:100%; max-width:155px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=table-fc.png?0074d2fdaa632e724022c13e94a49a22 style="width:100%; max-width:155px;"></td>
</tr>
<tr>
<td align=center><b>Входной размер</b></td>
<td align=center>$I \times I \times C$</td>
<td align=center>$I \times I \times C$</td>
<td align=center>$N_{\text{in}}$</td>
</tr>
<tr>
<td align=center><b>Выходной размер</b></td>
<td align=center>$O \times O \times K$</td>
<td align=center>$O \times O \times C$</td>
<td align=center>$N_{\text{out}}$</td>
</tr>
<tr>
<td align=center><b>Количество параметров</b></td>
<td align=center>$(F \times F \times C + 1) \cdot K$</td>
<td align=center>$0$</td>
<td align=center>$(N_{\text{in}} + 1 ) \times N_{\text{out}}$</td>
</tr>
<tr>
<td align=center><b>Примечания</b></td>
<td align=left>• Один параметр смещения на фильтр<br>
                 • In most cases, $S &lt; F$<br>
                 • A common choice for $K$ is $2C$</td>
<td align=left>• Операция пулинга выполняется поканально<br>
                 • In most cases, $S = F$</td>
<td align=left>• Ввод сглаживается<br>
                 • Один параметр смещения на нейрон<br>
                 • Количество нейронов FC не имеет структурных ограничений</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Receptive field</span> The receptive field at layer $k$ is the area denoted $R_k \times R_k$ of the input that each pixel of the $k$-th activation map can 'see'.
By calling $F_j$ the filter size of layer $j$ and $S_i$ the stride value of layer $i$ and with the convention $S_0 = 1$, the receptive field at layer $k$ can be computed with the formula:
</p><div class=mobile-container>
\[\boxed{R_k = 1 + \sum_{j=1}^{k} (F_j - 1) \prod_{i=0}^{j-1} S_i}\]
</div>
<p><i>In the example below, we have $F_1 = F_2 = 3$ and $S_1 = S_2 = 1$, which gives $R_2 = 1 + 2\cdot 1 + 2\cdot 1 = 5$.</i></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=receptive-field-a.png?3f718275d9c2de56f2255b2a4797ea87 style=width:100%;max-width:450px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#activation-function id=activation-function></a>Часто используемые функции активации</h2>
<p><span class="new-item item-g">Блок линейной ректификации</span> Rectified Linear Unit layer (ReLU) - это функция активации $g$, которая используется для всех элементов объёма. Он направлен на привнесение в сеть нелинейностей. Его варианты приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:650px;">
<colgroup>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b>ReLU</b></td>
<td align=center><b>ReLU с утечкой</b></td>
<td align=center><b>ELU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\max(0,z)$</td>
<td align=center>$g(z)=\max(\epsilon z,z)$<br>
                   with $\epsilon\ll1$</td>
<td align=center>$g(z)=\max(\alpha(e^z-1),z)$<br>
                   with $\alpha\ll1$</td>
</tr>
<tr>
<td align=center><img alt=ReLU class=img-responsive netsrc=teaching/cs-229/illustrations/ src=relu.png?6c1d78551355db5c6e4f6f8b5282cfa8 style="width:100%; max-width:200px;"></td>
<td align=center><img alt="Leaky ReLU" class=img-responsive netsrc=teaching/cs-229/illustrations/ src=leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e style="width:100%; max-width:200px;"></td>
<td align=center><img alt=ELU class=img-responsive netsrc=teaching/cs-230/illustrations/ src=elu.png?d195c8a479724512b56ff0da101361a6 style="width:100%; max-width:200px;"></td>
</tr>
<tr>
<td align=left>• Сложности нелинейности поддаются биологической интерпретации</td>
<td align=left>• Решает проблему умирания ReLU для отрицательных значений</td>
<td align=left>• Дифференцируема везде</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Softmax</span> The softmax step can be seen as a generalized logistic function that takes as input a vector of scores $x\in\mathbb{R}^n$ and outputs a vector of output probability $p\in\mathbb{R}^n$ through a softmax function at the end of the architecture. It is defined as follows:</p>
<div class=mobile-container>
\[\boxed{p=\begin{pmatrix}p_1\\\vdots\\p_n\end{pmatrix}}\quad\textrm{where}\quad\boxed{p_i=\frac{e^{x_i}}{\displaystyle\sum_{j=1}^ne^{x_j}}}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#object-detection id=object-detection></a>Обнаружение объектов</h2>
<p><span class="new-item item-r">Виды моделей</span> Существует 3 основных типа алгоритмов распознавания объектов, для которых характер предсказаний различен. Они описаны в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:600px; max-width:780px;">
<colgroup>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Классификация изображений</b></td>
<td align=center><b>Классификация и локализация</b></td>
<td align=center><b>Обнаружение</b></td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=object-detection-clas-en.jpeg?f380203d7e5d88936e654205473e86c2></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=object-detection-loc-en.jpeg?f8ec96e14fb13f2515f2c179cd326545></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=object-detection-det-en.jpeg?f735de7d1c1bccd2ff1c864b587ad842></td>
</tr>
<tr>
<td align=left>• Классифицирует картинку<br>
                 • Прогнозирует вероятность объекта</td>
<td align=left>• Обнаруживает объект на картинке<br>
                 • Прогнозирует вероятность объекта and where it is located</td>
<td align=left>• Обнаруживает до нескольких объектов на картинке<br>
                 • Прогнозирует вероятности появления объектов и их местонахождение</td>
</tr>
<tr>
<td align=left>Традиционная CNN</td>
<td align=left>Simplified YOLO, R-CNN</td>
<td align=left>YOLO, R-CNN</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Обнаружение</span> В контексте обнаружения объекта используются разные методы в зависимости от того, хотим ли мы просто найти объект или обнаружить более сложную форму на изображении (ориентир, Landmark, Reference point). Два основных из них суммированы в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:300px; max-width:800px;">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Обнаружение ограничивающей рамки</b></td>
<td align=center><b>Обнаружение ориентира</b></td>
</tr>
<tr>
<td align=left>• Обнаруживает часть изображения c объектом</td>
<td align=left>• Обнаруживает форму или характеристики объекта (например: глаза)<br>
                 • Более детализировано</td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=detection-bounding-box.jpeg?4fab94de8d967605519bfc6bafd14df3 style="width:100%; max-width:300px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=detection-landmark.jpeg?ed85ca8d6c2673f35e8c266c5476690f style="width:100%; max-width:300px;"></td>
</tr>
<tr>
<td align=left>Box of center $(b_x,b_y)$, height $b_h$ and width $b_w$</td>
<td align=left>Reference points $(l_{1x},l_{1y}),$ $...,$ $(l_{nx},l_{ny})$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Intersection over Union</span> Intersection over Union, also known as $\textrm{IoU}$, is a function that quantifies how correctly positioned a predicted bounding box $B_p$ is over the actual bounding box $B_a$. It is defined as:</p>
<div class=mobile-container>
\[\boxed{\textrm{IoU}(B_p,B_a)=\frac{B_p\cap B_a}{B_p\cup B_a}}\]
</div>
<p><span class=remark>Remark: we always have $\textrm{IoU}\in[0,1]$. By convention, a predicted bounding box $B_p$ is considered as being reasonably good if $\textrm{IoU}(B_p,B_a)\geqslant0.5$.</span></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=intersection-over-union.jpeg?43dc827ff1461e0391da237a455d69ef style="width:100%; max-width:750px;">
</center>
</div>
<br>
<p><span class="new-item item-b">Якорные рамки</span> Anchor box - это метод, используемый для прогнозирования перекрывающихся ограничивающих рамок. На практике сети позволяют прогнозировать более одной рамки одновременно, причем каждое предсказание рамки ограничивается заданным набором геометрических свойств. Например, первый прогноз потенциально может быть прямоугольной рамкой заданной формы, а второй будет другой прямоугольной рамкой с другими параметрами.</p>
<br>
<p><span class="new-item item-b">Подавление немаксимума</span> Non-max suppression - Техника подавления немаксимальных направлена на удаление дублирующих перекрывающихся ограничивающих рамок одного и того же объекта путем выбора наиболее репрезентативных. После удаления всех рамок, имеющих прогноз вероятности ниже 0.6, следующие шаги повторяются, пока остаются рамки:</p>
<p>Для данного класса,
<br>• Шаг 1: Выберите рамку с наибольшей вероятностью прогноза.
<br>• Step 2: Discard any box having an $\textrm{IoU}\geqslant0.5$ with the previous box.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=non-max-suppression-en.jpeg?9cca7cb1256642553de7ffeba7fe0577 style=width:100%;>
</center>
</div>
<br>
<p><span class="new-item item-r">YOLO</span> You Only Look Once (YOLO) - это алгоритм обнаружения объектов, который выполняет следующие шаги:</p>
<p>• Step 1: Divide the input image into a $G\times G$ grid.
<br>• Шаг 2: Для каждой ячейки сетки запустите CNN, которая предсказывает $y$ в следующей форме:
</p><div class=mobile-container>
\[\boxed{y=\big[\underbrace{p_c,b_x,b_y,b_h,b_w,c_1,c_2,...,c_p}_{\textrm{repeated }k\textrm{ times}},...\big]^T\in\mathbb{R}^{G\times G\times k\times(5+p)}}\]
</div>
where $p_c$ is the probability of detecting an object, $b_x,b_y,b_h,b_w$ are the properties of the detected bouding box, $c_1,...,c_p$ is a one-hot representation of which of the $p$ classes were detected, and $k$ is the number of anchor boxes.
<br>• Шаг 3: Запустить алгоритм подавления немаксимальных значений, чтобы удалить любые потенциально повторяющиеся перекрывающиеся ограничивающие рамки.<p></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=yolo-en.jpeg?1eff4444ea01396f48e793bec5f2ef3b style=width:100%;>
</center>
</div>
<br>
<p><span class=remark>Remark: when $p_c=0$, then the network does not detect any object. In that case, the corresponding predictions $b_x, ..., c_p$ have to be ignored.</span></p>
<br>
<p><span class="new-item item-r">R-CNN</span> Region with Convolutional Neural Networks (R-CNN) - это алгоритм обнаружения объектов, который сначала сегментирует изображение, чтобы найти потенциально релевантные ограничивающие рамки, а затем запускает алгоритм обнаружения, чтобы найти наиболее вероятные объекты в этих ограничивающих рамках.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=r-cnn-en.jpeg?5bb82ac3b9da8171d5c8a741861c3aa6 style=width:100%;>
</center>
</div>
<br>
<p><span class=remark>Примечание: хотя исходный алгоритм является дорогостоящим и медленным в вычислительном отношении, новые архитектуры позволили алгоритму работать быстрее, например Fast R-CNN и Faster R-CNN.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#face id=face></a>Проверка и распознавание лиц</h2>
<p><span class="new-item item-g">Типы моделей</span> В таблице ниже приведены два основных типа моделей:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:300px; max-width: 700px;">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Проверка лица</b></td>
<td align=center><b>Распознавание лиц</b></td>
</tr>
<tr>
<td align=left>• Это правильный человек?<br>
                 • Один-к-одному поиск</td>
<td align=left>• Это одно из $K$ лиц в базе данных?<br>
                 • Один-к-многим поиск</td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=face-verification-en.jpeg?9b6ea3c15805347193943fe09692f71b style="width:100%; max-width:300px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=face-recognition-en.jpeg?ed30504000897087c2549f4f964c9441 style="width:100%; max-width:300px;"></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-b">One Shot Learning</span> One Shot Learning is a face verification algorithm that uses a limited training set to learn a similarity function that quantifies how different two given images are. The similarity function applied to two images is often noted $d(\textrm{image 1}, \textrm{image 2}).$</p>
<br>
<p><span class="new-item item-r">Siamese Network</span> Siamese Networks aim at learning how to encode images to then quantify how different two images are. For a given input image $x^{(i)}$, the encoded output is often noted as $f(x^{(i)})$.</p>
<br>
<p><span class="new-item item-g">Triplet loss</span> The triplet loss $\ell$ is a loss function computed on the embedding representation of a triplet of images $A$ (anchor), $P$ (positive) and $N$ (negative). The anchor and the positive example belong to a same class, while the negative example to another one. By calling $\alpha\in\mathbb{R}^+$ the margin parameter, this loss is defined as follows:</p>
<div class=mobile-container>
\[\boxed{\ell(A,P,N)=\max\left(d(A,P)-d(A,N)+\alpha,0\right)}\]
</div>
<center>
  <div class=row>
      <div class="col-xs-6 col-md-6"><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=triplet-loss-1.png?b18c14e9714ee258b805cb71ac498f4e style="width:100%; max-width:280px"></div>
      <div class="col-xs-6 col-md-6"><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=triplet-loss-2.png?952990aae18c538c4bb2d93434342c52 style="width:100%; max-width:280px"></div>
  </div>
</center>
<br>
<h2><a aria-hidden=true class=anchor href=#style-transfer id=style-transfer></a>Перенос нейронного стиля</h2>
<p><span class="new-item item-g">Motivation</span> The goal of neural style transfer is to generate an image $G$ based on a given content $C$ and a given style $S$.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=neural-style-motivation-en.jpeg?6b66c6e6a11a720c49301837f7834a61 style=width:100%;>
</center>
</div>
<br>
<p><span class="new-item item-b">Activation</span> In a given layer $l$, the activation is noted $a^{[l]}$ and is of dimensions $n_H\times n_w\times n_c$</p>
<br>
<p><span class="new-item item-r">Content cost function</span> The content cost function $J_{\textrm{content}}(C,G)$ is used to determine how the generated image $G$ differs from the original content image $C$. It is defined as follows:</p>
<div class=mobile-container>
\[\boxed{J_{\textrm{content}}(C,G)=\frac{1}{2}||a^{[l](C)}-a^{[l](G)}||^2}\]
</div>
<br>
<p><span class="new-item item-g">Style matrix</span> The style matrix $G^{[l]}$ of a given layer $l$ is a Gram matrix where each of its elements $G_{kk'}^{[l]}$ quantifies how correlated the channels $k$ and $k'$ are. It is defined with respect to activations $a^{[l]}$ as follows:</p>
<div class=mobile-container>
\[\boxed{G_{kk'}^{[l]}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_w^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}}\]
</div>
<p><span class=remark>Remark: the style matrix for the style image and the generated image are noted $G^{[l](S)}$ and $G^{[l](G)}$ respectively.</span></p>
<br>
<p><span class="new-item item-r">Style cost function</span> The style cost function $J_{\textrm{style}}(S,G)$ is used to determine how the generated image $G$ differs from the style $S$. It is defined as follows:</p>
<div class=mobile-container>
\[\boxed{J_{\textrm{style}}^{[l]}(S,G)=\frac{1}{(2n_Hn_wn_c)^2}||G^{[l](S)}-G^{[l](G)}||_F^2=\frac{1}{(2n_Hn_wn_c)^2}\sum_{k,k'=1}^{n_c}\Big(G_{kk'}^{[l](S)}-G_{kk'}^{[l](G)}\Big)^2}\]
</div>
<br>
<p><span class="new-item item-b">Overall cost function</span> The overall cost function is defined as being a combination of the content and style cost functions, weighted by parameters $\alpha,\beta$, as follows:</p>
<div class=mobile-container>
\[\boxed{J(G)=\alpha J_{\textrm{content}}(C,G)+\beta J_{\textrm{style}}(S,G)}\]
</div>
<p><span class=remark>Remark: a higher value of $\alpha$ will make the model care more about the content while a higher value of $\beta$ will make it care more about the style.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#ct-architectures id=ct-architectures></a>Архитектуры с использованием вычислительных трюков</h2>
<p><span class="new-item item-r">Генеративные состязательные сети</span> Generative adversarial networks, также известные как GANs, состоят из генеративной и дискриминативной моделей, где генеративная модель направлена на генерирование наиболее правдивого вывода, который будет передан дискриминативной модели, направленной на различение созданного и истинного изображения.</p>
<div class=mobile-container>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=discriminator-generator-en.jpeg?850896147a318376ce537812fbefe3a8>
</div>
<br>
<p><span class=remark>Примечание: варианты использования с вариантами GAN включают текст в изображение, создание музыки и синтез.</span></p>
<br>
<p><span class="new-item item-r">Residual Network architecture</span> (также называется ResNet) использует остаточные блоки с большим количеством слоев, чтобы уменьшить ошибку обучения. Остаточный блок имеет следующее характеристическое уравнение:</p>
<div class=mobile-container>
\[\boxed{a^{[l+2]}=g(a^{[l]}+z^{[l+2]})}\]
</div>
<br>
<p><span class="new-item item-r">Inception Network</span> This architecture uses inception modules and aims at giving a try at different convolutions in order to increase its performance through features diversification. In particular, it uses the $1\times1$ convolution trick to limit the computational burden. </p>
<br>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>