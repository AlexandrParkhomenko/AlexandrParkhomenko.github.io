<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 230 - Convolutional Neural Networks Cheatsheet</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport>
<link href=https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-230 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 15px;">   <b>CS 230 - Глубокое обучение</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Convolutional Neural Nets</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#overview>Обзор</a></div> <div class=dropdown-container> <a href=#overview><span>Структура архитектуры</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#layer>Типы слоёв</a></div> <div class=dropdown-container> <a href=#layer><span>Свертка</span></a> <a href=#layer><span>Пулинг</span></a> <a href=#layer><span>Полносвязный</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#filter>Фильтрация гиперпараметров</a></div> <div class=dropdown-container> <a href=#filter><span>Размеры</span></a> <a href=#filter><span>Шаг</span></a> <a href=#filter><span>Дополнение</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#hyperparameters>Настройка гиперпараметров</a></div> <div class=dropdown-container> <a href=#hyperparameters><span>Совместимость параметров</span></a> <a href=#hyperparameters><span>Сложность модели</span></a> <a href=#hyperparameters><span>Рецептивное поле</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#activation-function>Функции активации</a></div> <div class=dropdown-container> <a href=#activation-function><span>Блок линейной ректификации</span></a> <a href=#activation-function><span>Softmax</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#object-detection>Обнаружение объектов</a></div> <div class=dropdown-container> <a href=#object-detection><span>Типы моделей</span></a> <a href=#object-detection><span>Обнаружение</span></a> <a href=#object-detection><span>Пересечение по объединению</span></a> <a href=#object-detection><span>Подавление немаксимумов</span></a> <a href=#object-detection><span>YOLO</span></a> <a href=#object-detection><span>R-CNN</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#face>Проверка/распознавание лиц</a></div> <div class=dropdown-container> <a href=#face><span>Обучение с первого раза</span></a> <a href=#face><span>Сиамская сеть</span></a> <a href=#face><span>Triplet loss</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#style-transfer>Нейронный перенос стиля</a></div> <div class=dropdown-container> <a href=#style-transfer><span>Активация</span></a> <a href=#style-transfer><span>Матрица стиля</span></a> <a href=#style-transfer><span>Функция стоимости стиля/контента</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#ct-architectures>Архитектуры с вычислительными трюками</a></div> <div class=dropdown-container> <a href=#ct-architectures><span>Generative Adversarial Net</span></a> <a href=#ct-architectures><span>ResNet</span></a> <a href=#ct-architectures><span>Inception Network</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/cheatsheet-convolutional-neural-networks.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> Посмотреть PDF-версию на GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE --><a aria-hidden=true class=anchor-bis href=#cs-230---deep-learning id=cs-230---deep-learning></a><a href=teaching/cs-230 onclick=trackOutboundLink(this);>CS 230 - Глубокое обучение</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option selected value=en>English</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ja>日本語</option>
        <option value=ko>한국어</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>CS 221 - Artificial Intelligence</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>CS 229 - Machine Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button><B>CS 230 - Глубокое обучение</B></BUTTON>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button><B>Convolutional Neural Networks</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/recurrent-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-recurrent-neural-networks'" type=button>Recurrent Neural Networks</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/deep-learning-tips-and-tricks/index.html'; oldhref='teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks'" type=button>Tips and tricks</button>
  </div>
</div>

<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Шпаргалка по Сверточным Нейронным Сетям
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-230-deep-learning on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-230-deep-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<i><!-- By --><a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> и <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a>;<a href=https://github.com/AlexandrParkhomenko onclick=trackOutboundLink(this);> Alexandr Parkhomenko</a> и <a href=https://github.com/geotrush onclick=trackOutboundLink(this);>Труш Георгий (Georgy Trush)</a></i>
<h2><a aria-hidden=true class=anchor href=#overview id=overview></a>Обзор</h2>
<p><span class="new-item item-r">Архитектура классической CNN</span> Сверточные нейронные сети, также известные как (Convolutional neural networks, CNN), представляют собой особый тип нейронных сетей, которые обычно состоят из следующих слоев:</p>
<div class=mobile-container>
<center>
  <img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=architecture-cnn-en.jpeg?3b7fccd728e29dc619e1bd8022bf71cf style=width:100%;max-width:900px>
</center>
</div>
<br>
<p>Слой свертки и слой пулинга можно настроить с учетом гиперпараметров, которые описаны в следующих разделах.</p>
<br>
<h2><a aria-hidden=true class=anchor href=#layer id=layer></a>Типы слоёв</h2>
<p><span class="new-item item-b">Слой свертки</span> Convolution layer (CONV) использует фильтры, которые выполняют операции свертки при сканировании входа $I$ относительно его размеров. Его гиперпараметры включают размер фильтра $F$ и шаг $S$. Полученный результат $O$ называется картой признаков или картой активации.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=convolution-layer-a.png?1c517e00cb8d709baf32fc3d39ebae67 style=width:100%;max-width:450px>
</center>
</div>
<br>
<p><span class=remark>Примечание: шаг свертки также может быть обобщен на одномерные и трехмерные случаи.</span></p>
<br>
<p><span class="new-item item-b">Слой Пулинга</span> Pooling (POOL) - это операция понижающей дискретизации, обычно применяемая после сверточного слоя, который обеспечивает некоторую пространственную инвариантность изображенных объектов. В частности, max-пулинг и усредненный пулинг - это особые виды пулинга, в которых берется максимальное и среднее значение соответственно.</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:400px; max-width:720px;">
<colgroup>
<col style=width:115px>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Тип</b></td>
<td align=center>Max-пулинг</td>
<td align=center>Усредненный пулинг</td>
</tr>
<tr>
<td align=center><b>Цель</b></td>
<td align=left>Каждая операция пулинга выбирает максимальное значение текущего представления</td>
<td align=left>Каждая операция пулинга усредняет значения текущего представления</td>
</tr>
<tr>
<td align=center><b>Иллюстрация</b></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=max-pooling-a.png?711b14799d07f9306864695e2713ae07></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=average-pooling-a.png?58f9ab6d61248c3ec8d526ef65763d2f></td>
</tr>
<tr>
<td align=center><b>Комментарии</b></td>
<td align=left>• Сохраняет обнаруженные признаки<br>• Наиболее часто используемые
</td>
<td align=left>• Уменьшает размерность карты признаков<br>• Используется в LeNet</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-b">Полносвязный</span> Fully Connected (FC) слой работает на сглаженном входе, где каждый вход подключен ко всем нейронам. Уровни FC, если они присутствуют, обычно находятся ближе к концу архитектур CNN и могут использоваться для оптимизации целевых метрик, таких как оценки классов.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=fully-connected-ltr.png?32caf9e07c79d652faa292812579d063 style="width:100%; max-width:500px;">
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#filter id=filter></a>Фильтрация гиперпараметров</h2>
<p>Слой свертки содержит фильтры, для которых важно знать значение его гиперпараметров.</p>
<p><span class="new-item item-b">Размеры фильтра</span> Фильтр размера $F\times F$, применяемый к входу, содержащему каналы $C$, представляет собой объём $F \times F \times C$, который выполняет свертки на входе размера $I \times I \times C$ и создает карту выходных признаков (также называемую картой активации) размера $O \times O \times 1$.
</p><div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=dimensions-filter-en.png?7ce161e129a392a1804a231536b59f45 style=width:100%;>
</center>
</div>
<br>
<i>Примечание: применение $K$ фильтров размера $F\times F$ приводит к выходной карте признаков размером $O \times O \times K$.</i>
<br><br>
<p><span class="new-item item-b">Шаг</span> $S$tride - Для сверточной операции или операции пулинга шаг $S$ обозначает количество пикселей, на которое окно перемещается после каждой операции.
</p><div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=stride.png?36b5b2e02f7e02c3c4075a9d836c048c style=width:100%;max-width:700px>
</center>
</div>
<br>
<br>
<p><span class="new-item item-b">Дополнение нулями</span> Zero-padding означает процесс добавления $P$ нулей к каждой стороне входного изображения. Это значение можно указать вручную или автоматически в одном из трех режимов, описанных ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:700px;">
  <colgroup>
    <col style=width:115px;>
    <col style=width:33%>
    <col style=width:33%>
    <col style=width:33%>
  </colgroup>
<tbody>
<tr>
<td align=center><b>Режим</b></td>
<td align=center>Действительный</td>
<td align=center>Такой же</td>
<td align=center>Полный</td>
</tr>
<tr>
<td align=center><b>Значение</b></td>
<td align=center>$P = 0$</td>
<td align=left>$P_\text{start} = \Bigl\lfloor\frac{S \lceil\frac{I}{S}\rceil - I + F - S}{2}\Bigr\rfloor$<br>$P_\text{end} = \Bigl\lceil\frac{S \lceil\frac{I}{S}\rceil - I + F - S}{2}\Bigr\rceil$</td>
<td align=left>$P_\text{start}\in[\![0,F-1]\!]$<br><br>$P_\text{end} = F-1$</td>
</tr>
<tr>
<td align=center><b>Иллюстрация</b></td>
<td align=center><img alt="Padding valid" class=img-responsive netsrc=teaching/cs-230/illustrations/ src=padding-valid-a.png?1f58d78612f6202ce201620919d71609></td>
<td align=center><img alt="Padding same" class=img-responsive netsrc=teaching/cs-230/illustrations/ src=padding-same-a.png?8b680283b10a6e131209b74e21a61213></td>
<td align=center><img alt="Padding full" class=img-responsive netsrc=teaching/cs-230/illustrations/ src=padding-full-a.png?b51e98467c8a77574c7e8f108654ad95></td>
</tr>
<tr>
<td align=center><b>Цель</b></td>
<td align=left>• Без дополнения<br>• Отбрасывает последнюю свертку при несовпадении размеров</td>
<td align=left>• Дополнения для карты признаков с размерами $\Bigl\lceil\frac{I}{S}\Bigr\rceil$<br>• Размер вывода математически удобен<br>• Также называется 'половинным' дополнением</td>
<td align=left>• Максимальное дополнение. С ним концевые свертки применяются к границам входа<br>• Фильтр 'видит' вход от начала до конца</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#hyperparameters id=hyperparameters></a>Настройка гиперпараметров</h2>
<p><span class="new-item item-r">Совместимость параметров в сверточном слое</span> Обозначим $I$ длину входного размера объёма, $F$ длину фильтра, $P$ длину дополнения нулями, $S$ шаг, затем выходной размер $O$ карты признаков по этому измерению определяется как:</p>
<div class=mobile-container>
\[\boxed{O=\frac{I-F+P_\text{start} + P_\text{end}}{S}+1}\]
</div>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=parameter-compatibility-en.jpeg?bc91caf0473dc42f1a495946f67726d3 style=width:100%;max-width:630px>
</center>
</div>
<br>
<p><span class=remark>Примечание: часто $P_\text{start} = P_\text{end} \triangleq P$, и в этом случае мы можем заменить $P_\text{start} + P_\text{end}$ на $2P$ в формуле выше.</span></p>
<br>
<p><span class="new-item item-r">Понимание сложности модели</span> Чтобы оценить сложность модели, часто бывает полезно определить количество параметров, которые будет иметь её архитектура. В данном слое сверточной нейронной сети это делается следующим образом:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:680px; max-width:900px;">
<colgroup>
<col style=width:120px>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center></td>
<td align=center><b>CONV</b></td>
<td align=center><b>POOL</b></td>
<td align=center><b>FC</b></td>
</tr>
<tr>
<td align=center><b>Иллюстрация</b></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=table-conv.png?79f617dcf0ac221ddfaf21694f6e08ad style="width:100%; max-width:155px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=table-pool.png?e8528df02bafea0840916a83482e42e9 style="width:100%; max-width:155px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=table-fc.png?0074d2fdaa632e724022c13e94a49a22 style="width:100%; max-width:155px;"></td>
</tr>
<tr>
<td align=center><b>Входной размер</b></td>
<td align=center>$I \times I \times C$</td>
<td align=center>$I \times I \times C$</td>
<td align=center>$N_{\text{in}}$</td>
</tr>
<tr>
<td align=center><b>Выходной размер</b></td>
<td align=center>$O \times O \times K$</td>
<td align=center>$O \times O \times C$</td>
<td align=center>$N_{\text{out}}$</td>
</tr>
<tr>
<td align=center><b>Количество параметров</b></td>
<td align=center>$(F \times F \times C + 1) \cdot K$</td>
<td align=center>$0$</td>
<td align=center>$(N_{\text{in}} + 1 ) \times N_{\text{out}}$</td>
</tr>
<tr>
<td align=center><b>Примечания</b></td>
<td align=left>• Один параметр смещения на фильтр<br>
                 • В большинстве случаев, $S &lt; F$<br>
                 • Обычный выбор для $K$ - это $2C$</td>
<td align=left>• Операция пулинга выполняется поканально<br>
                 • В большинстве случаев, $S = F$</td>
<td align=left>• Вход сглаживается<br>
                 • Один параметр смещения на нейрон<br>
                 • Количество нейронов FC не имеет структурных ограничений</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Рецептивное поле</span> Воспринимающее поле в слое $k$ - это область, обозначенная $R_k \times R_k$ входа, которую может "видеть" каждый пиксель $k$-й карты активации. Называя $F_j$ размером фильтра слоя $j$, а $S_i$ значением шага слоя $i$, и, согласно соглашению $S_0 = 1$, рецептивное поле на слое $k$ можно вычислить по формуле:
</p><div class=mobile-container>
\[\boxed{R_k = 1 + \sum_{j=1}^{k} (F_j - 1) \prod_{i=0}^{j-1} S_i}\]
</div>
<p><i>В приведенном ниже примере у нас есть $F_1 = F_2 = 3$ и $S_1 = S_2 = 1$, который дает $R_2 = 1 + 2\cdot 1 + 2\cdot 1 = 5$.</i></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=receptive-field-a.png?3f718275d9c2de56f2255b2a4797ea87 style=width:100%;max-width:450px>
</center>
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#activation-function id=activation-function></a>Часто используемые функции активации</h2>
<p><span class="new-item item-g">Блок линейной ректификации</span> Блок линейной ректификации layer (ReLU) - это функция активации $g$, которая используется для всех элементов объёма. Он направлен на привнесение в сеть нелинейностей. Его варианты приведены в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:650px;">
<colgroup>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b>ReLU</b></td>
<td align=center><b>ReLU с утечкой</b></td>
<td align=center><b>ELU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\max(0,z)$</td>
<td align=center>$g(z)=\max(\epsilon z,z)$<br>
                   with $\epsilon\ll1$</td>
<td align=center>$g(z)=\max(\alpha(e^z-1),z)$<br>
                   with $\alpha\ll1$</td>
</tr>
<tr>
<td align=center><img alt=ReLU class=img-responsive netsrc=teaching/cs-229/illustrations/ src=relu.png?6c1d78551355db5c6e4f6f8b5282cfa8 style="width:100%; max-width:200px;"></td>
<td align=center><img alt="ReLU с утечкой" class=img-responsive netsrc=teaching/cs-229/illustrations/ src=leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e style="width:100%; max-width:200px;"></td>
<td align=center><img alt=ELU class=img-responsive netsrc=teaching/cs-230/illustrations/ src=elu.png?d195c8a479724512b56ff0da101361a6 style="width:100%; max-width:200px;"></td>
</tr>
<tr>
<td align=left>• Сложности нелинейности поддаются биологической интерпретации</td>
<td align=left>• Решает проблему зануления ReLU отрицательных значений</td>
<td align=left>• Дифференцируема везде</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Softmax</span> Шаг softmax можно рассматривать как обобщенную логистическую функцию, которая принимает на вход вектор оценок $x\in\mathbb{R}^n$ и выводит вектор выходной вероятности $p\in\mathbb{R}^n$ через функцию softmax в конце архитектуры. Это определяется следующим образом:</p>
<div class=mobile-container>
\[\boxed{p=\begin{pmatrix}p_1\\\vdots\\p_n\end{pmatrix}}\quad\textrm{где}\quad\boxed{p_i=\frac{e^{x_i}}{\displaystyle\sum_{j=1}^ne^{x_j}}}\]
</div>
<br>
<h2><a aria-hidden=true class=anchor href=#object-detection id=object-detection></a>Обнаружение объектов</h2>
<p><span class="new-item item-r">Виды моделей</span> Существует 3 основных типа алгоритмов распознавания объектов, для которых характер предсказаний различен. Они описаны в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:600px; max-width:780px;">
<colgroup>
<col style=width:33%>
<col style=width:33%>
<col style=width:33%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Классификация изображений</b></td>
<td align=center><b>Классификация и локализация</b></td>
<td align=center><b>Обнаружение</b></td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=object-detection-clas-en.jpeg?f380203d7e5d88936e654205473e86c2></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=object-detection-loc-en.jpeg?f8ec96e14fb13f2515f2c179cd326545></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=object-detection-det-en.jpeg?f735de7d1c1bccd2ff1c864b587ad842></td>
</tr>
<tr>
<td align=left>• Классифицирует картинку<br>
                 • Прогнозирует вероятность объекта</td>
<td align=left>• Обнаруживает объект на картинке<br>
                 • Прогнозирует вероятность объекта and where it is located</td>
<td align=left>• Обнаруживает до нескольких объектов на картинке<br>
                 • Прогнозирует вероятности появления объектов и их местонахождение</td>
</tr>
<tr>
<td align=left>Классическая CNN</td>
<td align=left>Упрощенный YOLO, R-CNN</td>
<td align=left>YOLO, R-CNN</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Обнаружение</span> В контексте обнаружения объекта используются разные методы в зависимости от того, хотим ли мы просто найти объект или обнаружить более сложную форму на изображении (ориентир, Landmark, Reference point). Два основных из них суммированы в таблице ниже:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:300px; max-width:800px;">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Обнаружение ограничивающей рамки</b></td>
<td align=center><b>Обнаружение ориентира</b></td>
</tr>
<tr>
<td align=left>• Обнаруживает часть изображения c объектом</td>
<td align=left>• Обнаруживает форму или характеристики объекта (например: глаза)<br>
                 • Более детализировано</td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=detection-bounding-box.jpeg?4fab94de8d967605519bfc6bafd14df3 style="width:100%; max-width:300px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=detection-landmark.jpeg?ed85ca8d6c2673f35e8c266c5476690f style="width:100%; max-width:300px;"></td>
</tr>
<tr>
<td align=left>Рамка с центром $(b_x,b_y)$, высота $b_h$ и ширина $b_w$</td>
<td align=left>Ориентиры $(l_{1x},l_{1y}), ..., (l_{nx},l_{ny})$</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-g">Пересечение по объединению</span> Пересечение по объединению (IoU) - это функция, которая количественно определяет, насколько правильно расположена предсказанная ограничивающая рамка $B_p$ над фактической ограничительной рамкой $B_a$. Она определяется как:</p>
<div class=mobile-container>
\[\boxed{\textrm{IoU}(B_p,B_a)=\frac{B_p\cap B_a}{B_p\cup B_a}}\]
</div>
<p><span class=remark>Примечание: у нас всегда есть $\textrm{IoU}\in[0,1]$. По соглашению, прогнозируемая ограничивающая рамка $B_p$ считается достаточно хорошей, если $\textrm{IoU}(B_p,B_a)\geqslant0.5$.</span></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=intersection-over-union.jpeg?43dc827ff1461e0391da237a455d69ef style="width:100%; max-width:750px;">
</center>
</div>
<br>
<p><span class="new-item item-b">Якорные рамки</span> Anchor box - это метод, используемый для прогнозирования перекрывающихся ограничивающих рамок. На практике сети позволяют прогнозировать более одной рамки одновременно, причем каждое предсказание рамки ограничивается заданным набором геометрических свойств. Например, первый прогноз потенциально может быть прямоугольной рамкой заданной формы, а второй будет другой прямоугольной рамкой с другими параметрами.</p>
<br>
<p><span class="new-item item-b">Подавление немаксимумов</span> Non-max suppression - Техника подавления немаксимумов направлена на удаление дублирующих перекрывающихся ограничивающих рамок одного и того же объекта путем выбора наиболее репрезентативных рамок. После удаления всех рамок, имеющих прогноз вероятности ниже 0.6, следующие шаги повторяются до тех пор, пока остаются рамки:</p>
<p>Для данного класса,
<br>• Шаг 1: Выберите рамку с наибольшей вероятностью прогноза.
<br>• Шаг 2: Отбросьте любую рамку с $\textrm{IoU}\geqslant0.5$ по сравнению с предыдущей рамкой.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=non-max-suppression-en.jpeg?9cca7cb1256642553de7ffeba7fe0577 style=width:100%;>
</center>
</div>
<br>
<p><span class="new-item item-r">YOLO</span> You Only Look Once (YOLO) - это алгоритм обнаружения объектов, который выполняет следующие шаги:</p>
<p>• Шаг 1: Разделить входное изображение на сетку $G\times G$.
<br>• Шаг 2: Для каждой ячейки сетки запустите CNN, которая предсказывает $y$ в следующей форме:
</p><div class=mobile-container>
\[\boxed{y=\big[\underbrace{p_c,b_x,b_y,b_h,b_w,c_1,c_2,...,c_p}_{\textrm{repeated }k\textrm{ times}},...\big]^T\in\mathbb{R}^{G\times G\times k\times(5+p)}}\]
</div>
где $p_c$ - вероятность обнаружения объекта, $b_x,b_y,b_h,b_w$ - свойства обнаруженной ограничивающий рамки, $c_1,...,c_p$ - one-hot представление того, какой из $p$ классов был обнаружен, а $k$ - количество якорных рамок.
<br>• Шаг 3: Запустить алгоритм подавления немаксимальных значений, чтобы удалить любые потенциально повторяющиеся перекрывающиеся ограничивающие рамки.<p></p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=yolo-en.jpeg?1eff4444ea01396f48e793bec5f2ef3b style=width:100%;>
</center>
</div>
<br>
<p><span class=remark>Примечание: когда $p_c=0$, сеть не обнаруживает никаких объектов. В этом случае соответствующие прогнозы $b_x, ..., c_p$ следует игнорировать.</span></p>
<br>
<p><span class="new-item item-r">R-CNN</span> Region with Convolutional Neural Networks (R-CNN) - это алгоритм обнаружения объектов, который сначала сегментирует изображение, чтобы найти потенциально релевантные ограничивающие рамки, а затем запускает алгоритм обнаружения, чтобы найти наиболее вероятные объекты в этих ограничивающих рамках.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=r-cnn-en.jpeg?5bb82ac3b9da8171d5c8a741861c3aa6 style=width:100%;>
</center>
</div>
<br>
<p><span class=remark>Примечание: хотя исходный алгоритм является дорогостоящим и медленным в вычислительном отношении, новые архитектуры позволили алгоритму работать быстрее, например Fast R-CNN и Faster R-CNN.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#face id=face></a>Проверка и распознавание лиц</h2>
<p><span class="new-item item-g">Типы моделей</span> В таблице ниже приведены два основных типа моделей:</p>
<div class=mobile-container>
<center>
<table style="table-layout:fixed; width:100%; min-width:300px; max-width: 700px;">
<colgroup>
<col style=width:50%>
<col style=width:50%>
</colgroup>
<tbody>
<tr>
<td align=center><b>Проверка лица</b></td>
<td align=center><b>Распознавание лиц</b></td>
</tr>
<tr>
<td align=left>• Это правильный человек?<br>
                 • Поиск one-to-one</td>
<td align=left>• Это одно из $K$ лиц в базе данных?<br>
                 • Поиск one-to-many</td>
</tr>
<tr>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=face-verification-en.jpeg?9b6ea3c15805347193943fe09692f71b style="width:100%; max-width:300px;"></td>
<td align=center><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=face-recognition-en.jpeg?ed30504000897087c2549f4f964c9441 style="width:100%; max-width:300px;"></td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-b">Обучение с первого раза</span> One Shot Learning - это алгоритм проверки лица, который использует ограниченный обучающий набор для изучения функции сходства, которая количественно определяет, насколько разные два заданных изображения. Функция подобия, применяемая к двум изображениям, часто обозначается $d(\textrm{image 1}, \textrm{image 2}).$</p>
<br>
<p><span class="new-item item-r">Сиамские сети</span> Siamese Network стремятся научиться кодировать изображения, чтобы затем количественно оценить, насколько два изображения отличаются друг от друга. Для заданного входного изображения $x^{(i)}$ закодированный вывод часто обозначается как $f(x^{(i)})$.</p>
<br>
<p><span class="new-item item-g">Потеря тройки</span> Triplet loss $\ell$ - это функция потерь, вычисленная на представлении тройки изображений $A$ (anchor), $P$ (positive) и $N$ (negative). Якорь (anchor) и положительный пример относятся к одному классу, а отрицательный пример - к другому. Называя $\alpha\in\mathbb{R}^+$ параметром отступа, этот потеря определяется следующим образом:</p>
<div class=mobile-container>
\[\boxed{\ell(A,P,N)=\max\left(d(A,P)-d(A,N)+\alpha,0\right)}\]
</div>
<center>
  <div class=row>
      <div class="col-xs-6 col-md-6"><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=triplet-loss-1.png?b18c14e9714ee258b805cb71ac498f4e style="width:100%; max-width:280px"></div>
      <div class="col-xs-6 col-md-6"><img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=triplet-loss-2.png?952990aae18c538c4bb2d93434342c52 style="width:100%; max-width:280px"></div>
  </div>
</center>
<br>
<h2><a aria-hidden=true class=anchor href=#style-transfer id=style-transfer></a>Нейронный перенос стиля</h2>
<p><span class="new-item item-g">Мотивация</span> цель нейронного переноса стиля - создать изображение $G$ на основе заданного контента $C$ и заданного стиля $S$.</p>
<div class=mobile-container>
<center>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=neural-style-motivation-en.jpeg?6b66c6e6a11a720c49301837f7834a61 style=width:100%;>
</center>
</div>
<br>
<p><span class="new-item item-b">Активация</span> В данном слое $l$ активация обозначена $a^{[l]}$ и имеет размеры $n_H\times n_w\times n_c$</p>
<br>
<p><span class="new-item item-r">Функция стоимости контента</span> Функция стоимости контента $J_{\textrm{content}}(C,G)$ используется для определения того, как сгенерированное изображение $G$ отличается от исходного изображения $C$ контента. Оно определяется следующим образом:</p>
<div class=mobile-container>
\[\boxed{J_{\textrm{content}}(C,G)=\frac{1}{2}||a^{[l](C)}-a^{[l](G)}||^2}\]
</div>
<br>
<p><span class="new-item item-g">Матрица стиля</span> Матрица стиля $G^{[l]}$ данного слоя $l$ является определителем Грама, где каждый из его элементов $G_{kk'}^{[l]}$ количественно определяет степень корреляции каналов $k$ и $k'$. Она определяется по отношению к активациям $a^{[l]}$ следующим образом:</p>
<div class=mobile-container>
\[\boxed{G_{kk'}^{[l]}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_w^{[l]}}a_{ijk}^{[l]}a_{ijk'}^{[l]}}\]
</div>
<p><span class=remark>Примечание: матрица стиля для изображения стиля и сгенерированное изображение помечаются $G^{[l](S)}$ и $G^{[l](G)}$ соответственно.</span></p>
<br>
<p><span class="new-item item-r">Функция стоимости стиля</span> функция стоимости стиля $J_{\textrm{style}}(S,G)$ используется для определения того, как сгенерированное изображение $G$ отличается от стиля $S$. Она определяется следующим образом:</p>
<div class=mobile-container>
\[\boxed{J_{\textrm{style}}^{[l]}(S,G)=\frac{1}{(2n_Hn_wn_c)^2}||G^{[l](S)}-G^{[l](G)}||_F^2=\frac{1}{(2n_Hn_wn_c)^2}\sum_{k,k'=1}^{n_c}\Big(G_{kk'}^{[l](S)}-G_{kk'}^{[l](G)}\Big)^2}\]
</div>
<br>
<p><span class="new-item item-b">Функция общей стоимости</span> функция общей стоимости определяется как комбинация признаков стоимости контента и стиля, взвешенных параметрами $\alpha,\beta$ следующим образом:</p>
<div class=mobile-container>
\[\boxed{J(G)=\alpha J_{\textrm{content}}(C,G)+\beta J_{\textrm{style}}(S,G)}\]
</div>
<p><span class=remark>Примечание: более высокое значение $\alpha$ заставит модель больше заботиться о контенте, а более высокое значение $\beta$ заставит её больше заботиться о стиле.</span></p>
<br>
<h2><a aria-hidden=true class=anchor href=#ct-architectures id=ct-architectures></a>Архитектуры с использованием вычислительных трюков</h2>
<p><span class="new-item item-r">Генеративные состязательные сети</span> Generative adversarial networks, также известные как GANs, состоят из генеративной и дискриминативной моделей, где генеративная модель направлена на генерирование наиболее правдивого вывода, который будет передан дискриминативной модели, направленной на сгенерированного и истинного изображений.</p>
<div class=mobile-container>
<img class=img-responsive netsrc=teaching/cs-230/illustrations/ src=discriminator-generator-en.jpeg?850896147a318376ce537812fbefe3a8>
</div>
<br>
<p><span class=remark>Примечание: ситуации использования различных видов GAN включают перевод текста в изображение, создание музыки, а также синтез другого рода.</span></p>
<br>
<p><span class="new-item item-r">ResNet</span> Residual Network architecture использует остаточные блоки с большим количеством слоев, чтобы уменьшить ошибку обучения. Остаточный блок имеет следующее характеристическое уравнение:</p>
<div class=mobile-container>
\[\boxed{a^{[l+2]}=g(a^{[l]}+z^{[l+2]})}\]
</div>
<br>
<p><span class="new-item item-r">Inception Network</span> Эта архитектура использует начальные модули и нацелена на то, чтобы попробовать различные свертки, тем самым повышая распознавательную способность за счет комбинации карт признаков различных масштабов. В частности, она использует трюк свертки $1\times1$ для ограничения вычислительной нагрузки. </p>
<br>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>