<!DOCTYPE html><html lang=en><head><!-- base href=../../ --><title>CS 229 - Deep Learning Cheatsheet</title><meta charset=utf-8><meta content="Teaching page of Shervine Amidi, Graduate Student at Stanford University." name=description><meta content="teaching, shervine, shervine amidi, data science" name=keywords><meta content="width=device-width, initial-scale=1" name=viewport>
<link href=https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning rel=canonical>
<link href=../../css/bootstrap.min.css rel=stylesheet>
<link href=../../css/font-awesome.min.css rel=stylesheet>
<link href=../../css/katex.min.css rel=stylesheet>
<link href=../../css/style.min.css rel=stylesheet type=text/css>
<link href=../../css/article.min.css rel=stylesheet>
<script src=../../js/jquery.min.js></script>
<script src=../../js/bootstrap.min.js></script>
<script defer src=../../js/underscore-min.js type=text/javascript></script>
<script defer src=../../js/katex.min.js></script>
<script defer src=../../js/auto-render.min.js></script>
<script defer src=../../js/article.min.js></script>
<script defer src=../../js/lang.min.js></script>
<script async defer src=../../js/buttons.js></script>
</head> <body data-offset=50 data-spy=scroll data-target=.navbar> <!-- HEADER <nav class="navbar navbar-inverse navbar-static-top"> <div class=container-fluid> <div class=navbar-header> <button class=navbar-toggle data-target=#myNavbar data-toggle=collapse type=button> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a class=navbar-brand href onclick=trackOutboundLink(this);> <img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48> </a> <p class=navbar-text><font color=#dddddd>Shervine Amidi</font></p> </div> <div class="collapse navbar-collapse" id=myNavbar> <ul class="nav navbar-nav"> <li><a href onclick=trackOutboundLink(this);>About</a></li> </ul> <ul class="nav navbar-nav navbar-center"> <li><a href=projects onclick=trackOutboundLink(this);>Projects</a></li> <li class=active><a href=teaching onclick=trackOutboundLink(this);>Teaching</a></li> <li><a href=blog onclick=trackOutboundLink(this);>Blog</a></li> </ul> <div class="collapse navbar-collapse" data-target=None id=HiddenNavbar> <ul class="nav navbar-nav navbar-right"> <li><a href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this);>About</a></li> <p class=navbar-text><font color=#dddddd>Afshine Amidi</font></p> <a class=navbar-brand href=https://www.mit.edu/~amidi onclick=trackOutboundLink(this); style="padding: 0px;"> <img alt=MIT netsrc=images/ src=../../images/mit-logo.png?4f7adbadc5c51293b439c17d7305f96b style="padding: 15px 15px; width: 70px; margin-left: 15px; margin-right: 5px;"> </a> </ul> </div> </div> </div> </nav> --> <div id=wrapper> <div id=sidebar-wrapper> <div class=sidebar-top> <li class=sidebar-title style=display:none;> <!-- DISPLAY:NONE --> <a href=teaching/cs-229 onclick=trackOutboundLink(this);><img alt=Stanford netsrc=images/ src=../../images/stanford-logo.png?f7176222abba492681ca93190e078e48 style="width: 15px;">   <b>CS 229 - Machine Learning</b></a> </li> <li class=sidebar-brand> <a href=#> <div> <span style=color:white>Deep Learning</span> </div> </a> </li> </div> <ul class=sidebar-nav> <li> <div class=dropdown-btn><a href=#nn>Neural Networks</a></div> <div class=dropdown-container> <a href=#nn><span>Architecture</span></a> <a href=#nn><span>Activation function</span></a> <a href=#nn><span>Backpropagation</span></a> <a href=#nn><span>Dropout</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#cnn>Convolutional Neural Networks</a></div> <div class=dropdown-container> <a href=#cnn><span>Convolutional layer</span></a> <a href=#cnn><span>Batch normalization</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#rnn>Recurrent Neural Networks</a></div> <div class=dropdown-container> <a href=#rnn><span>Gates</span></a> <a href=#rnn><span>LSTM</span></a> </div> </li> <li> <div class=dropdown-btn><a href=#reinforcement>Reinforcement learning</a></div> <div class=dropdown-container> <a href=#reinforcement><span>Markov decision processes</span></a> <a href=#reinforcement><span>Value/policy iteration</span></a> <a href=#reinforcement><span>Approximate dynamic     programming</span></a> <a href=#reinforcement><span>Policy search</span></a> </div> </li> </ul> <center> <div class=sidebar-footer> <li> <a href=https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-deep-learning.pdf onclick=trackOutboundLink(this); style="color: white; text-decoration:none;"> <i aria-hidden=false class="fa fa-github fa-fw"></i> View PDF version on GitHub </a> </li> </div> </center> </div> <article class="markdown-body entry-content" itemprop=text>
<div class="alert alert-primary" role=alert style=display:none;> <!-- DISPLAY:NONE -->
  Would you like to see this cheatsheet in your native language? You can help us <a class=alert-link href=https://github.com/shervinea/cheatsheet-translation onclick=trackOutboundLink(this);>translating it</a> on GitHub!
</div>
<div class=title-lang style=display:none;> <!-- DISPLAY:NONE -->
  <a aria-hidden=true class=anchor-bis href=#cs-229---machine-learning id=cs-229---machine-learning></a><a href=teaching/cs-229 onclick=trackOutboundLink(this);>CS 229 - Machine Learning</a>
  
  <div style=float:right;display:none;> <!-- DISPLAY:NONE -->
    <div class=input-group>
      <select class=form-control onchange=changeLangAndTrack(this); onfocus=storeCurrentIndex(this);>
        <option value=ar>العربية</option>
        <option selected value=en>English</option>
        <option value=es>Español</option>
        <option value=fa>فارسی</option>
        <option value=fr>Français</option>
        <option value=ko>한국어</option>
        <option value=pt>Português</option>
        <option value=tr>Türkçe</option>
        <option value=vi>Tiếng Việt</option>
        <option value=zh>简中</option>
        <option value=zh-tw>繁中</option>
      </select>
      <div class=input-group-addon><i class=fa></i></div>
    </div>
  </div>
</div>
<br>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-221/reflex-models/index.html'; oldhref='teaching/cs-221/cheatsheet-reflex-models'" type=button>CS 221 - Artificial Intelligence</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button><B>CS 229 - Machine Learning</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-230/convolutional-neural-networks/index.html'; oldhref='teaching/cs-230/cheatsheet-convolutional-neural-networks'" type=button>CS 230 - Deep Learning</button>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/probability/index.html'; oldhref='teaching/cs-229/refresher-probabilities-statistics'" type=button>Probabilities</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/linear-algebra/index.html'; oldhref='teaching/cs-229/refresher-algebra-calculus'" type=button>Algebra</button>
  </div>
</div>
<div aria-label=... class="btn-group btn-group-justified" role=group>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/supervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-supervised-learning'" type=button>Supervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/unsupervised-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-unsupervised-learning'" type=button>Unsupervised Learning</button>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default active" onclick="location.href='../../cs-229/deep-learning/index.html'; oldhref='teaching/cs-229/cheatsheet-deep-learning'" type=button><B>Deep Learning</B></BUTTON>
  </div>
  <div class=btn-group role=group>
    <button class="btn btn-default" onclick="location.href='../../cs-229/machine-learning-tips-and-tricks/index.html'; oldhref='teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks'" type=button>Tips and tricks</button>
  </div>
</div>
<h1>
  <a aria-hidden=true class=anchor-bis href=#cheatsheet id=user-content-cheatsheet></a>Deep Learning cheatsheet
  <div style=float:right;display:none;> <!-- DISPLAY:NONE --><a aria-label="Star afshinea/stanford-cs-229-machine-learning on GitHub" class="github-button fa-fw" data-icon=octicon-star data-show-count=true href=https://github.com/afshinea/stanford-cs-229-machine-learning onclick=trackOutboundLink(this);>Star</a></div>
</h1>
<p>By <a href=https://twitter.com/afshinea onclick=trackOutboundLink(this);>Afshine Amidi</a> and <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);>Shervine Amidi</a></p>
<h2><a aria-hidden=true class=anchor href=#nn id=nn></a>Neural Networks</h2>
<p>Neural networks are a class of models that are built with layers. Commonly used types of neural networks include convolutional and recurrent neural networks.</p>
<p><span class="new-item item-g">Архитектура</span> Словарь архитектур нейронных сетей описан на рисунке ниже:</p>
<center>
  <img alt=Illustration class=img-responsive netsrc=teaching/cs-229/illustrations/ src=neural-network-en.png?835862d448ad85bc5a038848d7d7df0b style=width:100%;max-width:700px>
</center>
<p>By noting $i$ the $i^{th}$ layer of the network and $j$ the $j^{th}$ hidden unit of the layer, we have:</p>
<div class=mobile-container>
\[\boxed{z_j^{[i]}={w_j^{[i]}}^Tx+b_j^{[i]}}\]
</div>
<p>where we note $w$, $b$, $z$ the weight, bias and output respectively.</p>
<br>
<p><span class="new-item item-b">Функция активации</span> используются в конце скрытого блока, чтобы внести в модель нелинейность. Вот самые распространенные:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Sigmoid</b></td>
<td align=center><b>Tanh</b></td>
<td align=center><b>ReLU</b></td>
<td align=center><b>Leaky ReLU</b></td>
</tr>
<tr>
<td align=center>$g(z)=\displaystyle\frac{1}{1+e^{-z}}$</td>
<td align=center>$g(z)=\displaystyle\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$</td>
<td align=center>$g(z)=\textrm{max}(0,z)$</td>
<td align=center>$g(z)=\textrm{max}(\epsilon z,z)$<br> with $\epsilon\ll1$</td>
</tr>
<tr>
<td align=center>
<img alt=Illustration class=img-responsive netsrc=teaching/cs-229/illustrations/ src=sigmoid.png?c91b6e5a7d4e78e95880bcf4e39889df>
</td>
<td align=center>
<img alt=Illustration class=img-responsive netsrc=teaching/cs-229/illustrations/ src=tanh.png?22ac27f27c510c6414e8a3bb4aca2d80>
</td>
<td align=center>
<img alt=Illustration class=img-responsive netsrc=teaching/cs-229/illustrations/ src=relu.png?6c1d78551355db5c6e4f6f8b5282cfa8>
</td>
<td align=center>
<img alt=Illustration class=img-responsive netsrc=teaching/cs-229/illustrations/ src=leaky-relu.png?73b2b4303d1880c69b63d7dfe2be852e>
</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-b">Cross-entropy loss</span> In the context of neural networks, the cross-entropy loss $L(z,y)$ is commonly used and is defined as follows:</p>
<div class=mobile-container>
\[\boxed{L(z,y)=-\Big[y\log(z)+(1-y)\log(1-z)\Big]}\]
</div>
<br>
<p><span class="new-item item-b">Learning rate</span> The learning rate, often noted $\alpha$ or sometimes $\eta$, indicates at which pace the weights get updated. This can be fixed or adaptively changed. The current most popular method is called Adam, which is a method that adapts the learning rate.</p>
<br>
<p><span class="new-item item-r">Обратное распространение</span> это метод обновления весов в нейронной сети с учетом фактического и желаемого результата. Производная по весу $w$ вычисляется с использованием цепного правила и имеет следующий вид:</p>
<div class=mobile-container>
\[\boxed{\frac{\partial L(z,y)}{\partial w}=\frac{\partial L(z,y)}{\partial a}\times\frac{\partial a}{\partial z}\times\frac{\partial z}{\partial w}}\]
</div>
<p>As a result, the weight is updated as follows:</p>
<div class=mobile-container>
\[\boxed{w\longleftarrow w-\alpha\frac{\partial L(z,y)}{\partial w}}\]
</div>
<br>
<p><span class="new-item item-g">Обновление весов</span> В нейронной сети веса обновляются следующим образом:
</p><ul>
<li><u>Step 1</u>: Take a batch of training data.
</li><li><u>Step 2</u>: Perform forward propagation to obtain the corresponding loss.
</li><li><u>Step 3</u>: Backpropagate the loss to get the gradients.
</li><li><u>Step 4</u>: Use the gradients to update the weights of the network.
</li></ul>
<p></p>
<br>
<p><span class="new-item item-g">Dropout</span> Dropout is a technique meant to prevent overfitting the training data by dropping out units in a neural network. In practice, neurons are either dropped with probability $p$ or kept with probability $1-p.$</p>
<br>
<h2><a aria-hidden=true class=anchor href=#cnn id=cnn></a>Convolutional Neural Networks</h2>
<p><span class="new-item item-r">Требования к сверточному слою</span> обозначим $W$ - размер входного объёма, $F$ - размер нейронов сверточного слоя, $P$ - величину дополнения нулями, тогда количество нейронов $N$, которые помещаются в данный объём, будет таким:</p>
<div class=mobile-container>
\[\boxed{N=\frac{W-F+2P}{S}+1}\]
</div>
<br>
<p><span class="new-item item-g">Batch normalization</span> It is a step of hyperparameter $\gamma, \beta$ that normalizes the batch $\{x_i\}$. By noting $\mu_B, \sigma_B^2$ the mean and variance of that we want to correct to the batch, it is done as follows:
</p><div class=mobile-container>
\[\boxed{x_i\longleftarrow\gamma\frac{x_i-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}+\beta}\]
</div>
It is usually done after a fully connected/convolutional layer and before a non-linearity layer and aims at allowing higher learning rates and reducing the strong dependence on initialization.<p></p>
<br>
<h2><a aria-hidden=true class=anchor href=#rnn id=rnn></a>Recurrent Neural Networks</h2>
<p><span class="new-item item-r">Типы вентилей</span> Вот различные типы вентилей, с которыми мы сталкиваемся в типичной рекуррентной нейронной сети:</p>
<div class=mobile-container>
<center>
<table>
<colgroup><col width=25%>
<col width=25%>
<col width=25%>
<col width=25%>
</colgroup><tbody>
<tr>
<td align=center><b>Input gate</b></td>
<td align=center><b>Forget gate</b></td>
<td align=center><b>Gate</b></td>
<td align=center><b>Output gate</b></td>
</tr>
<tr>
<td align=center>Write to cell or not?</td>
<td align=center>Erase a cell or not?</td>
<td align=center>How much to write to cell?</td>
<td align=center>How much to reveal cell?</td>
</tr>
</tbody>
</table>
</center>
</div>
<br>
<p><span class="new-item item-b">LSTM</span> Сеть с долгой кратковременной памятью (LSTM) - это тип модели RNN, которая позволяет избежать проблемы исчезающего градиента, добавляя вентиль «забывания».</p>
<br>
<div class="alert alert-warning" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link nethref=teaching/cs-230 href=../../cs-230/recurrent-neural-networks/index.html onclick=trackOutboundLink(this);>Deep Learning cheatsheets</a>!</div>
<br>
<h2><a aria-hidden=true class=anchor href=#reinforcement id=reinforcement></a>Reinforcement Learning and Control</h2>
<p>The goal of reinforcement learning is for an agent to learn how to evolve in an environment.</p>
<h3>Definitions</h3>
<p><span class="new-item item-b">Markov decision processes</span> A Markov decision process (MDP) is a 5-tuple $(\mathcal{S},\mathcal{A},\{P_{sa}\},\gamma,R)$ where:
</p><ul>
<li>$\mathcal{S}$ is the set of states
</li><li>$\mathcal{A}$ is the set of actions
</li><li>$\{P_{sa}\}$ are the state transition probabilities for $s\in\mathcal{S}$ and $a\in\mathcal{A}$
</li><li>$\gamma\in[0,1[$ is the discount factor
</li><li>$R:\mathcal{S}\times\mathcal{A}\longrightarrow\mathbb{R}$ or $R:\mathcal{S}\longrightarrow\mathbb{R}$ is the reward function that the algorithm wants to maximize
</li></ul><p></p>
<br>
<p><span class="new-item item-b">Policy</span> A policy $\pi$ is a function $\pi:\mathcal{S}\longrightarrow\mathcal{A}$ that maps states to actions.</p>
<p><span class=remark>Remark: we say that we execute a given policy $\pi$ if given a state $s$ we take the action $a=\pi(s)$.</span></p>
<br>
<p><span class="new-item item-g">Value function</span> For a given policy $\pi$ and a given state $s$, we define the value function $V^{\pi}$ as follows:</p>
<div class=mobile-container>
\[\boxed{V^\pi(s)=E\Big[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi\Big]}\]
</div>
<br>
<p><span class="new-item item-r">Bellman equation</span> The optimal Bellman equations characterizes the value function $V^{\pi^*}$ of the optimal policy $\pi^*$:</p>
<div class=mobile-container>
\[\boxed{V^{\pi^*}(s)=R(s)+\max_{a\in\mathcal{A}}\gamma\sum_{s'\in S}P_{sa}(s')V^{\pi^*}(s')}\]
</div>
<p><span class=remark>Remark: we note that the optimal policy $\pi^*$ for a given state $s$ is such that:</span></p>
<div class=mobile-container>
\[\boxed{\pi^*(s)=\underset{a\in\mathcal{A}}{\textrm{argmax}}\sum_{s'\in\mathcal{S}}P_{sa}(s')V^*(s')}\]
</div>
<br>
<p><span class="new-item item-g">Алгоритм итерации ценностей</span> алгоритм итерации ценностей состоит из двух этапов:</p>
<p>1) We initialize the value:</p>
<div class=mobile-container>
\[\boxed{V_0(s)=0}\]
</div>
<p>2) We iterate the value based on the values before:</p>
<div class=mobile-container>
\[\boxed{V_{i+1}(s)=R(s)+\max_{a\in\mathcal{A}}\left[\sum_{s'\in\mathcal{S}}\gamma P_{sa}(s')V_i(s')\right]}\]
</div>
<br>
<p><span class="new-item item-r">Оценка максимального правдоподобия</span> оценки максимального правдоподобия для вероятностей перехода между состояниями следующие:</p>
<div class=mobile-container>
\[\boxed{P_{sa}(s')=\frac{\#\textrm{times took action }a\textrm{ in state }s\textrm{ and got to }s'}{\#\textrm{times took action }a\textrm{ in state }s}}\]
</div>
<br>
<p><span class="new-item item-g">Q-learning</span> $Q$-learning is a model-free estimation of $Q$, which is done as follows:</p>
<div class=mobile-container>
\[\boxed{Q(s,a)\leftarrow Q(s,a)+\alpha\Big[R(s,a,s')+\gamma\max_{a'}Q(s',a')-Q(s,a)\Big]}\]
</div>
<br>
<div class="alert alert-warning" role=alert>For a more detailed overview of the concepts above, check out the <a class=alert-link nethref=teaching/cs-221/cheatsheet-states-models/ href=../../cs-221/states-models/index.html onclick=trackOutboundLink(this);>States-based Models cheatsheets</a>!</div>
</article> </div> <!-- FOOTER <footer class=footer> <div class=footer id=contact> <div class=container> <a href=https://twitter.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-twitter fa-3x fa-fw"></i></a> <a href=https://linkedin.com/in/shervineamidi onclick=trackOutboundLink(this);><i class="fa fa-linkedin fa-3x fa-fw"></i></a> <a href=https://github.com/shervinea onclick=trackOutboundLink(this);><i class="fa fa-github fa-3x fa-fw"></i></a> <a href="https://scholar.google.com/citations?user=nMnMTm8AAAAJ" onclick=trackOutboundLink(this);><i class="fa fa-google fa-3x fa-fw"></i></a> <a class=crptdml data-domain=stanford data-name=shervine data-tld=edu href=#mail onclick="trackOutboundLink(this); window.location.href = 'mailto:' + this.dataset.name + '@' + this.dataset.domain + '.' + this.dataset.tld"><i class="fa fa-envelope fa-3x fa-fw"></i></a> </div> </div> </footer> --> </body></html>